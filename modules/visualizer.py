# modules/visualizer.py

# --- Importaciones Est谩ndar y de Terceros

import streamlit as st
import pandas as pd
import base64
import geopandas as gpd
import altair as alt
import folium
from folium.plugins import MarkerCluster, MiniMap
from folium.raster_layers import WmsTileLayer
from streamlit_folium import folium_static
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
import branca.colormap as cm
import matplotlib.pyplot as plt
import matplotlib.cm as mpl_cm
from scipy import stats
from scipy.interpolate import Rbf
import pymannkendall as mk
from prophet.plot import plot_plotly
import io

# --- Importaciones de M贸dulos Propios ---
from modules.analysis import calculate_spi, calculate_spei, calculate_monthly_anomalies, calculate_percentiles_and_extremes
from modules.config import Config
from modules.utils import add_folium_download_button
from modules.interpolation import create_interpolation_surface
# Re-importaciones para funciones de tendencia y pron贸stico (asumiendo que existen en esos m贸dulos)
from modules.forecasting import (
    generate_sarima_forecast, generate_prophet_forecast,
    get_decomposition_results, create_acf_chart, create_pacf_chart
)

# --- DISPLAY UTILS ---

def display_filter_summary(total_stations_count, selected_stations_count, year_range, selected_months_count):
    """Muestra una caja informativa con un resumen de los filtros aplicados."""
    #Formatear el rango de a帽os
    if isinstance(year_range, tuple) and len(year_range) == 2:
        year_text=f"{year_range[0]}-{year_range[1]}"
    else:
        year_text ="N/A"
    summary_text = (
        f"**Estaciones Seleccionadas:** {selected_stations_count} de {total_stations_count} | "
        f"**Per铆odo:** {year_text} | "
        f"**Meses:** {selected_months_count} de 12"
    )
    st.info(summary_text)

def get_map_options():
    return {
        "CartoDB Positron (Predeterminado)": {"tiles": "cartodbpositron", "attr": '&copy; <a href="https://carto.com/attributions">CartoDB</a>', "overlay": False},
        "OpenStreetMap": {"tiles": "OpenStreetMap", "attr": '&copy; <a href="https://www.openstreetmap.org/copyright">OpenStreetMap</a> contributors', "overlay": False},
        "Topograf铆a (OpenTopoMap)": {"tiles": "https://{s}.tile.opentomap.org/{z}/{x}/{y}.png", "attr": 'Map data: &copy; <a href="https://www.openstreetmap.org/copyright">OpenStreetMap</a> contributors, <a href="http://viewfinderpanoramas.org">SRTM</a> | Map style: &copy; <a href="https://opentopomap.org">Open Topo Map</a> (<a href="https://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA</a>)', "overlay": False},
        "Relieve y Oc茅anos (GEBCO)": {"url": "https://www.gebco.net/data_and_products/gebco_web_services/web_map_service/web_map_service.php", "layers": "GEBCO_2021_Surface", "transparent": False, "attr": "GEBCO 2021", "overlay": True},
        "Mapa de Colombia (WMS IDEAM)": {"url": "https://geoservicios.ideam.gov.co/geoserver/ideam/wms", "layers": "ideam:col_admin", "transparent": True, "attr": "IDEAM", "overlay": True},
        "Cobertura de la Tierra (WMS IGAC)": {"url": "https://servicios.igac.gov.co/server/services/IDEAM/IDEAM_Cobertura_Corine/MapServer/WMSServer", "layers": "IDEAM_Cobertura_Corine_Web", "transparent": True, "attr": "IGAC", "overlay": True},
    }

def display_map_controls(container_object, key_prefix):
    map_options = get_map_options()
    base_maps = {k: v for k, v in map_options.items() if not v.get("overlay")}
    overlays = {k: v for k, v in map_options.items() if v.get("overlay")}
    selected_base_map_name = container_object.selectbox("Seleccionar Mapa Base",
                                                       list(base_maps.keys()), key=f"{key_prefix}_base_map")
    default_overlays = ["Mapa de Colombia (WMS IDEAM)"]
    selected_overlays_names = container_object.multiselect("Seleccionar Capas Adicionales",
                                                          list(overlays.keys()), default=default_overlays, key=f"{key_prefix}_overlays")
    selected_overlays_config = [overlays[k] for k in selected_overlays_names]
    return base_maps[selected_base_map_name], selected_overlays_config

def create_enso_chart(enso_data):
    if enso_data.empty or Config.ENSO_ONI_COL not in enso_data.columns:
        return go.Figure()
    data = enso_data.copy().sort_values(Config.DATE_COL)
    data.dropna(subset=[Config.ENSO_ONI_COL], inplace=True)
    if data.empty:
        return go.Figure()
    conditions = [data[Config.ENSO_ONI_COL] >= 0.5, data[Config.ENSO_ONI_COL] <= -0.5]
    phases = ['El Ni帽o', 'La Ni帽a']
    colors = ['red', 'blue']
    data['phase'] = np.select(conditions, phases, default='Neutral')
    data['color'] = np.select(conditions, colors, default='grey')
    y_range = [data[Config.ENSO_ONI_COL].min() - 0.5, data[Config.ENSO_ONI_COL].max() + 0.5]
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=data[Config.DATE_COL], y=[y_range[1] - y_range[0]] * len(data),
        base=y_range[0], marker_color=data['color'], width=30*24*60*60*1000,
        opacity=0.3, hoverinfo='none', showlegend=False
    ))
    legend_map = {'El Ni帽o': 'red', 'La Ni帽a': 'blue', 'Neutral': 'grey'}
    for phase, color in legend_map.items():
        fig.add_trace(go.Scatter(
            x=[None], y=[None], mode='markers',
            marker=dict(size=15, color=color, symbol='square', opacity=0.5),
            name=phase, showlegend=True
        ))
    fig.add_trace(go.Scatter(
        x=data[Config.DATE_COL], y=data[Config.ENSO_ONI_COL],
        mode='lines', name='Anomal铆a ONI', line=dict(color='black', width=2), showlegend=True
    ))
    fig.add_hline(y=0.5, line_dash="dash", line_color="red")
    fig.add_hline(y=-0.5, line_dash="dash", line_color="blue")
    fig.update_layout(
        height=600, title="Fases del Fen贸meno ENSO y Anomal铆a ONI",
        yaxis_title="Anomal铆a ONI (掳C)", xaxis_title="Fecha", showlegend=True,
        legend_title_text='Fase', yaxis_range=y_range
    )
    return fig

def create_anomaly_chart(df_plot):
    if df_plot.empty:
        return go.Figure()
    df_plot['color'] = np.where(df_plot['anomalia'] < 0, 'red', 'blue')
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=df_plot[Config.DATE_COL], y=df_plot['anomalia'],
        marker_color=df_plot['color'], name='Anomal铆a de Precipitaci贸n'
    ))
    if Config.ENSO_ONI_COL in df_plot.columns:
        df_plot_enso = df_plot.dropna(subset=[Config.ENSO_ONI_COL])
        # Highlight El Ni帽o periods
        nino_periods = df_plot_enso[df_plot_enso[Config.ENSO_ONI_COL] >= 0.5]
        for _, row in nino_periods.iterrows():
            fig.add_vrect(x0=row[Config.DATE_COL] - pd.DateOffset(days=15),
                          x1=row[Config.DATE_COL] + pd.DateOffset(days=15),
                          fillcolor="red", opacity=0.15, layer="below", line_width=0)

        # Highlight La Ni帽a periods
        nina_periods = df_plot_enso[df_plot_enso[Config.ENSO_ONI_COL] <= -0.5]
        for _, row in nina_periods.iterrows():
            fig.add_vrect(x0=row[Config.DATE_COL] - pd.DateOffset(days=15),
                          x1=row[Config.DATE_COL] + pd.DateOffset(days=15),
                          fillcolor="blue", opacity=0.15, layer="below", line_width=0)
        
        # Add hidden traces for legend
        fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',
                                 marker=dict(symbol='square', color='rgba(255, 0, 0, 0.3)'),
                                 name='Fase El Ni帽o'))
        fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',
                                 marker=dict(symbol='square', color='rgba(0, 0, 255, 0.3)'),
                                 name='Fase La Ni帽a'))
                                 
    fig.update_layout(
        height=600, title="Anomal铆as Mensuales de Precipitaci贸n y Fases ENSO",
        yaxis_title=f"Anomal铆a de Precipitaci贸n (mm)", xaxis_title="Fecha", showlegend=True
    )
    return fig

#--- FUNCIN AUXILIAR PARA POPUP ---
def generate_station_popup_html(row, df_anual_melted, include_chart=False, df_monthly_filtered=None):
    """Robustly generates the HTML content for a station's popup."""
    full_html = ""
    station_name = row.get(Config.STATION_NAME_COL, 'N/A')
    try:
        # Get the year range from the session state
        year_range_val = st.session_state.get('year_range', (2000, 2020))
        if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
            year_min, year_max = year_range_val
        else: # Fallback for other modes
            year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
        total_years_in_period = year_max - year_min + 1
        
        # Calculate statistics
        df_station_data = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] == station_name]
        if not df_station_data.empty:
            summary_data = df_station_data.groupby(Config.STATION_NAME_COL).agg(
                precip_media_anual=('precipitation', 'mean'),
                a帽os_validos=('precipitation', 'count')
            ).iloc[0]
            valid_years = int(summary_data.get('a帽os_validos', 0))
            precip_media_anual = summary_data.get('precip_media_anual', 0)
        else:
            valid_years = 0
            precip_media_anual = 0
            
        # Generate the text part of the HTML
        text_html = f"""
        <h4>{station_name}</h4>
        <p><b>Municipio:</b> {row.get(Config.MUNICIPALITY_COL, 'N/A')}</p>
        <p><b>Altitud:</b> {row.get(Config.ALTITUDE_COL, 'N/A')} m</p>
        <p><b>Promedio Anual:</b> {precip_media_anual:.0f} mm</p>
        <small>(Calculado con <b>{valid_years}</b> de <b>{total_years_in_period}</b> a帽os del per铆odo)</small>
        """
        full_html = text_html
        
        # Try to generate the chart part of the HTML (Minigr谩ficos)
        chart_html = ""
        if include_chart and df_monthly_filtered is not None:
            df_station_monthly_avg = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station_name]
            if not df_station_monthly_avg.empty:
                df_monthly_avg = df_station_monthly_avg.groupby(Config.MONTH_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                if not df_monthly_avg.empty:
                    fig = go.Figure(data=[go.Bar(x=df_monthly_avg[Config.MONTH_COL], y=df_monthly_avg[Config.PRECIPITATION_COL])])
                    fig.update_layout(title_text=f"Ppt. Mensual Media", xaxis_title="Mes", yaxis_title="Ppt. (mm)",
                                      height=250, width=350, margin=dict(t=40, b=20, l=20, r=20))
                    chart_html = fig.to_html(full_html=False, include_plotlyjs='cdn')
                    
        # Combine text and chart if chart was created successfully
        if chart_html:
            sanitized_chart_html = chart_html.replace('"', '&quot;')
            full_html = text_html + "<hr>" + f'<iframe srcdoc="{sanitized_chart_html}" width="370" height="270" frameborder="0"></iframe>'
            
    except Exception as e:
        st.warning(f"Could not generate the full popup content for '{station_name}'. Reason: {e}")
        if 'text_html' in locals():
            full_html = text_html
        else:
            full_html = f"<h4>{station_name}</h4><p>Error loading popup data.</p>"
            
    return folium.Popup(full_html, max_width=450)

#--- CHART AND MAP HELPER FUNCTIONS --
def create_folium_map(location, zoom, base_map_config, overlays_config, fit_bounds_data=None):
    """Creates a Folium map with robust centering logic."""
    m = folium.Map(location=location, zoom_start=zoom, tiles=base_map_config.get("tiles", "OpenStreetMap"),
                   attr=base_map_config.get("attr", None))
                   
    if fit_bounds_data is not None and not fit_bounds_data.empty:
        if len(fit_bounds_data) > 1:
            bounds = fit_bounds_data.total_bounds
            if np.all(np.isfinite(bounds)):
                m.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])
        elif len(fit_bounds_data) == 1:
            point = fit_bounds_data.iloc[0].geometry
            m.location = [point.y, point.x]
            m.zoom_start = 12
            
    for layer_config in overlays_config:
        if layer_config.get("url"):
            WmsTileLayer(url=layer_config["url"], layers=layer_config["layers"], fmt='image/png',
                         transparent=layer_config.get("transparent", False), overlay=True, control=True,
                         name=layer_config.get("attr", "Overlay")).add_to(m)
                         
    return m

#--- MAIN TAB DISPLAY FUNCTIONS ---
def display_welcome_tab():
    st.header("Bienvenido al Sistema de Informaci贸n de Lluvias y Clima")
    st.markdown(Config.WELCOME_TEXT, unsafe_allow_html=True)
    if os.path.exists(Config.LOGO_PATH):
        try:
            # CORRECCIN: Leemos la imagen en binario para evitar UnidentifiedImageError
            with open(Config.LOGO_PATH, "rb") as f:
                logo_bytes = f.read()
            st.image(logo_bytes, width=250, caption="Corporaci贸n Cuenca Verde")
        except Exception:
            st.warning("No se pudo cargar el logo de bienvenida.")


def display_spatial_distribution_tab(gdf_filtered, stations_for_analysis, df_anual_melted, df_monthly_filtered):
    st.header("Distribuci贸n espacial de las Estaciones de Lluvia")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
    
    gdf_display = gdf_filtered.copy()
    if not df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL]).empty:
        summary_stats = (
            df_anual_melted.groupby(Config.STATION_NAME_COL)[Config.PRECIPITATION_COL]
            .agg(['mean', 'count']).reset_index()
        )
        summary_stats.rename(columns={'mean': 'precip_media_anual', 'count': 'a帽os_validos'}, inplace=True)
        gdf_display = gdf_display.merge(summary_stats, on=Config.STATION_NAME_COL, how='left')
    else:
        gdf_display['precip_media_anual'] = np.nan
        gdf_display['a帽os_validos'] = 0
    
    gdf_display['precip_media_anual'] = gdf_display['precip_media_anual'].fillna(0)
    gdf_display['a帽os_validos'] = gdf_display['a帽os_validos'].fillna(0).astype(int)
    
    sub_tab_mapa, sub_tab_grafico = st.tabs(["Mapa Interactivo", "Gr谩fico de Disponibilidad de Datos"])
    with sub_tab_mapa:
        controls_col, map_col = st.columns([1, 3])
        with controls_col:
            st.subheader("Controles del Mapa")
            selected_base_map_config, selected_overlays_config = display_map_controls(st, "dist_esp")
            if not gdf_display.empty:
                st.markdown("---")
                if os.path.exists(Config.LOGO_PATH):
                    try:
                        with open(Config.LOGO_PATH, "rb") as f:
                            logo_bytes = f.read()
                        st.image(logo_bytes, width=70)
                    except Exception:
                        st.warning("No se pudo cargar el logo.")
                st.metric("Estaciones en Vista", len(gdf_display))
                st.markdown("---")
        with map_col:
            if not gdf_display.empty:
                m = create_folium_map(
                    location=[4.57, -74.29], # Default center
                    zoom=5,
                    base_map_config=selected_base_map_config,
                    overlays_config=selected_overlays_config,
                    fit_bounds_data=gdf_display
                )
                if 'gdf_municipios' in st.session_state and st.session_state.gdf_municipios is not None:
                    folium.GeoJson(st.session_state.gdf_municipios.to_json(), name='Municipios').add_to(m)
                    
                marker_cluster = MarkerCluster(name='Estaciones').add_to(m)
                for _, row in gdf_display.iterrows():
                    popup_object = generate_station_popup_html(row, df_anual_melted, include_chart=False)
                    folium.Marker(
                        location=[row['geometry'].y, row['geometry'].x],
                        tooltip=row[Config.STATION_NAME_COL],
                        popup=popup_object
                    ).add_to(marker_cluster)
                    
                folium.LayerControl().add_to(m)
                m.add_child(MiniMap(toggle_display=True))
                folium_static(m, height=450, width="100%")
                add_folium_download_button(m, "mapa_distribucion.html")
            else:
                st.warning("No hay estaciones seleccionadas para mostrar en el mapa.")
                
        with sub_tab_grafico:
            st.subheader("Disponibilidad y Composici贸n de Datos por Estaci贸n")
            # --- L贸gica de Gr谩fico de Disponibilidad ---
            if not gdf_display.empty:
                if st.session_state.analysis_mode == "Completar series (interpolaci贸n)":
                    st.info("Mostrando la composici贸n de datos originales vs. completados para el per铆odo seleccionado.")
                    if not df_monthly_filtered.empty and Config.ORIGIN_COL in df_monthly_filtered.columns:
                        data_composition = df_monthly_filtered.groupby([Config.STATION_NAME_COL, Config.ORIGIN_COL]).size().unstack(fill_value=0)
                        if 'Original' not in data_composition: data_composition['Original'] = 0
                        if 'Completado' not in data_composition: data_composition['Completado'] = 0
                        data_composition['total'] = data_composition['Original'] + data_composition['Completado']
                        data_composition['% Original'] = (data_composition['Original'] / data_composition['total']) * 100
                        data_composition['% Completado'] = (data_composition['Completado'] / data_composition['total']) * 100
                        sort_order_comp = st.radio("Ordenar por:", ["% Datos Originales (Mayor a Menor)", "% Datos Originales (Menor a Mayor)", "Alfab茅tico"], horizontal=True, key="sort_comp")
                        
                        if "Mayor a Menor" in sort_order_comp: data_composition = data_composition.sort_values("% Original", ascending=False)
                        elif "Menor a Mayor" in sort_order_comp: data_composition = data_composition.sort_values("% Original", ascending=True)
                        else: data_composition = data_composition.sort_index(ascending=True)
                        
                        df_plot = data_composition.reset_index().melt(
                            id_vars=Config.STATION_NAME_COL, value_vars=['% Original', '% Completado'],
                            var_name='Tipo de Dato', value_name='Porcentaje')
                            
                        fig_comp = px.bar(df_plot, x=Config.STATION_NAME_COL, y='Porcentaje', color='Tipo de Dato',
                                          title='Composici贸n de Datos por Estaci贸n',
                                          labels={Config.STATION_NAME_COL: 'Estaci贸n', 'Porcentaje': '% del Per铆odo'},
                                          text_auto='.1f',
                                          color_discrete_map={'% Original': '#1f77b4', '% Completado': '#ff7f0e'})
                        fig_comp.update_layout(height=500, xaxis={'categoryorder': 'trace'})
                        st.plotly_chart(fig_comp, width='stretch')
                    else:
                        st.warning("No hay datos mensuales procesados para mostrar la composici贸n.")
                else:
                    st.info("Mostrando el porcentaje de disponibilidad de datos seg煤n el archivo de estaciones.")
                    sort_order_disp = st.radio("Ordenar estaciones por:", ["% Datos (Mayor a Menor)", "% Datos (Menor a Mayor)", "Alfab茅tico"], horizontal=True, key="sort_disp")
                    df_chart = gdf_display.copy()
                    
                    if "% Datos (Mayor a Menor)" in sort_order_disp: df_chart = df_chart.sort_values(Config.PERCENTAGE_COL, ascending=False)
                    elif "% Datos (Menor a Mayor" in sort_order_disp: df_chart = df_chart.sort_values(Config.PERCENTAGE_COL, ascending=True)
                    else: df_chart = df_chart.sort_values(Config.STATION_NAME_COL, ascending=True)
                    
                    fig_disp = px.bar(df_chart, x=Config.STATION_NAME_COL, y=Config.PERCENTAGE_COL,
                                      title='Porcentaje de Disponibilidad de Datos Hist贸ricos',
                                      labels={Config.STATION_NAME_COL: 'Estaci贸n', Config.PERCENTAGE_COL: '% de Datos Disponibles'},
                                      color=Config.PERCENTAGE_COL,
                                      color_continuous_scale=px.colors.sequential.Viridis)
                    fig_disp.update_layout(height=500, xaxis={'categoryorder': 'trace'})
                    st.plotly_chart(fig_disp, width='stretch')
            else:
                st.warning("No hay estaciones seleccionadas para mostrar el gr谩fico.")


def display_graphs_tab(df_anual_melted, df_monthly_filtered, stations_for_analysis, gdf_filtered):
    st.header("Visualizaciones de Precipitaci贸n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
    
    year_range_val = st.session_state.get('year_range', (2000, 2020))
    if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
        year_min, year_max = year_range_val
    else:
        year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci贸n: {stations_for_analysis[0]}"

    # --- ENRIQUECIMIENTO DE DATAFRAMES CON METADATA (MUNICIPIO, ALTITUD) ---
    metadata_cols = [Config.STATION_NAME_COL, Config.MUNICIPALITY_COL, Config.ALTITUDE_COL]
    gdf_metadata = gdf_filtered[metadata_cols].drop_duplicates(subset=[Config.STATION_NAME_COL]).copy() 
    
    df_anual_rich = df_anual_melted.merge(gdf_metadata, on=Config.STATION_NAME_COL, how='left')
    df_monthly_rich = df_monthly_filtered.merge(gdf_metadata, on=Config.STATION_NAME_COL, how='left')
    
    # --- PESTAAS DE VISUALIZACIN ---
    sub_tab_anual, sub_tab_mensual, sub_tab_comparacion, sub_tab_distribucion, \
    sub_tab_acumulada, sub_tab_altitud, sub_tab_regional = \
    st.tabs(["An谩lisis Anual", "An谩lisis Mensual", "Comparaci贸n R谩pida", "Distribuci贸n",
             "Acumulada", "Relaci贸n Altitud", "Serie Regional"])

    # 1. ANLISIS ANUAL
    with sub_tab_anual:
        anual_graf_tab, anual_analisis_tab = st.tabs(["Gr谩fico de Serie Anual", "An谩lisis Multianual"])
        
        with anual_graf_tab:
            if not df_anual_rich.empty:
                st.subheader("Precipitaci贸n Anual (mm)")
                st.info("Solo se muestran los a帽os con 10 o m谩s meses de datos v谩lidos.")
                chart_anual = (
                    alt.Chart(df_anual_rich.dropna(subset=[Config.PRECIPITATION_COL])) # <-- USAR df_anual_rich
                    .mark_line(point=True)
                    .encode(
                        x=alt.X(f'{Config.YEAR_COL}:O', title='A帽o'),
                        y=alt.Y(f'{Config.PRECIPITATION_COL}:Q', title='Precipitaci贸n (mm)'),
                        color=f'{Config.STATION_NAME_COL}:N',
                        tooltip=[
                            alt.Tooltip(Config.STATION_NAME_COL), 
                            alt.Tooltip(Config.YEAR_COL, format='d', title='A帽o'), 
                            alt.Tooltip(f'{Config.PRECIPITATION_COL}:Q', format='.0f', title='Ppt. Anual (mm)'),
                            alt.Tooltip(f'{Config.MUNICIPALITY_COL}:N', title='Municipio'), 
                            alt.Tooltip(f'{Config.ALTITUDE_COL}:Q', format='.0f', title='Altitud (m)') 
                        ]
                    )
                    .properties(title=f'Precipitaci贸n Anual por Estaci贸n ({year_min} - {year_max})')
                    .interactive()
                )
                st.altair_chart(chart_anual, use_container_width=True)
            else:
                st.warning("No hay datos anuales para mostrar la serie.")
                
        with anual_analisis_tab:
            if not df_anual_rich.empty:
                st.subheader("Precipitaci贸n Media Multianual")
                st.caption(f"Per铆odo de an谩lisis: {year_min} - {year_max}")
                chart_type_annual = st.radio("Seleccionar tipo de gr谩fico:", ("Gr谩fico de Barras (Promedio)", "Gr谩fico de Cajas (Distribuci贸n)"), key="avg_chart_type_annual", horizontal=True)
                
                if chart_type_annual == "Gr谩fico de Barras (Promedio)":
                    df_summary = df_anual_rich.groupby(Config.STATION_NAME_COL, as_index=False)[Config.PRECIPITATION_COL].mean().round(0)
                    # El resto de la l贸gica de barras (sorting, etc.) usa df_summary y Config.PRECIPITATION_COL, por lo que es seguro.
                    sort_order = st.radio("Ordenar estaciones por:", ["Promedio (Mayor a Menor)", "Promedio (Menor a Mayor)", "Alfab茅tico"], horizontal=True, key="sort_annual_avg")
                    if "Mayor a Menor" in sort_order: df_summary = df_summary.sort_values(Config.PRECIPITATION_COL, ascending=False)
                    elif "Menor a Mayor" in sort_order: df_summary = df_summary.sort_values(Config.PRECIPITATION_COL, ascending=True)
                    else: df_summary = df_summary.sort_values(Config.STATION_NAME_COL, ascending=True)

                    fig_avg = px.bar(df_summary, x=Config.STATION_NAME_COL,
                                    y=Config.PRECIPITATION_COL,
                                    title=f'Promedio de Precipitaci贸n Anual por Estaci贸n ({year_min} - {year_max})',
                                    labels={Config.STATION_NAME_COL: 'Estaci贸n', Config.PRECIPITATION_COL: 'Precipitaci贸n Media Anual (mm)'},
                                    color=Config.PRECIPITATION_COL,
                                    color_continuous_scale=px.colors.sequential.Blues_r)
                    fig_avg.update_layout(height=500,
                                        xaxis={'categoryorder': 'total descending' if "Mayor a Menor" in sort_order
                                                else ('total ascending' if "Menor a Mayor" in sort_order else 'trace')})
                    st.plotly_chart(fig_avg, width='stretch')
                else: # Gr谩fico de Cajas
                    df_anual_filtered_for_box = df_anual_rich[df_anual_rich[Config.STATION_NAME_COL].isin(stations_for_analysis)]
                    fig_box_annual = px.box(df_anual_filtered_for_box, x=Config.STATION_NAME_COL,
                                            y=Config.PRECIPITATION_COL,
                                            color=Config.STATION_NAME_COL, points='all',
                                            title='Distribuci贸n de la Precipitaci贸n Anual por Estaci贸n',
                                            labels={Config.STATION_NAME_COL: 'Estaci贸n',
                                                    Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)'})
                    fig_box_annual.update_layout(height=500)
                    st.plotly_chart(fig_box_annual, width='stretch', key="box_anual_multianual")
            else:
                st.warning("No hay datos anuales para mostrar el an谩lisis multianual.")

    # 2. ANLISIS MENSUAL
    with sub_tab_mensual:
        mensual_graf_tab, mensual_enso_tab, mensual_datos_tab = st.tabs(["Gr谩fico de Serie Mensual", "An谩lisis ENSO en el Per铆odo", "Tabla de Datos"])
        
        with mensual_graf_tab:
            if not df_monthly_rich.empty:
                controls_col, chart_col = st.columns([1, 4])
                with controls_col:
                    st.markdown("##### Opciones del Gr谩fico")
                    chart_type = st.radio("Tipo de Gr谩fico:",
                                          ["L铆neas y Puntos", "Nube de Puntos", "Gr谩fico de Cajas (Distribuci贸n Mensual)"],
                                          key="monthly_chart_type")
                    color_by_disabled = (chart_type == "Gr谩fico de Cajas (Distribuci贸n Mensual)")
                    color_by = st.radio("Colorear por:", ["Estaci贸n", "Mes"],
                                        key="monthly_color_by", disabled=color_by_disabled)
                with chart_col:
                    if chart_type != "Gr谩fico de Cajas (Distribuci贸n Mensual)":
                        base_chart = alt.Chart(df_monthly_rich).encode( # <-- USAR df_monthly_rich
                            x=alt.X(f'{Config.DATE_COL}:T', title='Fecha'),
                            y=alt.Y(f'{Config.PRECIPITATION_COL}:Q', title='Precipitaci贸n (mm)'),
                            tooltip=[
                                alt.Tooltip(Config.DATE_COL, format='%Y-%m'),
                                alt.Tooltip(f'{Config.PRECIPITATION_COL}:Q', format='.0f', title='Ppt. Mensual'),
                                alt.Tooltip(f'{Config.STATION_NAME_COL}:N', title='Estaci贸n'), 
                                alt.Tooltip(Config.ORIGIN_COL, title='Origen'), 
                                alt.Tooltip(f'{Config.MONTH_COL}:N', title="Mes"),
                                alt.Tooltip(f'{Config.MUNICIPALITY_COL}:N', title='Municipio'), 
                                alt.Tooltip(f'{Config.ALTITUDE_COL}:Q', format='.0f', title='Altitud (m)')
                            ]
                        )
                        color_encoding = alt.Color(f'{Config.STATION_NAME_COL}:N', legend=alt.Legend(title="Estaciones"))
                        if color_by == "Mes":
                            color_encoding = alt.Color(f'month({Config.DATE_COL}):N', legend=alt.Legend(title="Meses"),
                                                       scale=alt.Scale(scheme='tableau20'))
                        
                        if chart_type == "L铆neas y Puntos":
                            line_chart = base_chart.mark_line(opacity=0.4,
                                                              color='lightgray').encode(detail=f'{Config.STATION_NAME_COL}:N')
                            point_chart = base_chart.mark_point(filled=True, size=60).encode(color=color_encoding)
                            final_chart = (line_chart + point_chart)
                        else:
                            point_chart = base_chart.mark_point(filled=True, size=60).encode(color=color_encoding)
                            final_chart = point_chart
                            
                        st.altair_chart(final_chart.properties(height=500, title=f"Serie de Precipitaci贸n Mensual ({year_min} - {year_max})").interactive(), use_container_width=True)
                    else:
                        st.subheader("Distribuci贸n de la Precipitaci贸n Mensual")
                        fig_box_monthly = px.box(df_monthly_rich, x=Config.MONTH_COL, # <-- USAR df_monthly_rich
                                                y=Config.PRECIPITATION_COL,
                                                color=Config.STATION_NAME_COL, title='Distribuci贸n de la Precipitaci贸n por Mes',
                                                labels={Config.MONTH_COL: 'Mes', Config.PRECIPITATION_COL: 'Precipitaci贸n Mensual (mm)', Config.STATION_NAME_COL: 'Estaci贸n'})
                        fig_box_monthly.update_layout(height=500)
                        st.plotly_chart(fig_box_monthly, width='stretch')
            else:
                st.warning("No hay datos mensuales para mostrar el gr谩fico.")
        
        with mensual_enso_tab:
            if 'df_enso' in st.session_state and st.session_state.df_enso is not None:
                enso_filtered = st.session_state.df_enso[(st.session_state.df_enso[Config.DATE_COL].dt.year >= year_min) &
                                                         (st.session_state.df_enso[Config.DATE_COL].dt.year <= year_max) &
                                                         (st.session_state.df_enso[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))]
                fig_enso_mensual = create_enso_chart(enso_filtered)
                st.plotly_chart(fig_enso_mensual, width='stretch', key="enso_chart_mensual")
            else:
                st.info("No hay datos ENSO disponibles para este an谩lisis.")
                
        with mensual_datos_tab:
            st.subheader("Datos de Precipitaci贸n Mensual Detallados")
            if not df_monthly_rich.empty: # <-- USAR df_monthly_rich para la tabla de datos
                df_values = df_monthly_rich.pivot_table(index=Config.DATE_COL,
                                                         columns=Config.STATION_NAME_COL, values=Config.PRECIPITATION_COL).round(1)
                st.dataframe(df_values, width='stretch')
            else:
                st.info("No hay datos mensuales detallados.")

    # 3. COMPARACIN RPIDA
    with sub_tab_comparacion:
        st.subheader("Comparaci贸n de Precipitaci贸n entre Estaciones")
        if len(stations_for_analysis) < 2:
            st.info("Seleccione al menos dos estaciones para comparar.")
        else:
            st.markdown("##### Precipitaci贸n Mensual Promedio")
            df_monthly_avg = df_monthly_rich.groupby([Config.STATION_NAME_COL, Config.MONTH_COL])[Config.PRECIPITATION_COL].mean().reset_index() # <-- USAR df_monthly_rich
            fig_avg_monthly = px.line(df_monthly_avg, x=Config.MONTH_COL,
                                    y=Config.PRECIPITATION_COL, color=Config.STATION_NAME_COL,
                                    labels={Config.MONTH_COL: 'Mes', Config.PRECIPITATION_COL: 'Precipitaci贸n Promedio (mm)'},
                                    title='Promedio de Precipitaci贸n Mensual por Estaci贸n')
            meses_dict = {'Enero': 1, 'Febrero': 2, 'Marzo': 3, 'Abril': 4, 'Mayo': 5, 'Junio': 6, 'Julio': 7,
                          'Agosto': 8, 'Septiembre': 9, 'Octubre': 10, 'Noviembre': 11, 'Diciembre': 12}
            fig_avg_monthly.update_layout(height=500, xaxis=dict(tickmode='array',
                                                                 tickvals=list(meses_dict.values()), ticktext=list(meses_dict.keys())))
            st.plotly_chart(fig_avg_monthly, width='stretch')

            st.markdown("##### Distribuci贸n de Precipitaci贸n Anual")
            df_anual_filtered_for_box = df_anual_rich[df_anual_rich[Config.STATION_NAME_COL].isin(stations_for_analysis)] # <-- USAR df_anual_rich
            fig_box_annual = px.box(df_anual_filtered_for_box, x=Config.STATION_NAME_COL,
                                    y=Config.PRECIPITATION_COL,
                                    color=Config.STATION_NAME_COL, points='all',
                                    title='Distribuci贸n de la Precipitaci贸n Anual por Estaci贸n',
                                    labels={Config.STATION_NAME_COL: 'Estaci贸n', Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)'})
            fig_box_annual.update_layout(height=500)
            st.plotly_chart(fig_box_annual, width='stretch', key="box_anual_comparacion")

    # 4. DISTRIBUCIN
    with sub_tab_distribucion:
        st.subheader("Distribuci贸n de la Precipitaci贸n")
        distribucion_tipo = st.radio("Seleccionar tipo de distribuci贸n:", ("Anual", "Mensual"), horizontal=True)
        plot_type = st.radio("Seleccionar tipo de gr谩fico:", ("Histograma", "Gr谩fico de Violin"), horizontal=True, key="distribucion_plot_type")
        
        if distribucion_tipo == "Anual":
            if not df_anual_rich.empty: # <-- USAR df_anual_rich
                if plot_type == "Histograma":
                    fig_hist_anual = px.histogram(df_anual_rich, x=Config.PRECIPITATION_COL,
                                                  color=Config.STATION_NAME_COL,
                                                  title=f'Distribuci贸n Anual de Precipitaci贸n ({year_min} - {year_max})',
                                                  labels={Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)', 'count': 'Frecuencia'})
                    fig_hist_anual.update_layout(height=500)
                    st.plotly_chart(fig_hist_anual, width='stretch')
                else:
                    fig_violin_anual = px.violin(df_anual_rich, y=Config.PRECIPITATION_COL, # <-- USAR df_anual_rich
                                                 x=Config.STATION_NAME_COL, color=Config.STATION_NAME_COL,
                                                 box=True, points="all", title='Distribuci贸n Anual con Gr谩fico de Violin',
                                                 labels={Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)', Config.STATION_NAME_COL: 'Estaci贸n'})
                    fig_violin_anual.update_layout(height=500)
                    st.plotly_chart(fig_violin_anual, width='stretch')
            else:
                st.warning("No hay datos anuales para mostrar la distribuci贸n.")
        else: # Mensual
            if not df_monthly_rich.empty: # <-- USAR df_monthly_rich
                if plot_type == "Histograma":
                    fig_hist_mensual = px.histogram(df_monthly_rich, x=Config.PRECIPITATION_COL, # <-- USAR df_monthly_rich
                                                    color=Config.STATION_NAME_COL,
                                                    title=f'Distribuci贸n Mensual de Precipitaci贸n ({year_min} - {year_max})',
                                                    labels={Config.PRECIPITATION_COL: 'Precipitaci贸n Mensual (mm)', 'count': 'Frecuencia'})
                    fig_hist_mensual.update_layout(height=500)
                    st.plotly_chart(fig_hist_mensual, width='stretch')
                else:
                    fig_violin_mensual = px.violin(df_monthly_rich, y=Config.PRECIPITATION_COL, # <-- USAR df_monthly_rich
                                                   x=Config.MONTH_COL, color=Config.STATION_NAME_COL,
                                                   box=True, points="all", title='Distribuci贸n Mensual con Gr谩fico de Violin',
                                                   labels={Config.MONTH_COL: 'Mes', Config.PRECIPITATION_COL: 'Precipitaci贸n Mensual (mm)', Config.STATION_NAME_COL: 'Estaci贸n'})
                    fig_violin_mensual.update_layout(height=500)
                    st.plotly_chart(fig_violin_mensual, width='stretch')
            else:
                st.warning("No hay datos mensuales para mostrar el gr谩fico.")

    # 5. ACUMULADA
    with sub_tab_acumulada:
        st.subheader("Precipitaci贸n Acumulada Anual")
        if not df_anual_rich.empty: # <-- USAR df_anual_rich
            df_acumulada = df_anual_rich.groupby([Config.YEAR_COL, Config.STATION_NAME_COL])[Config.PRECIPITATION_COL].sum().reset_index()
            fig_acumulada = px.bar(df_acumulada, x=Config.YEAR_COL, y=Config.PRECIPITATION_COL,
                                    color=Config.STATION_NAME_COL,
                                    title=f'Precipitaci贸n Acumulada por A帽o ({year_min} - {year_max})',
                                    labels={Config.YEAR_COL: 'A帽o', Config.PRECIPITATION_COL: 'Precipitaci贸n Acumulada (mm)'})
            fig_acumulada.update_layout(barmode='group', height=500)
            st.plotly_chart(fig_acumulada, width='stretch')
        else:
            st.info("No hay datos para calcular la precipitaci贸n acumulada.")

    # 6. RELACIN ALTITUD
    with sub_tab_altitud:
        st.subheader("Relaci贸n entre Altitud y Precipitaci贸n")
        # Usamos df_anual_rich para el promedio y la altitud
        if not df_anual_rich.empty and not df_anual_rich[Config.ALTITUDE_COL].isnull().all():
            df_relacion = (
                df_anual_rich.groupby(Config.STATION_NAME_COL)
                [Config.PRECIPITATION_COL].mean()
                .reset_index()
            )
            # Re-mergeamos con metadata para obtener Municipio y Altitud
            df_relacion = df_relacion.merge(
                gdf_filtered[[Config.STATION_NAME_COL, Config.ALTITUDE_COL, Config.MUNICIPALITY_COL]].drop_duplicates(), 
                on=Config.STATION_NAME_COL, 
                how='left'
            )
            
            fig_relacion = px.scatter(df_relacion, x=Config.ALTITUDE_COL, y=Config.PRECIPITATION_COL,
                                    color=Config.STATION_NAME_COL,
                                    title='Relaci贸n entre Precipitaci贸n Media Anual y Altitud',
                                    labels={Config.ALTITUDE_COL: 'Altitud (m)', Config.PRECIPITATION_COL: 'Precipitaci贸n Media Anual (mm)'},
                                    hover_data=[Config.MUNICIPALITY_COL]
                                    )
            fig_relacion.update_layout(height=500)
            st.plotly_chart(fig_relacion, width='stretch')
        else:
            st.info("No hay datos de altitud o precipitaci贸n disponibles para analizar la relaci贸n.")

    # 7. SERIE REGIONAL
    with sub_tab_regional:
        st.subheader("Serie de Tiempo Promedio Regional (M煤ltiples Estaciones)")
        if not stations_for_analysis:
            st.warning("Seleccione una o m谩s estaciones en el panel lateral para calcular la serie regional.")
        elif df_monthly_rich.empty: # <-- USAR df_monthly_rich
            st.warning("No hay datos mensuales para las estaciones seleccionadas para calcular la serie regional.")
        else:
            with st.spinner("Calculando serie de tiempo regional..."):
                df_regional_avg = df_monthly_rich.groupby(Config.DATE_COL)[Config.PRECIPITATION_COL].mean().reset_index() # <-- USAR df_monthly_rich
                df_regional_avg.rename(columns={Config.PRECIPITATION_COL: 'Precipitaci贸n Promedio'}, inplace=True)
                
                show_individual = False
                if len(stations_for_analysis) > 1:
                    show_individual = st.checkbox("Superponer estaciones individuales", value=False)
                    
                fig_regional = go.Figure()
                if show_individual and len(stations_for_analysis) <= 10:
                    for station in stations_for_analysis:
                        df_s = df_monthly_rich[df_monthly_rich[Config.STATION_NAME_COL] == station] # <-- USAR df_monthly_rich
                        fig_regional.add_trace(go.Scatter(
                            x=df_s[Config.DATE_COL], y=df_s[Config.PRECIPITATION_COL], mode='lines',
                            name=station, line=dict(color='rgba(128, 128, 128, 0.5)', width=1.5),
                            showlegend=True
                        ))
                elif show_individual:
                    st.info("Demasiadas estaciones seleccionadas para superponer (>10). Mostrando solo el promedio regional.")
                    
                fig_regional.add_trace(go.Scatter(
                    x=df_regional_avg[Config.DATE_COL], y=df_regional_avg['Precipitaci贸n Promedio'],
                    mode='lines', name='Promedio Regional', line=dict(color='#1f77b4', width=3)
                ))
                fig_regional.update_layout(
                    title=f'Serie de Tiempo Promedio Regional ({len(stations_for_analysis)} Estaciones)',
                    xaxis_title="Fecha", yaxis_title="Precipitaci贸n Mensual (mm)", height=550
                )
                st.plotly_chart(fig_regional, width='stretch')
                
                with st.expander("Ver Datos de la Serie Regional Promedio"):
                    df_regional_avg_display = df_regional_avg.rename(columns={'Precipitaci贸n Promedio': 'Precipitaci贸n Promedio Regional (mm)'})
                    st.dataframe(df_regional_avg_display.round(1), width='stretch')


def display_advanced_maps_tab(gdf_filtered, stations_for_analysis, df_anual_melted, df_monthly_filtered):
    st.header("Mapas Avanzados")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
    
    tab_names = ["Animaci贸n GIF (Antioquia)", "Visualizaci贸n Temporal", "Gr谩fico de Carrera",
                 "Mapa Animado", "Comparaci贸n de Mapas", "Interpolaci贸n Comparativa"]
    gif_tab, temporal_tab, race_tab, anim_tab, compare_tab, kriging_tab = st.tabs(tab_names)

    # modules/visualizer.py

# ... (dentro de la funci贸n display_advanced_maps_tab)

    with gif_tab:
        st.subheader("Distribuci贸n Espacio-Temporal de la Lluvia en Antioquia")

        col_controls, col_gif = st.columns([1, 3])
    
        with col_controls:
            if st.button(" Reiniciar Animaci贸n", key="reset_gif_button"):
                # Incrementar la clave en session_state para forzar la recarga
                st.session_state.gif_reload_key += 1
                st.rerun()

        with col_gif:
            gif_path = Config.GIF_PATH  # "assets/PPAM.gif"
            if os.path.exists(gif_path):
                try:
                    st.image(gif_path, caption="Animaci贸n PPAM", width=600)
                        
                except Exception as e:
                    st.error(f"Ocurri贸 un error al intentar mostrar el GIF con st.image: {e}")
            else:
                st.error(f"No se pudo encontrar el archivo GIF en la ruta especificada: {gif_path}")
        
    with temporal_tab:
        st.subheader("Explorador Anual de Precipitaci贸n")
        df_anual_melted_non_na = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not df_anual_melted_non_na.empty:
            all_years_int = sorted(df_anual_melted_non_na[Config.YEAR_COL].unique())
            controls_col, map_col = st.columns([1, 3])
            with controls_col:
                st.markdown("##### Opciones de Visualizaci贸n")
                selected_base_map_config, selected_overlays_config = display_map_controls(st, "temporal")
                selected_year = None
                if len(all_years_int) > 1:
                    selected_year = st.slider('Seleccione un A帽o para Explorar',
                                             min_value=min(all_years_int),
                                             max_value=max(all_years_int),
                                             value=min(all_years_int),
                                             key="temporal_year_slider")
                elif len(all_years_int) == 1:
                    selected_year = all_years_int[0]
                    st.info(f"Mostrando 煤nico a帽o disponible: {selected_year}")
                    
                if selected_year:
                    st.markdown(f"#### Resumen del A帽o: {selected_year}")
                    df_year_filtered = df_anual_melted_non_na[df_anual_melted_non_na[Config.YEAR_COL] == selected_year]
                    if not df_year_filtered.empty:
                        num_stations = len(df_year_filtered)
                        st.metric("Estaciones con Datos", num_stations)
                        if num_stations > 1:
                            st.metric("Promedio Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].mean():.0f} mm")
                            st.metric("M谩ximo Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].max():.0f} mm")
                        else:
                            st.metric("Precipitaci贸n Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].iloc[0]:.0f} mm")

            with map_col:
                if selected_year:
                    m_temporal = create_folium_map([4.57, -74.29], 5, selected_base_map_config, selected_overlays_config)
                    df_year_filtered = df_anual_melted_non_na[df_anual_melted_non_na[Config.YEAR_COL] == selected_year]
                    
                    if not df_year_filtered.empty:
                        cols_to_merge = [
                            Config.STATION_NAME_COL, Config.LATITUDE_COL, Config.LONGITUDE_COL,
                            Config.MUNICIPALITY_COL, Config.ALTITUDE_COL, 'geometry'
                        ]
                        df_map_data = pd.merge(
                            df_year_filtered,
                            gdf_filtered[cols_to_merge].drop_duplicates(),
                            on=Config.STATION_NAME_COL, how="inner"
                        )
                        
                        if not df_map_data.empty:
                            min_val, max_val = df_anual_melted_non_na[Config.PRECIPITATION_COL].min(), df_anual_melted_non_na[Config.PRECIPITATION_COL].max()
                            if min_val >= max_val: max_val = min_val + 1
                            
                            colormap = cm.LinearColormap(colors=plt.cm.viridis.colors, vmin=min_val, vmax=max_val)
                            
                            for _, row in df_map_data.iterrows():
                                popup_object = generate_station_popup_html(row, df_anual_melted,
                                                                           include_chart=False, 
                                                                           df_monthly_filtered=df_monthly_filtered)
                                folium.CircleMarker(
                                    location=[row['geometry'].y, row['geometry'].x], radius=5,
                                    color=colormap(row[Config.PRECIPITATION_COL]), fill=True,
                                    fill_color=colormap(row[Config.PRECIPITATION_COL]), fill_opacity=0.8,
                                    tooltip=row[Config.STATION_NAME_COL], popup=popup_object
                                ).add_to(m_temporal)
                            
                            temp_gdf = gpd.GeoDataFrame(df_map_data, geometry='geometry', crs=gdf_filtered.crs)
                            if not temp_gdf.empty:
                                bounds = temp_gdf.total_bounds
                                if np.all(np.isfinite(bounds)):
                                    m_temporal.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])
                                    
                            folium.LayerControl().add_to(m_temporal)
                            folium_static(m_temporal, height=700, width="100%")
                        else:
                            st.warning("No hay datos de estaciones v谩lidos para el a帽o seleccionado en el mapa.")
                    else:
                        st.info("No hay datos para el a帽o seleccionado.")
                else:
                    st.warning("No hay a帽os con datos v谩lidos en el rango seleccionado.")
        else:
            st.warning("No hay datos anuales para la visualizaci贸n temporal.")

    with race_tab:
        st.subheader("Ranking Anual de Precipitaci贸n por Estaci贸n")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not df_anual_valid.empty:
            fig_racing = px.bar(
                df_anual_valid, x=Config.PRECIPITATION_COL, y=Config.STATION_NAME_COL,
                animation_frame=Config.YEAR_COL, orientation='h',
                labels={Config.PRECIPITATION_COL: 'Precipitaci贸n Anual (mm)', Config.STATION_NAME_COL: 'Estaci贸n'},
                title="Evoluci贸n de Precipitaci贸n Anual por Estaci贸n"
            )
            fig_racing.update_layout(
                height=max(600, len(stations_for_analysis) * 35),
                yaxis=dict(categoryorder='total ascending')
            )
            st.plotly_chart(fig_racing, width='stretch')
        else:
            st.warning("No hay suficientes datos anuales con los filtros actuales para generar el Gr谩fico de Carrera.")

    with anim_tab:
        st.subheader("Mapa Animado de Precipitaci贸n Anual")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not df_anual_valid.empty:
            df_anim_merged = pd.merge(
                df_anual_valid,
                gdf_filtered.drop_duplicates(subset=[Config.STATION_NAME_COL]),
                on=Config.STATION_NAME_COL,
                how="inner"
            )
            if not df_anim_merged.empty:
                fig_mapa_animado = px.scatter_geo(
                    df_anim_merged,
                    lat=Config.LATITUDE_COL, lon=Config.LONGITUDE_COL,
                    color=Config.PRECIPITATION_COL, size=Config.PRECIPITATION_COL,
                    hover_name=Config.STATION_NAME_COL,
                    animation_frame=Config.YEAR_COL,
                    projection='natural earth',
                    title='Precipitaci贸n Anual por Estaci贸n'
                )
                fig_mapa_animado.update_geos(fitbounds="locations", visible=True)
                st.plotly_chart(fig_mapa_animado, width='stretch')
            else:
                st.warning("No se pudieron combinar los datos anuales con la informaci贸n geogr谩fica de las estaciones.")
        else:
            st.warning("No hay suficientes datos anuales con los filtros actuales para generar el Mapa Animado.")

    with compare_tab:
        st.subheader("Comparaci贸n de Mapas Anuales")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        all_years = sorted(df_anual_valid[Config.YEAR_COL].unique())
        
        if len(all_years) > 1:
            control_col, map_col1, map_col2 = st.columns([1, 2, 2])
            with control_col:
                st.markdown("##### Controles de Mapa")
                selected_base_map_config, selected_overlays_config = display_map_controls(st, "compare")
                min_year, max_year = int(all_years[0]), int(all_years[-1])
                st.markdown("**Mapa 1**")
                year1 = st.selectbox("Seleccione el primer a帽o", options=all_years, index=len(all_years)-1, key="compare_year1")
                st.markdown("**Mapa 2**")
                year2 = st.selectbox("Seleccione el segundo a帽o", options=all_years, index=len(all_years)-2, key="compare_year2")
                min_precip, max_precip = int(df_anual_valid[Config.PRECIPITATION_COL].min()), int(df_anual_valid[Config.PRECIPITATION_COL].max())
                if min_precip >= max_precip: max_precip = min_precip + 1
                color_range = st.slider("Rango de Escala de Color (mm)", min_precip, max_precip, (min_precip, max_precip), key="color_compare")
                
                # Colormap consistente para ambos mapas
                colormap = cm.LinearColormap(
                    colors=plt.cm.viridis.colors,
                    vmin=color_range[0], vmax=color_range[1]
                )
            
            def create_compare_map(data, year, col, gdf_stations_info):
                col.markdown(f"**Precipitaci贸n en {year}**")
                m = create_folium_map([6.24, -75.58], 6, selected_base_map_config, selected_overlays_config)
                if not data.empty:
                    data_with_geom = pd.merge(data, gdf_stations_info, on=Config.STATION_NAME_COL)
                    gpd_data = gpd.GeoDataFrame(data_with_geom, geometry='geometry', crs=gdf_stations_info.crs)
                    for _, row in gpd_data.iterrows():
                        if pd.notna(row[Config.PRECIPITATION_COL]):
                            popup_object = generate_station_popup_html(row, df_anual_melted)
                            folium.CircleMarker(
                                location=[row['geometry'].y, row['geometry'].x], radius=5,
                                color=colormap(row[Config.PRECIPITATION_COL]),
                                fill=True, fill_color=colormap(row[Config.PRECIPITATION_COL]), fill_opacity=0.8,
                                tooltip=row[Config.STATION_NAME_COL], popup=popup_object
                            ).add_to(m)
                    if not gpd_data.empty:
                        m.fit_bounds(gpd_data.total_bounds.tolist())
                    folium.LayerControl().add_to(m)
                with col:
                    folium_static(m, height=450, width="100%")
                    
            gdf_geometries = gdf_filtered[[Config.STATION_NAME_COL, 'geometry']].drop_duplicates()
            data_year1 = df_anual_valid[df_anual_valid[Config.YEAR_COL] == year1]
            data_year2 = df_anual_valid[df_anual_valid[Config.YEAR_COL] == year2]
            
            create_compare_map(data_year1, year1, map_col1, gdf_geometries)
            create_compare_map(data_year2, year2, map_col2, gdf_geometries)
        else:
            st.warning("Se necesitan datos de al menos dos a帽os diferentes para generar la Comparaci贸n de Mapas.")

    with kriging_tab:
        st.subheader("Comparaci贸n de Superficies de Interpolaci贸n Anual")
        df_anual_non_na = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not stations_for_analysis:
            st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        elif df_anual_non_na.empty or len(df_anual_non_na[Config.YEAR_COL].unique()) == 0:
            st.warning("No hay suficientes datos anuales para realizar la interpolaci贸n.")
        else:
            min_year, max_year = int(df_anual_non_na[Config.YEAR_COL].min()), int(df_anual_non_na[Config.YEAR_COL].max())
            control_col, map_col1, map_col2 = st.columns([1, 2, 2])
            
            with control_col:
                st.markdown("#### Controles de los Mapas")
                interpolation_methods = ["Kriging Ordinario", "IDW", "Spline (Thin Plate)"]
                if Config.ELEVATION_COL in gdf_filtered.columns:
                    interpolation_methods.insert(1, "Kriging con Deriva Externa (KED)")
                
                st.markdown("**Mapa 1**")
                year1 = st.slider("Seleccione el a帽o", min_year, max_year, max_year, key="interp_year1")
                method1 = st.selectbox("M茅todo de interpolaci贸n", options=interpolation_methods, key="interp_method1")
                variogram_model1 = None
                if "Kriging" in method1:
                    variogram_options = ['linear', 'spherical', 'exponential', 'gaussian']
                    variogram_model1 = st.selectbox("Modelo de Variograma para Mapa 1", variogram_options, key="var_model_1")
                
                st.markdown("---")
                year2 = st.slider("Seleccione el a帽o", min_year, max_year, max_year - 1 if max_year > min_year else max_year, key="interp_year2")
                method2 = st.selectbox("M茅todo de interpolaci贸n", options=interpolation_methods, index=1, key="interp_method2")
                variogram_model2 = None
                if "Kriging" in method2:
                    variogram_options = ['linear', 'spherical', 'exponential', 'gaussian']
                    variogram_model2 = st.selectbox("Modelo de Variograma para Mapa 2", variogram_options, key="var_model_2")
            
            # Las funciones de interpolaci贸n se asumen que existen en modules.interpolation
            fig1, fig_var1, error1 = create_interpolation_surface(year1, method1, variogram_model1, gdf_filtered, df_anual_non_na)
            fig2, fig_var2, error2 = create_interpolation_surface(year2, method2, variogram_model2, gdf_filtered, df_anual_non_na)
            
            with map_col1:
                if fig1: st.plotly_chart(fig1, width='stretch')
                else: st.info(error1)
            with map_col2:
                if fig2: st.plotly_chart(fig2, width='stretch')
                else: st.info(error2)
                
            st.markdown("---")
            st.markdown("##### Variogramas de los Mapas")
            col3, col4 = st.columns(2)
            
            with col3:
                if fig_var1:
                    buf = io.BytesIO()
                    fig_var1.savefig(buf, format="png")
                    st.pyplot(fig_var1)
                    st.download_button(
                        label="Descargar Variograma 1 (PNG)", data=buf.getvalue(),
                        file_name=f"variograma_1_{year1}_{method1}_{variogram_model1}.png", mime="image/png"
                    )
                    plt.close(fig_var1)
                else:
                    st.info("El variograma no est谩 disponible para este m茅todo o no hay suficientes datos.")
            
            with col4:
                if fig_var2:
                    buf = io.BytesIO()
                    fig_var2.savefig(buf, format="png")
                    st.pyplot(fig_var2)
                    st.download_button(
                        label="Descargar Variograma 2 (PNG)", data=buf.getvalue(),
                        file_name=f"variograma_2_{year2}_{method2}_{variogram_model2}.png", mime="image/png"
                    )
                    plt.close(fig_var2)
                else:
                    st.info("El variograma no est谩 disponible para este m茅todo o no hay suficientes datos.")


def display_drought_analysis_tab(df_monthly_filtered, gdf_filtered, stations_for_analysis):
    st.header("An谩lisis de Extremos Hidrol贸gicos")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
        
    percentile_sub_tab, indices_sub_tab = st.tabs(["An谩lisis por Percentiles", "ndices de Sequ铆a (SPI/SPEI)"])
    
    with percentile_sub_tab:
        st.subheader("An谩lisis de Eventos Extremos por Percentiles Mensuales")
        station_to_analyze_perc = st.selectbox(
            "Seleccione una estaci贸n para el an谩lisis:",
            options=sorted(stations_for_analysis),
            key="percentile_station_select"
        )
        if station_to_analyze_perc:
            display_percentile_analysis_subtab(df_monthly_filtered, station_to_analyze_perc)
            
    with indices_sub_tab:
        st.subheader("An谩lisis con ndices Estandarizados")
        col1_idx, col2_idx = st.columns([1, 2])
        with col1_idx:
            index_type = st.radio("Seleccione el 铆ndice a Calcular:", ("SPI", "SPEI"))
            station_to_analyze_idx = st.selectbox("Seleccione una estaci贸n para el an谩lisis:",
                                                  options=sorted(stations_for_analysis),
                                                  key="index_station_select")
            index_window = st.select_slider("Seleccione la escala de tiempo (meses):",
                                            options=[3, 6, 9, 12, 24], value=12, key="index_window_slider",
                                            help="Escalas cortas (3m) reflejan sequ铆as agr铆colas. Escalas largas (12-24m) reflejan sequ铆as hidrol贸gicas.")
            
        if station_to_analyze_idx:
            df_station_idx = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station_to_analyze_idx].copy()
            df_station_idx = df_station_idx.set_index(Config.DATE_COL).sort_index()
            index_values = pd.Series(dtype=float)
            
            with col2_idx:
                if index_type == "SPI":
                    precip_series = df_station_idx[Config.PRECIPITATION_COL]
                    if len(precip_series.dropna()) < index_window * 2:
                        st.warning(f"No hay suficientes datos ({len(precip_series.dropna())} meses) para calcular el SPI-{index_window}.")
                    else:
                        with st.spinner(f"Calculando SPI-{index_window}..."):
                            index_values = calculate_spi(precip_series, index_window)
                            
                elif index_type == "SPEI":
                    if Config.ET_COL not in df_station_idx.columns or df_station_idx[Config.ET_COL].isnull().all():
                        st.error(f"No hay datos de evapotranspiraci贸n ('{Config.ET_COL}') disponibles para esta estaci贸n. No se puede calcular el SPEI.")
                    else:
                        precip_series = df_station_idx[Config.PRECIPITATION_COL]
                        et_series = df_station_idx[Config.ET_COL]
                        if len(precip_series.dropna()) < index_window * 2 or len(et_series.dropna()) < index_window * 2:
                            st.warning(f"No hay suficientes datos de precipitaci贸n o evapotranspiraci贸n para calcular el SPEI-{index_window}.")
                        else:
                            with st.spinner(f"Calculando SPEI-{index_window}..."):
                                index_values = calculate_spei(precip_series, et_series, index_window)
            
            if not index_values.empty:
                df_plot = pd.DataFrame({'index_val': index_values}).dropna()
                conditions = [
                    df_plot['index_val'] <= -2.0, (df_plot['index_val'] > -2.0) & (df_plot['index_val'] <= -1.5),
                    (df_plot['index_val'] > -1.5) & (df_plot['index_val'] <= -1.0), (df_plot['index_val'] > -1.0) & (df_plot['index_val'] < 1.0),
                    (df_plot['index_val'] >= 1.0) & (df_plot['index_val'] < 1.5), (df_plot['index_val'] >= 1.5) & (df_plot['index_val'] < 2.0),
                    df_plot['index_val'] >= 2.0
                ]
                colors = ['#b2182b', '#ef8a62', '#fddbc7', '#d1e5f0', '#92c5de', '#4393c3', '#2166ac']
                df_plot['color'] = np.select(conditions, colors, default='grey')
                fig = go.Figure()
                fig.add_trace(go.Bar(x=df_plot.index, y=df_plot['index_val'], marker_color=df_plot['color'], name=index_type))
                fig.update_layout(title=f"Indice {index_type}-{index_window} para {station_to_analyze_idx}",
                                  yaxis_title=f"Valor {index_type}", xaxis_title="Fecha", height=600)
                
                with col2_idx:
                    st.plotly_chart(fig, width='stretch')
                with st.expander(f"Ver tabla de datos {index_type}"):
                    st.dataframe(df_plot[['index_val']].rename(columns={'index_val': index_type}).style.format("{:.2f}"))


def display_anomalies_tab(df_long, df_monthly_filtered, stations_for_analysis):
    st.header("An谩lisis de Anomal铆as de Precipitaci贸n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
        
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci贸n: {stations_for_analysis[0]}"
    if df_long is None or df_long.empty:
        st.warning("No se puede realizar el an谩lisis de anomal铆as. El DataFrame base no est谩 disponible.")
        return
        
    df_anomalias = calculate_monthly_anomalies(df_monthly_filtered, df_long)
    if st.session_state.get('exclude_na', False):
        df_anomalias.dropna(subset=['anomalia'], inplace=True)
        
    if df_anomalias.empty or df_anomalias['anomalia'].isnull().all():
        st.warning("No hay suficientes datos hist贸ricos para calcular y mostrar las anomal铆as con los filtros actuales.")
        return
        
    anom_graf_tab, anom_fase_tab, anom_extremos_tab = st.tabs(["Gr谩fico de Anomalias", "Anomal铆as por Fase ENSO", "Tabla de Eventos Extremos"])
    
    with anom_graf_tab:
        df_plot = df_anomalias.groupby(Config.DATE_COL).agg(
            anomalia=('anomalia', 'mean'),
            anomalia_oni=(Config.ENSO_ONI_COL, 'first')
        ).reset_index()
        fig = create_anomaly_chart(df_plot)
        st.plotly_chart(fig, width='stretch')
        
    with anom_fase_tab:
        if Config.ENSO_ONI_COL in df_anomalias.columns:
            df_anomalias_enso = df_anomalias.dropna(subset=[Config.ENSO_ONI_COL]).copy()
            conditions = [df_anomalias_enso[Config.ENSO_ONI_COL] >= 0.5,
                          df_anomalias_enso[Config.ENSO_ONI_COL] <= -0.5]
            phases = ['El Ni帽o', 'La Ni帽a']
            df_anomalias_enso['enso_fase'] = np.select(conditions, phases, default='Neutral')
            fig_box = px.box(df_anomalias_enso, x='enso_fase', y='anomalia', color='enso_fase',
                            title="Distribuci贸n de Anomal铆as de Precipitaci贸n por Fase ENSO",
                            labels={'anomalia': 'Anomal铆a de Precipitaci贸n (mm)', 'enso_fase': 'Fase ENSO'},
                            points='all')
            st.plotly_chart(fig_box, width='stretch')
        else:
            st.warning("La columna 'anomalia_oni' no est谩 disponible para este an谩lisis.")

    with anom_extremos_tab:
        st.subheader("Eventos Mensuales Extremos (Basado en Anomal铆as)")
        df_extremos = df_anomalias.dropna(subset=['anomalia']).copy()
        df_extremos['fecha'] = df_extremos[Config.DATE_COL].dt.strftime('%Y-%m')
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### 10 Meses m谩s Secos")
            secos = df_extremos.nsmallest(10, 'anomalia')[['fecha', Config.STATION_NAME_COL,
                                                           'anomalia', Config.PRECIPITATION_COL, 'precip_promedio_mes']]
            st.dataframe(secos.rename(columns={Config.STATION_NAME_COL: 'Estaci贸n', 'anomalia': 'Anomal铆a (mm)', Config.PRECIPITATION_COL: 'Ppt. (mm)', 'precip_promedio_mes': 'Ppt. Media (mm)'}).round(0), width='stretch')
        with col2:
            st.markdown("##### 10 Meses m谩s H煤medos")
            humedos = df_extremos.nlargest(10, 'anomalia')[['fecha', Config.STATION_NAME_COL,
                                                           'anomalia', Config.PRECIPITATION_COL, 'precip_promedio_mes']]
            st.dataframe(humedos.rename(columns={Config.STATION_NAME_COL: 'Estaci贸n', 'anomalia': 'Anomal铆a (mm)', Config.PRECIPITATION_COL: 'Ppt. (mm)', 'precip_promedio_mes': 'Ppt. Media (mm)'}).round(0), width='stretch')


def display_stats_tab(df_long, df_anual_melted, df_monthly_filtered, stations_for_analysis, gdf_filtered):
    st.header("Estad铆sticas de Precipitaci贸n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
        
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci贸n: {stations_for_analysis[0]}"
    
    matriz_tab, resumen_mensual_tab, sintesis_tab = st.tabs(["Matriz de Disponibilidad", "Resumen Mensual", "S铆ntesis General"])
    
    with matriz_tab:
        st.subheader("Matriz de Disponibilidad de Datos Anual")
        df_base_raw = st.session_state.get('df_monthly_processed', pd.DataFrame())
        if df_base_raw.empty:
            st.warning("Los datos procesados no est谩n disponibles en la sesi贸n.")
            return
            
        df_base_filtered = df_base_raw[df_base_raw[Config.STATION_NAME_COL].isin(stations_for_analysis)].copy()
        
        if st.session_state.analysis_mode == "Completar series (interpolaci贸n)":
            view_mode = st.radio("Seleccione la vista de la matriz:",
                                 ("Porcentaje de Datos Originales",
                                  "Porcentaje de Datos Totales (Original + Completado)",
                                  "Porcentaje de Datos Completados (Interpolados)"),
                                 horizontal=True)
            if view_mode == "Porcentaje de Datos Completados (Interpolados)":
                df_counts = df_base_filtered[df_base_filtered[Config.ORIGIN_COL] == 'Completado'].groupby(
                    [Config.STATION_NAME_COL, Config.YEAR_COL]
                ).size().reset_index(name='count_completed')
                df_counts['porc_value'] = (df_counts['count_completed'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Reds"
                title_text = "Porcentaje de Datos Completados (Interpolados)"
            elif view_mode == "Porcentaje de Datos Totales (Original + Completado)":
                df_counts = df_base_filtered.groupby(
                    [Config.STATION_NAME_COL, Config.YEAR_COL]
                ).size().reset_index(name='count_total')
                df_counts['porc_value'] = (df_counts['count_total'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Blues"
                title_text = "Disponibilidad de Datos Totales (Original + Completado)"
            else: # Porcentaje de Datos Originales
                df_original_filtered = df_long[df_long[Config.STATION_NAME_COL].isin(stations_for_analysis)]
                df_counts = df_original_filtered.groupby(
                    [Config.STATION_NAME_COL, Config.YEAR_COL]
                ).size().reset_index(name='count_original')
                df_counts['porc_value'] = (df_counts['count_original'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Greens"
                title_text = "Disponibilidad de Datos Originales"
        else: # Usar datos originales (Modo por defecto)
            df_base_filtered = df_long[df_long[Config.STATION_NAME_COL].isin(stations_for_analysis)].copy()
            df_counts = df_base_filtered.groupby(
                [Config.STATION_NAME_COL, Config.YEAR_COL]
            ).size().reset_index(name='count_total')
            df_counts['porc_value'] = (df_counts['count_total'] / 12) * 100
            heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values='porc_value').fillna(0)
            color_scale = "Greens"
            title_text = "Disponibilidad de Datos Originales"
            
        if not heatmap_df.empty:
            avg_availability = heatmap_df.stack().mean()
            logo_col, metric_col = st.columns([1, 5])
            with logo_col:
                if os.path.exists(Config.LOGO_PATH): 
                    try:
                        with open(Config.LOGO_PATH, "rb") as f:
                            logo_bytes = f.read()
                        st.image(logo_bytes, width=50)
                    except Exception:
                        pass
            with metric_col: st.metric(label=f"Disponibilidad Promedio Anual ({title_text})",
                                     value=f"{avg_availability:.1f}%")
            styled_df = heatmap_df.style.background_gradient(cmap=color_scale, axis=None, vmin=0,
                                                               vmax=100).format("{:.0f}%", na_rep="-").set_table_styles([
                {'selector': 'th', 'props': [('background-color', '#333'), ('color', 'white'), ('font-size', '14px')]},
                {'selector': 'td', 'props': [('text-align', 'center')]}])
            st.dataframe(styled_df)
        else:
            st.info("No hay datos para mostrar en la matriz con la selecci贸n actual.")

    with resumen_mensual_tab:
        st.subheader("Resumen de Estad铆sticas Mensuales por Estaci贸n")
        if not df_monthly_filtered.empty:
            summary_data = []
            for station_name, group in df_monthly_filtered.groupby(Config.STATION_NAME_COL):
                max_row = group.loc[group[Config.PRECIPITATION_COL].idxmax()]
                min_row = group.loc[group[Config.PRECIPITATION_COL].idxmin()]
                summary_data.append({
                    "Estaci贸n": station_name,
                    "Ppt. M谩xima Mensual (mm)": max_row[Config.PRECIPITATION_COL],
                    "Fecha M谩xima": max_row[Config.DATE_COL].strftime('%Y-%m'),
                    "Ppt. M铆nima Mensual (mm)": min_row[Config.PRECIPITATION_COL],
                    "Fecha M铆nima": min_row[Config.DATE_COL].strftime('%Y-%m'),
                    "Promedio Mensual (mm)": group[Config.PRECIPITATION_COL].mean()
                })
            summary_df = pd.DataFrame(summary_data)
            st.dataframe(summary_df.round(0), width='stretch')
        else:
            st.info("No hay datos para mostrar el resumen mensual.")

    with sintesis_tab:
        st.subheader("S铆ntesis General de Precipitaci贸n")
        
        # 1. Preparaci贸n de Datos y validaci贸n
        if not df_monthly_filtered.empty and not df_anual_melted.empty:
            df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
            df_monthly_valid = df_monthly_filtered.dropna(subset=[Config.PRECIPITATION_COL])

            if not df_anual_valid.empty and not df_monthly_valid.empty and not gdf_filtered.empty:
                
                # --- A. EXTREMOS DE PRECIPITACIN ---
                max_monthly_row = df_monthly_valid.loc[df_monthly_valid[Config.PRECIPITATION_COL].idxmax()]
                min_monthly_row = df_monthly_valid.loc[df_monthly_valid[Config.PRECIPITATION_COL].idxmin()]
                max_annual_row = df_anual_valid.loc[df_anual_valid[Config.PRECIPITATION_COL].idxmax()]
                min_annual_row = df_anual_valid.loc[df_anual_valid[Config.PRECIPITATION_COL].idxmin()]

                # --- B. PROMEDIOS REGIONALES/CLIMATOLGICOS ---
                df_yearly_avg = df_anual_valid.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                year_max_avg = df_yearly_avg.loc[df_yearly_avg[Config.PRECIPITATION_COL].idxmax()]
                year_min_avg = df_yearly_avg.loc[df_yearly_avg[Config.PRECIPITATION_COL].idxmin()]

                df_monthly_avg = df_monthly_valid.groupby(Config.MONTH_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                month_max_avg = df_monthly_avg.loc[df_monthly_avg[Config.PRECIPITATION_COL].idxmax()][Config.MONTH_COL]
                month_min_avg = df_monthly_avg.loc[df_monthly_avg[Config.PRECIPITATION_COL].idxmin()][Config.MONTH_COL]
                
                # --- C. EXTREMOS DE ALTITUD ---
                df_stations_valid = gdf_filtered.dropna(subset=[Config.ALTITUDE_COL])
                if not df_stations_valid.empty:
                    station_max_alt = df_stations_valid.loc[df_stations_valid[Config.ALTITUDE_COL].idxmax()]
                    station_min_alt = df_stations_valid.loc[df_stations_valid[Config.ALTITUDE_COL].idxmin()]
                else:
                    station_max_alt = None
                    station_min_alt = None

                # --- D. CLCULO DE TENDENCIAS (SEN'S SLOPE) ---
                trend_results = []
                for station in stations_for_analysis:
                    station_data = df_anual_valid[df_anual_valid[Config.STATION_NAME_COL] == station].copy()
                    if len(station_data) >= 4:
                        mk_result_table = mk.original_test(station_data[Config.PRECIPITATION_COL])
                        trend_results.append({
                            Config.STATION_NAME_COL: station,
                            'slope_sen': mk_result_table.slope,
                            'p_value': mk_result_table.p
                        })

                df_trends = pd.DataFrame(trend_results)
                max_pos_trend_row = None
                min_neg_trend_row = None
                
                if not df_trends.empty:
                    df_pos_trends = df_trends[df_trends['slope_sen'] > 0]
                    df_neg_trends = df_trends[df_trends['slope_sen'] < 0]

                    if not df_pos_trends.empty:
                        max_pos_trend_row = df_pos_trends.loc[df_pos_trends['slope_sen'].idxmax()]
                    
                    if not df_neg_trends.empty:
                        min_neg_trend_row = df_neg_trends.loc[df_neg_trends['slope_sen'].idxmin()]
                
                meses_map = {1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril', 5: 'Mayo', 6: 'Junio', 7: 'Julio',
                             8: 'Agosto', 9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'}

                # --- DISPLAY DE RESULTADOS ---
                st.markdown("#### 1. Extremos de Precipitaci贸n")
                
                col1, col2, col3, col4 = st.columns(4)
                
                # MXIMA PRECIPITACIN ANUAL
                with col1:
                    st.metric(
                        "M谩xima Ppt. Anual",
                        f"{max_annual_row[Config.PRECIPITATION_COL]:.0f} mm",
                        f"{max_annual_row[Config.STATION_NAME_COL]} ({int(max_annual_row[Config.YEAR_COL])})"
                    )
                # MNIMA PRECIPITACIN ANUAL
                with col2:
                    st.metric(
                        "M铆nima Ppt. Anual",
                        f"{min_annual_row[Config.PRECIPITATION_COL]:.0f} mm",
                        f"{min_annual_row[Config.STATION_NAME_COL]} ({int(min_annual_row[Config.YEAR_COL])})"
                    )
                # MXIMA PRECIPITACIN MENSUAL
                with col3:
                    st.metric(
                        "M谩xima Ppt. Mensual",
                        f"{max_monthly_row[Config.PRECIPITATION_COL]:.0f} mm",
                        f"{max_monthly_row[Config.STATION_NAME_COL]} ({meses_map.get(max_monthly_row[Config.MONTH_COL])} {max_monthly_row[Config.DATE_COL].year})"
                    )
                # MNIMA PRECIPITACIN MENSUAL
                with col4:
                    st.metric(
                        "M铆nima Ppt. Mensual",
                        f"{min_monthly_row[Config.PRECIPITATION_COL]:.0f} mm",
                        f"{min_monthly_row[Config.STATION_NAME_COL]} ({meses_map.get(min_monthly_row[Config.MONTH_COL])} {min_monthly_row[Config.DATE_COL].year})"
                    )
                
                st.markdown("#### 2. Promedios Hist贸ricos y Climatol贸gicos")

                col5, col6, col7 = st.columns(3)

                # AO MS LLUVIOSO (PROMEDIO ANUAL)
                with col5:
                    st.metric(
                        "A帽o m谩s Lluvioso (Promedio Regional)",
                        f"{year_max_avg[Config.PRECIPITATION_COL]:.0f} mm",
                        f"A帽o: {int(year_max_avg[Config.YEAR_COL])}"
                    )
                
                # AO MENOS LLUVIOSO (PROMEDIO ANUAL)
                with col6:
                    st.metric(
                        "A帽o menos Lluvioso (Promedio Regional)",
                        f"{year_min_avg[Config.PRECIPITATION_COL]:.0f} mm",
                        f"A帽o: {int(year_min_avg[Config.YEAR_COL])}"
                    )
                
                # MES MS LLUVIOSO / MENOS LLUVIOSO
                with col7:
                    st.metric(
                        "Mes Climatol贸gico m谩s Lluvioso",
                        f"{df_monthly_avg.loc[df_monthly_avg[Config.MONTH_COL] == month_max_avg, Config.PRECIPITATION_COL].iloc[0]:.0f} mm",
                        f"{meses_map.get(month_max_avg)} (M铆n: {meses_map.get(month_min_avg)})"
                    )
                
                st.markdown("#### 3. Geograf铆a y Tendencias")

                col8, col9, col10, col11 = st.columns(4)
                
                # ESTACIN MAYOR ALTITUD
                with col8:
                    if station_max_alt is not None:
                        st.metric(
                            "Estaci贸n a Mayor Altitud",
                            f"{station_max_alt[Config.ALTITUDE_COL]:.0f} m",
                            f"{station_max_alt[Config.STATION_NAME_COL]}"
                        )
                    else:
                        st.info("No hay datos de altitud.")
                
                # ESTACIN MENOR ALTITUD
                with col9:
                    if station_min_alt is not None:
                        st.metric(
                            "Estaci贸n a Menor Altitud",
                            f"{station_min_alt[Config.ALTITUDE_COL]:.0f} m",
                            f"{station_min_alt[Config.STATION_NAME_COL]}"
                        )
                    else:
                        st.info("No hay datos de altitud.")
                
                # MAYOR TENDENCIA POSITIVA (Sen's Slope)
                with col10:
                    if max_pos_trend_row is not None:
                        st.metric(
                            "Mayor Tendencia Positiva",
                            f"+{max_pos_trend_row['slope_sen']:.2f} mm/a帽o",
                            f"{max_pos_trend_row[Config.STATION_NAME_COL]} (p={max_pos_trend_row['p_value']:.3f})"
                        )
                    else:
                        st.info("No hay tendencias positivas para mostrar.")
                
                # MAYOR TENDENCIA NEGATIVA (Sen's Slope)
                with col11:
                    if min_neg_trend_row is not None:
                        st.metric(
                            "Mayor Tendencia Negativa",
                            f"{min_neg_trend_row['slope_sen']:.2f} mm/a帽o",
                            f"{min_neg_trend_row[Config.STATION_NAME_COL]} (p={min_neg_trend_row['p_value']:.3f})"
                        )
                    else:
                        st.info("No hay tendencias negativas para mostrar.")

            else:
                st.info("No hay datos anuales, mensuales o geogr谩ficos v谩lidos para mostrar la s铆ntesis.")
        else:
            st.info("No hay datos para mostrar la s铆ntesis general.")


def display_correlation_tab(df_monthly_filtered, stations_for_analysis):
    st.header("An谩lisis de Correlaci贸n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
    
    st.markdown("Esta secci贸n cuantifica la relaci贸n lineal entre la precipitaci贸n y diferentes variables (otras estaciones o indices clim谩ticos) utilizando el coeficiente de correlaci贸n de Pearson.")
    
    enso_corr_tab, station_corr_tab, indices_climaticos_tab = st.tabs(["Correlaci贸n con ENSO (ONI)", "Comparaci贸n entre Estaciones", "Correlaci贸n con Otros ndices"])
    
    with enso_corr_tab:
        if Config.ENSO_ONI_COL not in df_monthly_filtered.columns or df_monthly_filtered[Config.ENSO_ONI_COL].isnull().all():
            st.warning("No se puede realizar el an谩lisis de correlaci贸n con ENSO. La columna 'anomalia_oni' no fue encontrada o no tiene datos en el per铆odo seleccionado.")
            return
            
        st.subheader("Configuraci贸n del An谩lisis de Correlaci贸n con ENSO")
        lag_months = st.slider(
            "Seleccionar desfase temporal (meses)",
            min_value=0, max_value=12, value=0,
            help="Analiza la correlaci贸n de la precipitaci贸n con el ENSO de 'x' meses atr谩s. Un desfase de 3 significa correlacionar la lluvia de hoy con el ENSO de hace 3 meses."
        )
        
        df_corr_analysis = df_monthly_filtered.dropna(subset=[Config.PRECIPITATION_COL, Config.ENSO_ONI_COL])
        if df_corr_analysis.empty:
            st.warning("No hay datos coincidentes entre la precipitaci贸n y el ENSO para la selecci贸n actual.")
            return
            
        analysis_level = st.radio("Nivel de An谩lisis de Correlaci贸n con ENSO", ["Promedio de la selecci贸n", "Por Estaci贸n Individual"], horizontal=True, key="enso_corr_level")
        df_plot_corr = pd.DataFrame()
        title_text = ""
        
        if analysis_level == "Por Estaci贸n Individual":
            station_to_corr = st.selectbox("Seleccione Estaci贸n:",
                                           options=sorted(df_corr_analysis[Config.STATION_NAME_COL].unique()),
                                           key="enso_corr_station")
            if station_to_corr:
                df_plot_corr = df_corr_analysis[df_corr_analysis[Config.STATION_NAME_COL] == station_to_corr].copy()
                title_text = f"Correlaci贸n para la estaci贸n: {station_to_corr}"
        else:
            df_plot_corr = df_corr_analysis.groupby(Config.DATE_COL).agg(
                precipitation=(Config.PRECIPITATION_COL, 'mean'),
                anomalia_oni=(Config.ENSO_ONI_COL, 'first')
            ).reset_index()
            title_text = "Correlaci贸n para el promedio de las estaciones seleccionadas"

        if not df_plot_corr.empty and len(df_plot_corr) > 2:
            if lag_months > 0:
                df_plot_corr['anomalia_oni_shifted'] = df_plot_corr['anomalia_oni'].shift(lag_months)
                df_plot_corr.dropna(subset=['anomalia_oni_shifted'], inplace=True)
                oni_column_to_use = 'anomalia_oni_shifted'
                lag_text = f" (con desfase de {lag_months} meses)"
            else:
                oni_column_to_use = 'anomalia_oni'
                lag_text = ""
                
            corr, p_value = stats.pearsonr(df_plot_corr[oni_column_to_use], df_plot_corr['precipitation'])
            st.subheader(title_text + lag_text)
            
            col1, col2 = st.columns(2)
            col1.metric("Coeficiente de Correlaci贸n (r)", f"{corr:.3f}")
            col2.metric("Significancia (valor p)", f"{p_value:.4f}")
            
            if p_value < 0.05:
                st.success("La correlaci贸n es estad铆sticamente significativa.")
            else:
                st.warning("La correlaci贸n no es estad铆sticamente significativa.")
                
            fig_corr = px.scatter(
                df_plot_corr, x=oni_column_to_use, y='precipitation', trendline='ols',
                title=f"Dispersi贸n: Precipitaci贸n vs. Anomal铆a ONI{lag_text}",
                labels={
                    oni_column_to_use: f'Anomal铆a ONI (掳C) [desfase {lag_months}m]',
                    'precipitation': 'Precipitaci贸n Mensual (mm)'
                }
            )
            st.plotly_chart(fig_corr, width='stretch')

    with station_corr_tab:
        if len(stations_for_analysis) < 2:
            st.info("Seleccione al menos dos estaciones para comparar la correlaci贸n entre ellas.")
        else:
            st.subheader("Correlaci贸n de Precipitaci贸n entre dos Estaciones")
            station_options = sorted(stations_for_analysis)
            col1, col2 = st.columns(2)
            station1_name = col1.selectbox("Estaci贸n 1:", options=station_options, key="corr_station_1")
            station2_name = col2.selectbox("Estaci贸n 2:", options=station_options, index=1 if len(station_options) > 1 else 0, key="corr_station_2")
            
            if station1_name and station2_name and station1_name != station2_name:
                df_station1 = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station1_name][[Config.DATE_COL, Config.PRECIPITATION_COL]]
                df_station2 = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station2_name][[Config.DATE_COL, Config.PRECIPITATION_COL]]
                
                df_merged = pd.merge(df_station1, df_station2, on=Config.DATE_COL, suffixes=('_1', '_2')).dropna()
                df_merged.rename(columns={f'{Config.PRECIPITATION_COL}_1': station1_name, f'{Config.PRECIPITATION_COL}_2': station2_name}, inplace=True)
                
                if not df_merged.empty and len(df_merged) > 2:
                    corr, p_value = stats.pearsonr(df_merged[station1_name], df_merged[station2_name])
                    st.markdown(f"#### Resultados de la correlaci贸n ({station1_name} vs. {station2_name})")
                    st.metric("Coeficiente de Correlaci贸n (r)", f"{corr:.3f}")
                    
                    if p_value < 0.05:
                        st.success(f"La correlaci贸n es estad铆sticamente significativa (p<{p_value:.4f}).")
                    else:
                        st.warning(f"La correlaci贸n no es estad铆sticamente significativa (p>={p_value:.4f}).")
                        
                    slope, intercept, _, _, _ = stats.linregress(df_merged[station1_name], df_merged[station2_name])
                    st.info(f"Ecuaci贸n de regresi贸n: y={slope:.2f}x+{intercept:.2f}")
                    
                    fig_scatter = px.scatter(
                        df_merged, x=station1_name, y=station2_name, trendline='ols',
                        title=f'Dispersi贸n de Precipitaci贸n: {station1_name} vs. {station2_name}',
                        labels={station1_name: f'Precipitaci贸n en {station1_name} (mm)', station2_name: f'Precipitaci贸n en {station2_name} (mm)'}
                    )
                    st.plotly_chart(fig_scatter, width='stretch')
                else:
                    st.warning("No hay suficientes datos superpuestos para calcular la correlaci贸n para las estaciones seleccionadas.")

    with indices_climaticos_tab:
        st.subheader("An谩lisis de Correlaci贸n con ndices Clim谩ticos (SOI, IOD)")
        available_indices = []
        if Config.SOI_COL in df_monthly_filtered.columns and not df_monthly_filtered[Config.SOI_COL].isnull().all():
            available_indices.append("SOI")
        if Config.IOD_COL in df_monthly_filtered.columns and not df_monthly_filtered[Config.IOD_COL].isnull().all():
            available_indices.append("IOD")
            
        if not available_indices:
            st.warning("No se encontraron columnas para los 铆ndices clim谩ticos (SOI o IOD) en el archivo principal o no hay datos en el per铆odo seleccionado.")
        else:
            col1_corr, col2_corr = st.columns(2)
            selected_index = col1_corr.selectbox("Seleccione un 铆ndice clim谩tico:", available_indices)
            selected_station_corr = col2_corr.selectbox("Seleccione una estaci贸n:",
                                                        options=sorted(stations_for_analysis),
                                                        key="station_for_index_corr")
                                                        
            if selected_index and selected_station_corr:
                index_col_map = {"SOI": Config.SOI_COL, "IOD": Config.IOD_COL}
                index_col_name = index_col_map.get(selected_index)
                df_merged_indices = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == selected_station_corr].copy()
                
                if index_col_name in df_merged_indices.columns:
                    df_merged_indices.dropna(subset=[Config.PRECIPITATION_COL, index_col_name], inplace=True)
                else:
                    st.error(f"La columna para el 铆ndice '{selected_index}' no se encontr贸 en los datos de la estaci贸n.")
                    return

                if not df_merged_indices.empty and len(df_merged_indices) > 2:
                    corr, p_value = stats.pearsonr(df_merged_indices[index_col_name], df_merged_indices[Config.PRECIPITATION_COL])
                    st.markdown(f"#### Resultados de la correlaci贸n ({selected_index}) vs. Precipitaci贸n de {selected_station_corr}")
                    st.metric("Coeficiente de Correlaci贸n (r)", f"{corr:.3f}")
                    
                    if p_value < 0.05:
                        st.success("La correlaci贸n es estad铆sticamente significativa.")
                    else:
                        st.warning(f"La correlaci贸n no es estad铆sticamente significativa.")
                        
                    fig_scatter_indices = px.scatter(
                        df_merged_indices, x=index_col_name, y=Config.PRECIPITATION_COL,
                        trendline='ols',
                        title=f'Dispersi贸n: {selected_index} vs. Precipitaci贸n de {selected_station_corr}',
                        labels={index_col_name: f'Valor del 铆ndice {selected_index}',
                                Config.PRECIPITATION_COL: 'Precipitaci贸n Mensual (mm)'}
                    )
                    st.plotly_chart(fig_scatter_indices, width='stretch')
                else:
                    st.warning("No hay suficientes datos superpuestos entre la estaci贸n y el 铆ndice para calcular la correlaci贸n.")

# --- INICIO DE display_enso_tab ---

def display_enso_tab(df_monthly_filtered, df_enso, gdf_filtered, stations_for_analysis):
    st.header("An谩lisis de Precipitaci贸n y el Fen贸meno ENSO")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
        
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci贸n: {stations_for_analysis[0]}"
    if df_enso is None or df_enso.empty:
        st.warning("No se encontraron datos del fen贸meno ENSO en el archivo de precipitaci贸n cargado.")
        return
        
    enso_series_tab, enso_anim_tab = st.tabs(["Series de Tiempo ENSO", "Mapa Interactivo ENSO"])
    
    with enso_series_tab:
        enso_vars_available = {
            Config.ENSO_ONI_COL: 'Anomal铆a ONI',
            'temp_sst': 'Temp. Superficial del Mar (SST)',
            'temp_media': 'Temp. Media'
        }
        available_tabs = [name for var, name in enso_vars_available.items() if var in df_enso.columns]
        
        if not available_tabs:
            st.warning("No hay variables ENSO disponibles en el archivo de datos para visualizar.")
        else:
            enso_variable_tabs = st.tabs(available_tabs)
            for i, var_name in enumerate(available_tabs):
                with enso_variable_tabs[i]:
                    var_code = [code for code, name in enso_vars_available.items() if name == var_name][0]
                    enso_filtered = df_enso
                    
                    if not enso_filtered.empty and var_code in enso_filtered.columns and not enso_filtered[var_code].isnull().all():
                        fig_enso_series = px.line(enso_filtered, x=Config.DATE_COL, y=var_code,
                                                  title=f"Serie de Tiempo para {var_name}")
                        st.plotly_chart(fig_enso_series, width='stretch')
                    else:
                        st.warning(f"No hay datos disponibles para '{var_code}' en el per铆odo seleccionado.")

    with enso_anim_tab:
        st.subheader("Explorador Mensual del Fen贸meno ENSO")
        if gdf_filtered.empty or Config.ENSO_ONI_COL not in df_enso.columns:
            st.warning("Datos insuficientes para generar esta visualizaci贸n. Se requiere informaci贸n de estaciones y la columna 'anomalia_oni'.")
            return
            
        controls_col, map_col = st.columns([1, 3])
        enso_anim_data = df_enso[[Config.DATE_COL, Config.ENSO_ONI_COL]].copy().dropna(subset=[Config.ENSO_ONI_COL])
        conditions = [enso_anim_data[Config.ENSO_ONI_COL] >= 0.5, enso_anim_data[Config.ENSO_ONI_COL] <= -0.5]
        phases = ['El Ni帽o', 'La Ni帽a']
        enso_anim_data['fase'] = np.select(conditions, phases, default='Neutral')
        
        year_range_val = st.session_state.get('year_range', (2000, 2020))
        if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
            year_min, year_max = year_range_val
        else:
            year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
            
        enso_anim_data_filtered = enso_anim_data[(enso_anim_data[Config.DATE_COL].dt.year >= year_min) &
                                                 (enso_anim_data[Config.DATE_COL].dt.year <= year_max)]
        selected_date = None
        
        with controls_col:
            st.markdown("##### Controles de Mapa")
            selected_base_map_config, selected_overlays_config = display_map_controls(st, "enso_anim")
            st.markdown("##### Selecci贸n de Fecha")
            available_dates = sorted(enso_anim_data_filtered[Config.DATE_COL].unique())
            
            if available_dates:
                selected_date = st.select_slider("Seleccione una fecha (A帽o-Mes)",
                                                options=available_dates,
                                                format_func=lambda date: pd.to_datetime(date).strftime('%Y-%m'))
                phase_info = enso_anim_data_filtered[enso_anim_data_filtered[Config.DATE_COL] == selected_date]
                
                if not phase_info.empty:
                    current_phase = phase_info['fase'].iloc[0]
                    current_oni = phase_info[Config.ENSO_ONI_COL].iloc[0]
                    st.metric(f"Fase ENSO en {pd.to_datetime(selected_date).strftime('%Y-%m')}",
                              current_phase, f"Anomal铆a ONI: {current_oni:.2f}掳C")
                else:
                    st.warning("No hay datos de ENSO para el per铆odo seleccionado.")
            else:
                st.warning("No hay fechas con datos ENSO en el rango seleccionado.")
                
        with map_col:
            if selected_date:
                m_enso = create_folium_map([4.57, -74.29], 5, selected_base_map_config, selected_overlays_config)
                phase_color_map = {'El Ni帽o': 'red', 'La Ni帽a': 'blue', 'Neutral': 'gray'}
                phase_info = enso_anim_data_filtered[enso_anim_data_filtered[Config.DATE_COL] == selected_date]
                current_phase_str = phase_info['fase'].iloc[0] if not phase_info.empty else "N/A"
                marker_color = phase_color_map.get(current_phase_str, 'black')
                
                for _, station in gdf_filtered.iterrows():
                    folium.Marker(
                        location=[station['geometry'].y, station['geometry'].x],
                        tooltip=f"{station[Config.STATION_NAME_COL]}<br>Fase: {current_phase_str}",
                        icon=folium.Icon(color=marker_color, icon='cloud')
                    ).add_to(m_enso)
                    
                if not gdf_filtered.empty:
                    bounds = gdf_filtered.total_bounds
                    if np.all(np.isfinite(bounds)):
                        m_enso.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])
                        
                folium.LayerControl().add_to(m_enso)
                folium_static(m_enso, height=700, width="100%")
            else:
                st.info("Seleccione una fecha para visualizar el mapa.")

# --- INICIO DE display_trends_and_forecast_tab ---

def display_trends_and_forecast_tab(df_anual_melted, df_monthly_to_process, stations_for_analysis):
    st.header("An谩lisis de Tendencias y Pron贸sticos")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
        
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci贸n: {stations_for_analysis[0]}"
    
    tab_names = [
        "An谩lisis Lineal", "Tendencia Mann-Kendall", "Tabla Comparativa",
        "Descomposici贸n de Series", "Autocorrelaci贸n (ACF/PACF)",
        "Pron贸stico SARIMA", "Pron贸stico Prophet", "SARIMA vs Prophet"
    ]
    tendencia_individual_tab, mann_kendall_tab, tendencia_tabla_tab, descomposicion_tab, \
    autocorrelacion_tab, pronostico_sarima_tab, pronostico_prophet_tab, \
    compare_forecast_tab = st.tabs(tab_names)

    with pronostico_sarima_tab:
        st.subheader("Pron贸stico de Precipitaci贸n Mensual (Modelo SARIMA)")
        with st.expander("Ajuste de Par谩metros SARIMA y Descripci贸n"):
            st.markdown("""
            El modelo **SARIMA** (Seasonal Auto-Regressive Integrated Moving Average) utiliza datos hist贸ricos para predecir valores futuros.
            - **(p, d, q):** Componentes no estacionales (AR, I, MA).
            - **(P, D, Q):** Componentes estacionales (AR, I, MA). $s=12$ (mensual).
            """)
            col_p, col_d, col_q = st.columns(3)
            p = col_p.slider("p (AR no estacional)", 0, 3, 1, key="sarima_p")
            d = col_d.slider("d (I no estacional)", 0, 2, 1, key="sarima_d")
            q = col_q.slider("q (MA no estacional)", 0, 3, 1, key="sarima_q")
            col_P, col_D, col_Q = st.columns(3)
            P = col_P.slider("P (AR estacional)", 0, 2, 1, key="sarima_P")
            D = col_D.slider("D (I estacional)", 0, 2, 1, key="sarima_D")
            Q = col_Q.slider("Q (MA estacional)", 0, 2, 1, key="sarima_Q")
            
        station_to_forecast = st.selectbox("Seleccione una estaci贸n para el pron贸stico:",
                                           options=stations_for_analysis, key="sarima_station_select")
        forecast_horizon = st.slider("Meses a pronosticar:", 12, 36, 12, step=12,
                                     key="sarima_forecast_horizon_slider")
        sarima_order = (p, d, q)
        seasonal_order = (P, D, Q, 12)
        ts_data_sarima = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] == station_to_forecast]
        
        if ts_data_sarima.empty or len(ts_data_sarima) < 24:
            st.warning("Se necesitan al menos 24 meses de datos continuos para un pron贸stico SARIMA confiable.")
        else:
            with st.spinner(f"Entrenando modelo y generando pron贸stico para {station_to_forecast} con SARIMA{sarima_order}x{seasonal_order[:-1]}..."):
                try:
                    ts_data_hist, forecast_mean, forecast_ci, sarima_df_export = generate_sarima_forecast(ts_data_sarima, sarima_order, seasonal_order, forecast_horizon)
                    st.session_state['sarima_forecast'] = sarima_df_export
                    
                    fig_pronostico = go.Figure()
                    fig_pronostico.add_trace(go.Scatter(x=ts_data_hist.index, y=ts_data_hist, mode='lines', name='Datos Hist贸ricos'))
                    fig_pronostico.add_trace(go.Scatter(x=forecast_mean.index, y=forecast_mean, mode='lines', name='Pron贸stico SARIMA', line=dict(color='red', dash='dash')))
                    fig_pronostico.add_trace(go.Scatter(x=forecast_ci.index, y=forecast_ci.iloc[:, 0], fill=None, mode='lines', line=dict(color='rgba(255,0,0,0.2)'), showlegend=False))
                    fig_pronostico.add_trace(go.Scatter(x=forecast_ci.index, y=forecast_ci.iloc[:, 1], fill='tonexty', mode='lines', line=dict(color='rgba(255,0,0,0.2)'), name='Intervalo de Confianza'))
                    
                    fig_pronostico.update_layout(title=f"Pron贸stico de Precipitaci贸n SARIMA {sarima_order}x{seasonal_order[:-1]} para {station_to_forecast}",
                                                xaxis_title="Fecha", yaxis_title="Precipitaci贸n (mm)")
                    st.plotly_chart(fig_pronostico, width='stretch')
                    st.info(f"El modelo SARIMA fue entrenado con la configuraci贸n: **Orden={sarima_order}**, **Estacional={seasonal_order}**.")
                    
                    forecast_df = pd.DataFrame({'fecha': forecast_mean.index, 'pronostico': forecast_mean.values,
                                                'limite_inferior': forecast_ci.iloc[:, 0].values, 'limite_superior': forecast_ci.iloc[:, 1].values})
                    csv_data = forecast_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Descargar Pron贸stico SARIMA en CSV", data=csv_data,
                        file_name=f'pronostico_sarima_{station_to_forecast.replace(" ", "_")}.csv',
                        mime='text/csv', key='download-sarima'
                    )
                except Exception as e:
                    st.error(f"No se pudo generar el pron贸stico SARIMA. El modelo no pudo convergir. Error: {e}")

    with pronostico_prophet_tab:
        st.subheader("Pron贸stico de Precipitaci贸n Mensual (Modelo Prophet)")
        station_to_forecast_prophet = st.selectbox("Seleccione una estaci贸n para el pron贸stico:",
                                                   options=stations_for_analysis, key="prophet_station_select",
                                                   help="El pron贸stico se realiza para una 煤nica serie de tiempo con Prophet.")
        forecast_horizon_prophet = st.slider("Meses a pronosticar:", 12, 36, 12, step=12,
                                             key="prophet_forecast_horizon_slider")
        ts_data_prophet_raw = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] == station_to_forecast_prophet]
        
        if ts_data_prophet_raw.empty or len(ts_data_prophet_raw) < 24:
            st.warning("Se necesitan al menos 24 meses de datos para que Prophet funcione correctamente.")
        else:
            with st.spinner(f"Entrenando modelo Prophet y generando pron贸stico para {station_to_forecast_prophet}..."):
                try:
                    model_prophet, forecast_prophet = generate_prophet_forecast(ts_data_prophet_raw, forecast_horizon_prophet)
                    st.session_state['prophet_forecast'] = forecast_prophet[['ds', 'yhat']].copy()
                    st.success("Pron贸stico generado exitosamente.")
                    
                    fig_prophet = plot_plotly(model_prophet, forecast_prophet)
                    fig_prophet.update_layout(title=f"Pron贸stico de Precipitaci贸n con Prophet para {station_to_forecast_prophet}",
                                              yaxis_title="Precipitaci贸n (mm)")
                    st.plotly_chart(fig_prophet, width='stretch')
                    
                    csv_data = forecast_prophet[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Descargar Pron贸stico Prophet en CSV", data=csv_data,
                        file_name=f'pronostico_prophet_{station_to_forecast_prophet.replace(" ", "_")}.csv',
                        mime='text/csv', key='download-prophet'
                    )
                except Exception as e:
                    st.error(f"Ocurri贸 un error al generar el pron贸stico con Prophet. Error: {e}")

    with compare_forecast_tab:
        st.subheader("Comparaci贸n de Pron贸sticos: SARIMA vs Prophet")
        sarima_disponible = st.session_state.get('sarima_forecast') is not None
        prophet_disponible = st.session_state.get('prophet_forecast') is not None
        
        if not sarima_disponible or not prophet_disponible:
            st.warning("Debe generar un pron贸stico SARIMA y un pron贸stico Prophet en las pesta帽as anteriores antes de poder compararlos.")
        else:
            sarima_df = st.session_state['sarima_forecast'].copy()
            prophet_df = st.session_state['prophet_forecast'].copy()
            
            if sarima_df.empty or prophet_df.empty:
                st.warning("Los pron贸sticos generados no contienen datos v谩lidos para la comparaci贸n.")
            else:
                station_id_for_history = st.selectbox("Estaci贸n para serie hist贸rica (debe coincidir con la de los pron贸sticos):",
                                                      options=stations_for_analysis, key="compare_station_history")
                ts_data = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] == station_id_for_history].copy()
                
                if ts_data.empty:
                    st.warning("Datos hist贸ricos no encontrados para la comparaci贸n.")
                else:
                    sarima_df['ds'] = pd.to_datetime(sarima_df['ds'])
                    prophet_df['ds'] = pd.to_datetime(prophet_df['ds'])
                    ts_data['ds'] = ts_data[Config.DATE_COL]
                    
                    df_combined = pd.merge(sarima_df[['ds', 'yhat']], prophet_df[['ds', 'yhat']], on='ds',
                                           suffixes=('_sarima', '_prophet'), how='outer')
                    df_combined = pd.merge(df_combined, ts_data[['ds', Config.PRECIPITATION_COL]], on='ds', how='left')
                    
                    fig_compare = go.Figure()
                    fig_compare.add_trace(go.Scatter(
                        x=df_combined['ds'], y=df_combined[Config.PRECIPITATION_COL],
                        mode='lines+markers', name='Hist贸rico', line=dict(color='gray', width=2)
                    ))
                    fig_compare.add_trace(go.Scatter(
                        x=df_combined['ds'], y=df_combined['yhat_sarima'],
                        mode='lines', name='Pron贸stico SARIMA', line=dict(color='red', dash='dash', width=3)
                    ))
                    fig_compare.add_trace(go.Scatter(
                        x=df_combined['ds'], y=df_combined['yhat_prophet'],
                        mode='lines', name='Pron贸stico Prophet', line=dict(color='blue', dash='dash', width=3)
                    ))
                    
                    fig_compare.update_layout(
                        title=f"Pron贸stico Comparativo SARIMA vs Prophet para {station_id_for_history}",
                        xaxis_title="Fecha", yaxis_title="Precipitaci贸n (mm)", height=650,
                        legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
                    )
                    st.plotly_chart(fig_compare, width='stretch')

    with tendencia_individual_tab:
        st.subheader("Tendencia de Precipitaci贸n Anual (Regresi贸n Lineal)")
        analysis_type = st.radio("Tipo de An谩lisis de Tendencia:", ["Promedio de la selecci贸n", "Estaci贸n individual"], horizontal=True, key="linear_trend_type")
        df_to_analyze = None
        title_for_download = "promedio"
        
        if analysis_type == "Promedio de la selecci贸n":
            df_to_analyze = df_anual_melted.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean().reset_index()
        else:
            station_to_analyze = st.selectbox("Seleccione una estaci贸n para analizar:", options=stations_for_analysis, key="tendencia_station_select")
            if station_to_analyze:
                df_to_analyze = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] == station_to_analyze]
                title_for_download = station_to_analyze.replace(" ", "_")

        if df_to_analyze is not None and len(df_to_analyze.dropna(subset=[Config.PRECIPITATION_COL])) > 2:
            df_to_analyze['a帽o_num'] = pd.to_numeric(df_to_analyze[Config.YEAR_COL])
            df_clean = df_to_analyze.dropna(subset=[Config.PRECIPITATION_COL])
            slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['a帽o_num'], df_clean[Config.PRECIPITATION_COL])
            tendencia_texto = "aumentando" if slope > 0 else "disminuyendo"
            significancia_texto = "**estad铆sticamente significativa**" if p_value < 0.05 else "no es estad铆sticamente significativa"
            
            st.markdown(f"La tendencia de la precipitaci贸n es de **{slope:.2f} mm/a帽o** (es decir, est谩 {tendencia_texto}). Con un valor p de **{p_value:.3f}**, esta tendencia **{significancia_texto}**.")
            
            df_to_analyze['tendencia'] = slope * df_to_analyze['a帽o_num'] + intercept
            fig_tendencia = px.scatter(df_to_analyze, x='a帽o_num', y=Config.PRECIPITATION_COL,
                                       title='Tendencia de la Precipitaci贸n Anual')
            fig_tendencia.add_trace(go.Scatter(x=df_to_analyze['a帽o_num'],
                                               y=df_to_analyze['tendencia'], mode='lines', name='L铆nea de Tendencia',
                                               line=dict(color='red')))
            fig_tendencia.update_layout(xaxis_title="A帽o", yaxis_title="Precipitaci贸n Anual (mm)")
            st.plotly_chart(fig_tendencia, width='stretch')
            
            csv_data = df_to_analyze.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="Descargar datos de Tendencia Anual", data=csv_data,
                file_name=f'tendencia_anual_{title_for_download}.csv', mime='text/csv',
                key='download-anual-tendencia'
            )
        else:
            st.warning("No hay suficientes datos en el per铆odo seleccionado para calcular una tendencia.")

    with mann_kendall_tab:
        st.subheader("Tendencia de Precipitaci贸n Anual (Prueba de Mann-Kendall)")
        with st.expander("驴Qu茅 es la prueba de Mann-Kendall?"):
            st.markdown("""
            La **Prueba de Mann-Kendall** es un m茅todo estad铆stico no param茅trico utilizado para detectar tendencias en series de tiempo. No asume que los datos sigan una distribuci贸n particular.
            - **Tendencia**: Indica si es 'increasing' (creciente), 'decreasing' (decreciente) o 'no trend'.
            - **Valor $p$**: Si es menor a 0.05, la tendencia se considera estad铆sticamente significativa.
            - **Pendiente de Sen**: Cuantifica la magnitud de la tendencia y es robusto frente a valores at铆picos.
            """)
        mk_analysis_type = st.radio("Tipo de An谩lisis de Tendencia:", ["Promedio de la selecci贸n", "Estaci贸n individual"], horizontal=True, key="mk_trend_type")
        df_to_analyze_mk = None
        
        if mk_analysis_type == "Promedio de la selecci贸n":
            df_to_analyze_mk = df_anual_melted.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean().reset_index()
        else:
            station_to_analyze_mk = st.selectbox("Seleccione una estaci贸n para analizar:", options=stations_for_analysis, key="mk_station_select")
            if station_to_analyze_mk:
                df_to_analyze_mk = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] == station_to_analyze_mk]

        if df_to_analyze_mk is not None and len(df_to_analyze_mk.dropna(subset=[Config.PRECIPITATION_COL])) > 3:
            df_clean_mk = df_to_analyze_mk.dropna(subset=[Config.PRECIPITATION_COL]).sort_values(by=Config.YEAR_COL)
            mk_result = mk.original_test(df_clean_mk[Config.PRECIPITATION_COL])
            
            st.markdown(f"#### Resultados para: {mk_analysis_type if mk_analysis_type == 'Promedio de la selecci贸n' else station_to_analyze_mk}")
            col1, col2, col3 = st.columns(3)
            col1.metric("Tendencia Detectada", mk_result.trend.capitalize())
            col2.metric("Valor p", f"{mk_result.p:.4f}")
            col3.metric("Pendiente de Sen (mm/a帽o)", f"{mk_result.slope:.2f}")
            
            if mk_result.p < 0.05:
                st.success("La tendencia es estad铆sticamente significativa ($p<0.05$).")
            else:
                st.warning("La tendencia no es estad铆sticamente significativa ($p>=0.05$).")
                
            fig_mk = px.scatter(df_clean_mk, x=Config.YEAR_COL, y=Config.PRECIPITATION_COL, title="An谩lisis de Tendencia con Pendiente de Sen")
            median_x = df_clean_mk[Config.YEAR_COL].median()
            median_y = df_clean_mk[Config.PRECIPITATION_COL].median()
            intercept_sen = median_y - mk_result.slope * median_x
            x_vals = np.array(df_clean_mk[Config.YEAR_COL])
            y_vals = mk_result.slope * x_vals + intercept_sen
            
            fig_mk.add_trace(go.Scatter(x=x_vals, y=y_vals, mode='lines', name="Pendiente de Sen", line=dict(color='orange')))
            fig_mk.update_layout(xaxis_title="A帽o", yaxis_title="Precipitaci贸n Anual (mm)")
            st.plotly_chart(fig_mk, width='stretch')
        else:
            st.warning("No hay suficientes datos (se requieren al menos 4 puntos) para calcular la tendencia de Mann-Kendall.")

    with tendencia_tabla_tab:
        st.subheader("Tabla Comparativa de Tendencias de Precipitaci贸n Anual")
        st.info("Esta tabla resume los resultados de dos m茅todos de an谩lisis de tendencia. Presione el bot贸n para calcular los valores para todas las estaciones seleccionadas.")
        
        if st.button("Calcular Tendencias para Todas las Estaciones Seleccionadas"):
            with st.spinner("Calculando tendencias..."):
                results = []
                df_anual_calc = df_anual_melted.copy()
                if st.session_state.get('exclude_zeros', False):
                    df_anual_calc = df_anual_calc[df_anual_calc[Config.PRECIPITATION_COL] > 0]
                    
                for station in stations_for_analysis:
                    station_data = df_anual_calc[df_anual_calc[Config.STATION_NAME_COL] == station].dropna(subset=[Config.PRECIPITATION_COL]).sort_values(by=Config.YEAR_COL)
                    slope_lin, p_lin = np.nan, np.nan
                    trend_mk, p_mk, slope_sen = "Datos insuficientes", np.nan, np.nan
                    
                    if len(station_data) > 2:
                        station_data['a帽o_num'] = pd.to_numeric(station_data[Config.YEAR_COL])
                        res = stats.linregress(station_data['a帽o_num'], station_data[Config.PRECIPITATION_COL])
                        slope_lin, p_lin = res.slope, res.pvalue
                        
                    if len(station_data) > 3:
                        mk_result_table = mk.original_test(station_data[Config.PRECIPITATION_COL])
                        trend_mk = mk_result_table.trend.capitalize()
                        p_mk = mk_result_table.p
                        slope_sen = mk_result_table.slope
                        
                    results.append({
                        "Estaci贸n": station, "A帽os Analizados": len(station_data),
                        "Tendencia Lineal (mm/a帽o)": slope_lin, "Valor p (Lineal)": p_lin,
                        "Tendencia MK": trend_mk, "Valor p (MK)": p_mk,
                        "Pendiente de Sen (mm/a帽o)": slope_sen,
                    })

                if results:
                    results_df = pd.DataFrame(results)
                    
                    def style_p_value(val):
                        if pd.isna(val) or isinstance(val, str): return ""
                        color = 'lightgreen' if val < 0.05 else 'lightcoral'
                        return f'background-color: {color}'
                        
                    st.dataframe(results_df.style.format({
                        "Tendencia Lineal (mm/a帽o)": "{:.2f}", "Valor p (Lineal)": "{:.4f}",
                        "Valor p (MK)": "{:.4f}", "Pendiente de Sen (mm/a帽o)": "{:.2f}",
                    }).applymap(style_p_value, subset=['Valor p (Lineal)', 'Valor p (MK)']),
                                 width='stretch')
                    
                    csv_data = results_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Descargar tabla de tendencias en CSV", data=csv_data,
                        file_name='tabla_tendencias_comparativa.csv', mime='text/csv', key='download-tabla-tendencias'
                    )
                else:
                    st.warning("No se pudieron calcular tendencias para las estaciones seleccionadas.")

    with descomposicion_tab:
        st.subheader("Descomposici贸n de Series de Tiempo Mensual")
        st.markdown("""
        La **descomposici贸n de una serie de tiempo** separa sus componentes principales: Tendencia, Estacionalidad y Residuo.
        """)
        station_to_decompose = st.selectbox("Seleccione una estaci贸n para la descomposici贸n:", options=stations_for_analysis, key="decompose_station_select")
        
        if station_to_decompose:
            df_station = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] == station_to_decompose].copy()
            if not df_station.empty:
                df_station.set_index(Config.DATE_COL, inplace=True)
                try:
                    result = get_decomposition_results(df_station[Config.PRECIPITATION_COL], period=12, model='additive')
                    fig_decomp = go.Figure()
                    fig_decomp.add_trace(go.Scatter(x=df_station.index, y=df_station[Config.PRECIPITATION_COL], mode='lines', name='Original'))
                    fig_decomp.add_trace(go.Scatter(x=result.trend.index, y=result.trend, mode='lines', name='Tendencia'))
                    fig_decomp.add_trace(go.Scatter(x=result.seasonal.index, y=result.seasonal, mode='lines', name='Estacionalidad'))
                    fig_decomp.add_trace(go.Scatter(x=result.resid.index, y=result.resid, mode='lines', name='Residuo'))
                    
                    fig_decomp.update_layout(title=f"Descomposici贸n de la Serie de Precipitaci贸n para {station_to_decompose}", height=600,
                                             legend=dict(orientation='h', yanchor="bottom", y=1.02, xanchor="right", x=1))
                    st.plotly_chart(fig_decomp, width='stretch')
                except Exception as e:
                    st.error(f"No se pudo realizar la descomposici贸n de la serie. Puede que la serie de datos sea demasiado corta. Error: {e}")
            else:
                st.warning(f"No hay datos mensuales para la estaci贸n {station_to_decompose} en el per铆odo seleccionado.")

    with autocorrelacion_tab:
        st.subheader("An谩lisis de Autocorrelaci贸n (ACF) y Autocorrelaci贸n Parcial (PACF)")
        st.markdown("Estos gr谩ficos ayudan a identificar la dependencia de la precipitaci贸n con sus valores pasados (rezagos).")
        station_to_analyze_acf = st.selectbox("Seleccione una estaci贸n:", options=stations_for_analysis, key="acf_station_select")
        max_lag = st.slider("N煤mero m谩ximo de rezagos (meses):", min_value=12, max_value=60, value=24, step=12)
        
        if station_to_analyze_acf:
            df_station_acf = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] == station_to_analyze_acf].copy()
            if not df_station_acf.empty:
                df_station_acf.set_index(Config.DATE_COL, inplace=True)
                df_station_acf = df_station_acf.asfreq('MS')
                df_station_acf[Config.PRECIPITATION_COL] = df_station_acf[Config.PRECIPITATION_COL].interpolate(method='time').dropna()
                
                if len(df_station_acf) > max_lag:
                    try:
                        fig_acf = create_acf_chart(df_station_acf[Config.PRECIPITATION_COL], max_lag)
                        st.plotly_chart(fig_acf, width='stretch')
                        fig_pacf = create_pacf_chart(df_station_acf[Config.PRECIPITATION_COL], max_lag)
                        st.plotly_chart(fig_pacf, width='stretch')
                    except Exception as e:
                        st.error(f"No se pudieron generar los gr谩ficos de autocorrelaci贸n. Error: {e}")
                else:
                    st.warning(f"No hay suficientes datos (se requieren > {max_lag} meses) para el an谩lisis de autocorrelaci贸n.")
            else:
                st.warning(f"No hay datos para la estaci贸n {station_to_analyze_acf} en el per铆odo seleccionado.")


def display_downloads_tab(df_anual_melted, df_monthly_filtered, stations_for_analysis):
    st.header("Opciones de Descarga")
    if len(stations_for_analysis) == 0:
        st.warning("Por favor, seleccione al menos una estaci贸n para activar las descargas.")
        return
        
    @st.cache_data
    def convert_df_to_csv(df):
        return df.to_csv(index=False).encode('utf-8')
        
    st.markdown("**Datos de Precipitaci贸n Anual (Filtrados)**")
    csv_anual = convert_df_to_csv(df_anual_melted)
    st.download_button("Descargar CSV Anual", csv_anual, 'precipitacion_anual.csv', 'text/csv', key='download-anual')
    
    st.markdown("**Datos de Precipitaci贸n Mensual (Filtrados)**")
    csv_mensual = convert_df_to_csv(df_monthly_filtered)
    st.download_button("Descargar CSV Mensual", csv_mensual, 'precipitacion_mensual.csv', 'text/csv', key='download-mensual')
    
    if st.session_state.analysis_mode == "Completar series (interpolaci贸n)":
        st.markdown("**Datos de Precipitaci贸n Mensual (Series Completadas y Filtradas)**")
        year_range_val = st.session_state.get('year_range', (2000, 2020))
        if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
            year_min, year_max = year_range_val
        else:
            year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
            
        df_completed_to_download = (st.session_state.df_monthly_processed[
            (st.session_state.df_monthly_processed[Config.STATION_NAME_COL].isin(stations_for_analysis)) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.year >= year_min) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.year <= year_max) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))
        ]).copy()
        
        csv_completado = convert_df_to_csv(df_completed_to_download)
        st.download_button("Descargar CSV con Series Completadas", csv_completado,
                           'precipitacion_mensual_completada.csv', 'text/csv', key='download-completado')


def display_station_table_tab(gdf_filtered, df_anual_melted, stations_for_analysis):
    st.header("Informaci贸n Detallada de las Estaciones")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci贸n para ver esta secci贸n.")
        return
        
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci贸n: {stations_for_analysis[0]}"
    st.info(f"Mostrando informaci贸n para {selected_stations_str}.")
    
    if gdf_filtered.empty:
        st.info("No hay estaciones que cumplan con los filtros geogr谩ficos y de datos seleccionados.")
        return
        
    df_info_table = gdf_filtered[[Config.STATION_NAME_COL, Config.ALTITUDE_COL,
                                  Config.MUNICIPALITY_COL, Config.REGION_COL,
                                  Config.PERCENTAGE_COL]].copy()
                                  
    if not df_anual_melted.empty:
        df_mean_precip = df_anual_melted.groupby(Config.STATION_NAME_COL)[Config.PRECIPITATION_COL].mean().round(0).reset_index()
        df_mean_precip.rename(columns={Config.PRECIPITATION_COL: 'Precipitaci贸n media anual (mm)'}, inplace=True)
        df_info_table = df_info_table.merge(df_mean_precip, on=Config.STATION_NAME_COL, how='left')
    else:
        df_info_table['Precipitaci贸n media anual (mm)'] = 'N/A'
        
    df_for_display = (
        df_info_table
        .drop(columns=[Config.PERCENTAGE_COL])
        .set_index(Config.STATION_NAME_COL)
    )
    st.dataframe(df_for_display, width='stretch')


def display_percentile_analysis_subtab(df_monthly_filtered, station_to_analyze_perc):
    """Realiza y muestra el an谩lisis de sequ铆as y eventos extremos por percentiles mensuales para una estaci贸n."""
    df_long = st.session_state.get('df_long')
    if df_long is None or df_long.empty:
        st.warning("No se puede realizar el an谩lisis de percentiles. El DataFrame hist贸rico no est谩 disponible.")
        return
        
    st.markdown("#### Par谩metros del An谩lisis")
    col1, col2 = st.columns(2)
    p_lower = col1.slider("Percentil Inferior (Sequ铆a):", 1, 40, 10, key="p_lower_perc")
    p_upper = col2.slider("Percentil Superior (H煤medo):", 60, 99, 90, key="p_upper_perc")
    st.markdown("---")
    
    with st.spinner(f"Calculando percentiles P{p_lower} y P{p_upper} para {station_to_analyze_perc}..."):
        try:
            df_extremes, df_thresholds = calculate_percentiles_and_extremes(
                df_long, station_to_analyze_perc, p_lower, p_upper
            )
            year_range_val = st.session_state.get('year_range', (2000, 2020))
            if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
                year_min, year_max = year_range_val
            else:
                year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
                
            df_plot = df_extremes[
                (df_extremes[Config.DATE_COL].dt.year >= year_min) &
                (df_extremes[Config.DATE_COL].dt.year <= year_max) &
                (df_extremes[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))
            ].copy()
            
            if df_plot.empty:
                st.warning("No hay datos que coincidan con los filtros de tiempo para la estaci贸n seleccionada.")
                return
                
            st.subheader(f"Serie de Tiempo con Eventos Extremos (P{p_lower} y P{p_upper} Percentiles)")
            color_map = {'Sequ铆a Extrema (<P{}%)'.format(p_lower): 'red',
                         'H煤medo Extremo (>P{}%)'.format(p_upper): 'blue',
                         'Normal': 'gray'}
                         
            fig_series = px.scatter(df_plot, x=Config.DATE_COL, y=Config.PRECIPITATION_COL,
                                    color='event_type',
                                    color_discrete_map=color_map,
                                    title=f"Precipitaci贸n Mensual y Eventos Extremos en {station_to_analyze_perc}",
                                    labels={Config.PRECIPITATION_COL: "Precipitaci贸n (mm)",
                                            Config.DATE_COL: "Fecha"},
                                    hover_data={'event_type': True, 'p_lower': ':.0f', 'p_upper': ':.0f'})

            mean_precip = df_long[df_long[Config.STATION_NAME_COL] == station_to_analyze_perc][Config.PRECIPITATION_COL].mean()
            fig_series.add_hline(y=mean_precip, line_dash="dash", line_color="green", annotation_text="Media Hist贸rica")
            fig_series.update_layout(height=500)
            st.plotly_chart(fig_series, width='stretch')

            st.subheader("Umbrales de Percentil Mensual (Climatolog铆a Hist贸rica)")
            meses_map_inv = {1: 'Ene', 2: 'Feb', 3: 'Mar', 4: 'Abr', 5: 'May', 6: 'Jun',
                             7: 'Jul', 8: 'Ago', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dic'}
            df_thresholds['Month_Name'] = df_thresholds[Config.MONTH_COL].map(meses_map_inv)
            
            fig_thresh = go.Figure()
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['p_upper'],
                                            mode='lines+markers', name=f'Percentil Superior (P{p_upper}%)', line=dict(color='blue')))
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['p_lower'],
                                            mode='lines+markers', name=f'Percentil Inferior (P{p_lower}%)', line=dict(color='red')))
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['mean_monthly'],
                                            mode='lines', name='Media Mensual', line=dict(color='green', dash='dot')))
            fig_thresh.update_layout(title='Umbrales de Precipitaci贸n por Mes (Basado en Climatolog铆a)',
                                     xaxis_title="Mes", yaxis_title="Precipitaci贸n (mm)", height=400)
            st.plotly_chart(fig_thresh, width='stretch')

        except Exception as e:
            st.error(f"Error al calcular el an谩lisis de percentiles: {e}")
            st.info("Aseg煤rese de que el archivo hist贸rico de datos ('df_long') contenga datos suficientes para la estaci贸n seleccionada.")
