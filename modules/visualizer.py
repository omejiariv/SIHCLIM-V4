# modules/visualizer.py

# --- Importaciones Est√°ndar y de Terceros ---
import streamlit as st
import pandas as pd
import geopandas as gpd
import altair as alt
import folium
from folium.plugins import MarkerCluster, MiniMap
from folium.raster_layers import WmsTileLayer
from streamlit_folium import folium_static
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
import base64
import branca.colormap as cm
import matplotlib.pyplot as plt
import matplotlib.cm as mpl_cm
from scipy import stats
from scipy.interpolate import Rbf
import pymannkendall as mk
from prophet.plot import plot_plotly
import io

# --- Importaciones de M√≥dulos Propios ---
from modules.analysis import calculate_spi, calculate_spei, calculate_monthly_anomalies, calculate_percentiles_and_extremes
from modules.config import Config
from modules.utils import add_folium_download_button
from modules.interpolation import create_interpolation_surface
from modules.analysis import calculate_spi, calculate_monthly_anomalies, calculate_percentiles_and_extremes
from modules.forecasting import (
    generate_sarima_forecast, generate_prophet_forecast,
    get_decomposition_results, create_acf_chart, create_pacf_chart
)

def display_filter_summary(total_stations_count, selected_stations_count, year_range, selected_months_count):
    """Muestra una caja informativa con un resumen de los filtros aplicados."""
    
    # Formatear el rango de a√±os
    if isinstance(year_range, tuple) and len(year_range) == 2:
        year_text = f"{year_range[0]} ‚Äì {year_range[1]}"
    else:
        year_text = "N/A"

    summary_text = (
        f"**Estaciones Seleccionadas:** `{selected_stations_count} de {total_stations_count}` | "
        f"**Per√≠odo:** `{year_text}` | "
        f"**Meses:** `{selected_months_count} de 12`"
    )
    st.info(summary_text)

def get_map_options():
    return {
        "CartoDB Positron (Predeterminado)": {"tiles": "cartodbpositron", "attr": '&copy; <a href="https://carto.com/attributions">CartoDB</a>', "overlay": False},
        "OpenStreetMap": {"tiles": "OpenStreetMap", "attr": '&copy; <a href="https://www.openstreetmap.org/copyright">OpenStreetMap</a> contributors', "overlay": False},
        "Topograf√≠a (OpenTopoMap)": {"tiles": "https://{s}.tile.opentomap.org/{z}/{x}/{y}.png", "attr": 'Map data: &copy; <a href="https://www.openstreetmap.org/copyright">OpenStreetMap</a> contributors, <a href="http://viewfinderpanoramas.org">SRTM</a> | Map style: &copy; <a href="https://opentopomap.org">Open Topo Map</a> (<a href="https://creativecommons.org/licenses/by-sa/3.0/">CC-BY-SA</a>)', "overlay": False},
        "Relieve y Oc√©anos (GEBCO)": {"url": "https://www.gebco.net/data_and_products/gebco_web_services/web_map_service/web_map_service.php", "layers": "GEBCO_2021_Surface", "transparent": False, "attr": "GEBCO 2021", "overlay": True},
        "Mapa de Colombia (WMS IDEAM)": {"url": "https://geoservicios.ideam.gov.co/geoserver/ideam/wms", "layers": "ideam:col_admin", "transparent": True, "attr": "IDEAM", "overlay": True},
        "Cobertura de la Tierra (WMS IGAC)": {"url": "https://servicios.igac.gov.co/server/services/IDEAM/IDEAM_Cobertura_Corine/MapServer/WMSServer", "layers": "IDEAM_Cobertura_Corine_Web", "transparent": True, "attr": "IGAC", "overlay": True},
    }

def display_map_controls(container_object, key_prefix):
    map_options = get_map_options()
    base_maps = {k: v for k, v in map_options.items() if not v.get("overlay")}
    overlays = {k: v for k, v in map_options.items() if v.get("overlay")}
    
    selected_base_map_name = container_object.selectbox("Seleccionar Mapa Base",
                                                        list(base_maps.keys()), key=f"{key_prefix}_base_map")
    
    default_overlays = ["Mapa de Colombia (WMS IDEAM)"]
    selected_overlays_names = container_object.multiselect("Seleccionar Capas Adicionales",
                                                     list(overlays.keys()), default=default_overlays, key=f"{key_prefix}_overlays")
    
    selected_overlays_config = [overlays[k] for k in selected_overlays_names]
    
    return base_maps[selected_base_map_name], selected_overlays_config

def create_enso_chart(enso_data):
    if enso_data.empty or Config.ENSO_ONI_COL not in enso_data.columns:
        return go.Figure()

    data = enso_data.copy().sort_values(Config.DATE_COL)
    data.dropna(subset=[Config.ENSO_ONI_COL], inplace=True)

    if data.empty:
        return go.Figure()

    conditions = [data[Config.ENSO_ONI_COL] >= 0.5, data[Config.ENSO_ONI_COL] <= -0.5]
    phases = ['El Ni√±o', 'La Ni√±a']
    colors = ['red', 'blue']
    data['phase'] = np.select(conditions, phases, default='Neutral')
    data['color'] = np.select(conditions, colors, default='grey')

    y_range = [data[Config.ENSO_ONI_COL].min() - 0.5, data[Config.ENSO_ONI_COL].max() + 0.5]

    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=data[Config.DATE_COL], y=[y_range[1] - y_range[0]] * len(data),
        base=y_range[0], marker_color=data['color'], width=30*24*60*60*1000,
        opacity=0.3, hoverinfo='none', showlegend=False
    ))
    legend_map = {'El Ni√±o': 'red', 'La Ni√±a': 'blue', 'Neutral': 'grey'}
    for phase, color in legend_map.items():
        fig.add_trace(go.Scatter(
            x=[None], y=[None], mode='markers',
            marker=dict(size=15, color=color, symbol='square', opacity=0.5),
            name=phase, showlegend=True
        ))
    fig.add_trace(go.Scatter(
        x=data[Config.DATE_COL], y=data[Config.ENSO_ONI_COL],
        mode='lines', name='Anomal√≠a ONI', line=dict(color='black', width=2), showlegend=True
    ))
    fig.add_hline(y=0.5, line_dash="dash", line_color="red")
    fig.add_hline(y=-0.5, line_dash="dash", line_color="blue")
    fig.update_layout(
        height=600, title="Fases del Fen√≥meno ENSO y Anomal√≠a ONI",
        yaxis_title="Anomal√≠a ONI (¬∞C)", xaxis_title="Fecha", showlegend=True,
        legend_title_text='Fase', yaxis_range=y_range
    )
    return fig

def create_anomaly_chart(df_plot):
    if df_plot.empty:
        return go.Figure()

    df_plot['color'] = np.where(df_plot['anomalia'] < 0, 'red', 'blue')
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=df_plot[Config.DATE_COL], y=df_plot['anomalia'],
        marker_color=df_plot['color'], name='Anomal√≠a de Precipitaci√≥n'
    ))

    if Config.ENSO_ONI_COL in df_plot.columns:
        df_plot_enso = df_plot.dropna(subset=[Config.ENSO_ONI_COL])
        
        # Highlight El Ni√±o periods
        nino_periods = df_plot_enso[df_plot_enso[Config.ENSO_ONI_COL] >= 0.5]
        for _, row in nino_periods.iterrows():
            fig.add_vrect(x0=row[Config.DATE_COL] - pd.DateOffset(days=15),
                          x1=row[Config.DATE_COL] + pd.DateOffset(days=15),
                          fillcolor="red", opacity=0.15, layer="below", line_width=0)

        # Highlight La Ni√±a periods
        nina_periods = df_plot_enso[df_plot_enso[Config.ENSO_ONI_COL] <= -0.5]
        for _, row in nina_periods.iterrows():
            fig.add_vrect(x0=row[Config.DATE_COL] - pd.DateOffset(days=15),
                          x1=row[Config.DATE_COL] + pd.DateOffset(days=15),
                          fillcolor="blue", opacity=0.15, layer="below", line_width=0)

        # Add hidden traces for legend
        fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',
                                 marker=dict(symbol='square', color='rgba(255, 0, 0, 0.3)'),
                                 name='Fase El Ni√±o'))
        fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',
                                 marker=dict(symbol='square', color='rgba(0, 0, 255, 0.3)'),
                                 name='Fase La Ni√±a'))

    fig.update_layout(
        height=600, title="Anomal√≠as Mensuales de Precipitaci√≥n y Fases ENSO",
        yaxis_title="Anomal√≠a de Precipitaci√≥n (mm)", xaxis_title="Fecha", showlegend=True
    )
    return fig

# --- FUNCI√ìN AUXILIAR PARA POPUP ---
def generate_station_popup_html(row, df_anual_melted, include_chart=False,
                                df_monthly_filtered=None):
    """
    Robustly generates the HTML content for a station's popup.
    """
    full_html = ""
    station_name = row.get(Config.STATION_NAME_COL, 'N/A')
    
    try:
        # Get the year range from the session state
        year_range_val = st.session_state.get('year_range', (2000, 2020))
        if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
            year_min, year_max = year_range_val
        else: # Fallback for other modes
            year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
        total_years_in_period = year_max - year_min + 1

        # Calculate statistics
        df_station_data = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] == station_name]
        if not df_station_data.empty:
            summary_data = df_station_data.groupby(Config.STATION_NAME_COL).agg(
                precip_media_anual=('precipitation', 'mean'),
                a√±os_validos=('precipitation', 'count')
            ).iloc[0]
            valid_years = int(summary_data.get('a√±os_validos', 0))
            precip_media_anual = summary_data.get('precip_media_anual', 0)
        else:
            valid_years = 0
            precip_media_anual = 0

        # Generate the text part of the HTML
        text_html = f"""
        <h4>{station_name}</h4>
        <p><b>Municipio:</b> {row.get(Config.MUNICIPALITY_COL, 'N/A')}</p>
        <p><b>Altitud:</b> {row.get(Config.ALTITUDE_COL, 'N/A')} m</p>
        <p><b>Promedio Anual:</b> {precip_media_anual:.0f} mm</p>
        <small>(Calculado con <b>{valid_years}</b> de <b>{total_years_in_period}</b> a√±os del per√≠odo)</small>
        """
        full_html = text_html

        # Try to generate the chart part of the HTML
        chart_html = ""
        if include_chart and df_monthly_filtered is not None:
            df_station_monthly_avg = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station_name]
            if not df_station_monthly_avg.empty:
                df_monthly_avg = df_station_monthly_avg.groupby(Config.MONTH_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                if not df_monthly_avg.empty:
                    fig = go.Figure(data=[go.Bar(x=df_monthly_avg[Config.MONTH_COL], y=df_monthly_avg[Config.PRECIPITATION_COL])])
                    fig.update_layout(title_text="Ppt. Mensual Media", xaxis_title="Mes", yaxis_title="Ppt. (mm)", 
                                      height=250, width=350, margin=dict(t=40, b=20, l=20, r=20))
                    chart_html = fig.to_html(full_html=False, include_plotlyjs='cdn')

        # Combine text and chart if chart was created successfully
        if chart_html:
            sanitized_chart_html = chart_html.replace('"', '&quot;')
            full_html = text_html + "<hr>" + f'<iframe srcdoc="{sanitized_chart_html}" width="370" height="270" frameborder="0"></iframe>'
        
    except Exception as e:
        st.warning(f"Could not generate the full popup content for '{station_name}'. Reason: {e}")
        if 'text_html' in locals():
            full_html = text_html
        else:
            full_html = f"<h4>{station_name}</h4><p>Error loading popup data.</p>"

    return folium.Popup(full_html, max_width=450)


# --- CHART AND MAP HELPER FUNCTIONS ---

def create_folium_map(location, zoom, base_map_config, overlays_config, fit_bounds_data=None):
    """
    Creates a Folium map with robust centering logic.
    """
    m = folium.Map(location=location, zoom_start=zoom, tiles=base_map_config.get("tiles", "OpenStreetMap"), attr=base_map_config.get("attr", None))

    if fit_bounds_data is not None and not fit_bounds_data.empty:
        if len(fit_bounds_data) > 1:
            bounds = fit_bounds_data.total_bounds
            if np.all(np.isfinite(bounds)):
                m.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])
        elif len(fit_bounds_data) == 1:
            point = fit_bounds_data.iloc[0].geometry
            m.location = [point.y, point.x]
            m.zoom_start = 12

    for layer_config in overlays_config:
        WmsTileLayer(url=layer_config["url"], layers=layer_config["layers"], fmt='image/png',
                     transparent=layer_config.get("transparent", False), overlay=True, control=True,
                     name=layer_config.get("attr", "Overlay")).add_to(m)
    return m
    
# --- MAIN TAB DISPLAY FUNCTIONS ---

def display_welcome_tab():
    st.header("Bienvenido al Sistema de Informaci√≥n de Lluvias y Clima")
    st.markdown(Config.WELCOME_TEXT, unsafe_allow_html=True)
    if os.path.exists(Config.LOGO_PATH):
        st.image(Config.LOGO_PATH, width=250, caption="Corporaci√≥n Cuenca Verde")

def display_spatial_distribution_tab(gdf_filtered, stations_for_analysis, df_anual_melted,
                                     df_monthly_filtered):
    st.header("Distribuci√≥n espacial de las Estaciones de Lluvia")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return                                     
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return

    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 \
        else f"1 estaci√≥n: {stations_for_analysis[0]}"

    year_range_val = st.session_state.get('year_range', (2000, 2020))
    if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
        year_min, year_max = year_range_val
    else:
        year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))

    gdf_display = gdf_filtered.copy()

    if not df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL]).empty:
        summary_stats = \
            df_anual_melted.groupby(Config.STATION_NAME_COL)[Config.PRECIPITATION_COL].agg(['mean',
                                                                                           'count']).reset_index()
        summary_stats.rename(columns={'mean': 'precip_media_anual', 'count': 'a√±os_validos'},
                             inplace=True)
        gdf_display = gdf_display.merge(summary_stats, on=Config.STATION_NAME_COL, how='left')
    else:
        gdf_display['precip_media_anual'] = np.nan
        gdf_display['a√±os_validos'] = 0

    gdf_display['precip_media_anual'] = gdf_display['precip_media_anual'].fillna(0)
    gdf_display['a√±os_validos'] = gdf_display['a√±os_validos'].fillna(0).astype(int)

    sub_tab_mapa, sub_tab_grafico = st.tabs(["Mapa Interactivo", "Gr√°fico de Disponibilidad de Datos"])

    with sub_tab_mapa:
        controls_col, map_col = st.columns([1, 3])
        with controls_col:
            st.subheader("Controles del Mapa")
            selected_base_map_config, selected_overlays_config = display_map_controls(st,
                                                                                      "dist_esp")
            if not gdf_display.empty:
                st.markdown("---")
                if os.path.exists(Config.LOGO_PATH):
                    st.image(Config.LOGO_PATH, width=70)
                st.metric("Estaciones en Vista", len(gdf_display))
                st.markdown("---")
                # ... (Additional controls can go here)

        with map_col:
            if not gdf_display.empty:
                m = create_folium_map(
                    location=[4.57, -74.29], # Default center
                    zoom=5,
                    base_map_config=selected_base_map_config,
                    overlays_config=selected_overlays_config,
                    fit_bounds_data=gdf_display
                )

                if 'gdf_municipios' in st.session_state and st.session_state.gdf_municipios is not None:
                    folium.GeoJson(st.session_state.gdf_municipios.to_json(),
                                   name='Municipios').add_to(m)

                marker_cluster = MarkerCluster(name='Estaciones').add_to(m)

                for _, row in gdf_display.iterrows():
                    popup_object = generate_station_popup_html(row, df_anual_melted, include_chart=False)
                    folium.Marker(
                        location=[row['geometry'].y, row['geometry'].x],
                        tooltip=row[Config.STATION_NAME_COL],
                        popup=popup_object
                    ).add_to(marker_cluster)

                folium.LayerControl().add_to(m)
                m.add_child(MiniMap(toggle_display=True))
                folium_static(m, height=450, width="100%")
                add_folium_download_button(m, "mapa_distribucion.html")
            else:
                st.warning("No hay estaciones seleccionadas para mostrar en el mapa.")

    with sub_tab_grafico:
        st.subheader("Disponibilidad y Composici√≥n de Datos por Estaci√≥n")

        if not gdf_display.empty:
            if st.session_state.analysis_mode == "Completar series (interpolaci√≥n)":
                st.info("Mostrando la composici√≥n de datos originales vs. completados para el per√≠odo seleccionado.")
                if not df_monthly_filtered.empty and Config.ORIGIN_COL in df_monthly_filtered.columns:
                    data_composition = df_monthly_filtered.groupby([Config.STATION_NAME_COL,
                                                                    Config.ORIGIN_COL]).size().unstack(fill_value=0)
                    if 'Original' not in data_composition: data_composition['Original'] = 0
                    if 'Completado' not in data_composition: data_composition['Completado'] = 0
                    data_composition['total'] = data_composition['Original'] + data_composition['Completado']
                    data_composition['% Original'] = (data_composition['Original'] / data_composition['total']) * 100
                    data_composition['% Completado'] = (data_composition['Completado'] / data_composition['total']) * 100
                    sort_order_comp = st.radio("Ordenar por:", ["% Datos Originales (Mayor a Menor)", "% Datos Originales (Menor a Mayor)", "Alfab√©tico"], horizontal=True, key="sort_comp")
                    if "Mayor a Menor" in sort_order_comp: data_composition = data_composition.sort_values("% Original", ascending=False)
                    elif "Menor a Mayor" in sort_order_comp: data_composition = data_composition.sort_values("% Original", ascending=True)
                    else: data_composition = data_composition.sort_index(ascending=True)
                    df_plot = data_composition.reset_index().melt(
                        id_vars=Config.STATION_NAME_COL, value_vars=['% Original', '% Completado'],
                        var_name='Tipo de Dato', value_name='Porcentaje')
                    fig_comp = px.bar(df_plot, x=Config.STATION_NAME_COL, y='Porcentaje', color='Tipo de Dato',
                                      title='Composici√≥n de Datos por Estaci√≥n',
                                      labels={Config.STATION_NAME_COL: 'Estaci√≥n', 'Porcentaje': '% del Per√≠odo'},
                                      text_auto='.1f',
                                      color_discrete_map={'% Original': '#1f77b4', '% Completado': '#ff7f0e'})
                    fig_comp.update_layout(height=500, xaxis={'categoryorder': 'trace'})
                    st.plotly_chart(fig_comp, use_container_width=True)
                else:
                    st.warning("No hay datos mensuales procesados para mostrar la composici√≥n.")
            else:
                st.info("Mostrando el porcentaje de disponibilidad de datos seg√∫n el archivo de estaciones.")
                sort_order_disp = st.radio("Ordenar estaciones por:", ["% Datos (Mayor a Menor)", "% Datos (Menor a Mayor)", "Alfab√©tico"], horizontal=True, key="sort_disp")
                df_chart = gdf_display.copy()
                if "% Datos (Mayor a Menor)" in sort_order_disp: df_chart = df_chart.sort_values(Config.PERCENTAGE_COL, ascending=False)
                elif "% Datos (Menor a Mayor" in sort_order_disp: df_chart = df_chart.sort_values(Config.PERCENTAGE_COL, ascending=True)
                else: df_chart = df_chart.sort_values(Config.STATION_NAME_COL, ascending=True)
                fig_disp = px.bar(df_chart, x=Config.STATION_NAME_COL, y=Config.PERCENTAGE_COL,
                                  title='Porcentaje de Disponibilidad de Datos Hist√≥ricos',
                                  labels={Config.STATION_NAME_COL: 'Estaci√≥n', Config.PERCENTAGE_COL: '% de Datos Disponibles'},
                                  color=Config.PERCENTAGE_COL,
                                  color_continuous_scale=px.colors.sequential.Viridis)
                fig_disp.update_layout(height=500, xaxis={'categoryorder':'trace'})
                st.plotly_chart(fig_disp, use_container_width=True)
        else:
            st.warning("No hay estaciones seleccionadas para mostrar el gr√°fico.")

def display_graphs_tab(df_anual_melted, df_monthly_filtered, stations_for_analysis, gdf_filtered):
    st.header("Visualizaciones de Precipitaci√≥n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return

    year_range_val = st.session_state.get('year_range', (2000, 2020))
    if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
        year_min, year_max = year_range_val
    else:
        year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
        
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci√≥n: {stations_for_analysis[0]}"
    
    sub_tab_anual, sub_tab_mensual, sub_tab_comparacion, sub_tab_distribucion, \
    sub_tab_acumulada, sub_tab_altitud, sub_tab_regional = \
        st.tabs(["An√°lisis Anual", "An√°lisis Mensual", "Comparaci√≥n R√°pida", "Distribuci√≥n",
                 "Acumulada", "Relaci√≥n Altitud", "Serie Regional"])

    with sub_tab_anual:
        anual_graf_tab, anual_analisis_tab = st.tabs(["Gr√°fico de Serie Anual", "An√°lisis Multianual"])
        with anual_graf_tab:
            if not df_anual_melted.empty:
                st.subheader("Precipitaci√≥n Anual (mm)")
                st.info("Solo se muestran los a√±os con 10 o m√°s meses de datos v√°lidos.")
                chart_anual = \
                    alt.Chart(df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])).mark_line(point=True).encode(
                        x=alt.X(f'{Config.YEAR_COL}:O', title='A√±o'),
                        y=alt.Y(f'{Config.PRECIPITATION_COL}:Q', title='Precipitaci√≥n (mm)'),
                        color=f'{Config.STATION_NAME_COL}:N',
                        tooltip=[alt.Tooltip(Config.STATION_NAME_COL), alt.Tooltip(Config.YEAR_COL,
                                                                                   format='d'), alt.Tooltip(f'{Config.PRECIPITATION_COL}:Q', format='.0f')]
                    ).properties(title=f'Precipitaci√≥n Anual por Estaci√≥n ({year_min} - {year_max})').interactive()
                st.altair_chart(chart_anual, use_container_width=True)
            else:
                st.warning("No hay datos anuales para mostrar la serie.")

        with anual_analisis_tab:
            if not df_anual_melted.empty:
                st.subheader("Precipitaci√≥n Media Multianual")
                st.caption(f"Per√≠odo de an√°lisis: {year_min} - {year_max}")
                chart_type_annual = st.radio("Seleccionar tipo de gr√°fico:", ("Gr√°fico de Barras (Promedio)", "Gr√°fico de Cajas (Distribuci√≥n)"), key="avg_chart_type_annual", horizontal=True)
                if chart_type_annual == "Gr√°fico de Barras (Promedio)":
                    df_summary = df_anual_melted.groupby(Config.STATION_NAME_COL,
                                                         as_index=False)[Config.PRECIPITATION_COL].mean().round(0)
                    sort_order = st.radio("Ordenar estaciones por:", ["Promedio (Mayor a Menor)", "Promedio (Menor a Mayor)", "Alfab√©tico"], horizontal=True, key="sort_annual_avg")
                    if "Mayor a Menor" in sort_order: df_summary = df_summary.sort_values(Config.PRECIPITATION_COL, ascending=False)
                    elif "Menor a Mayor" in sort_order: df_summary = df_summary.sort_values(Config.PRECIPITATION_COL, ascending=True)
                    else: df_summary = df_summary.sort_values(Config.STATION_NAME_COL, ascending=True)
                    
                    fig_avg = px.bar(df_summary, x=Config.STATION_NAME_COL,
                                     y=Config.PRECIPITATION_COL,
                                     title=f'Promedio de Precipitaci√≥n Anual por Estaci√≥n ({year_min} - {year_max})',
                                     labels={Config.STATION_NAME_COL: 'Estaci√≥n', Config.PRECIPITATION_COL: 'Precipitaci√≥n Media Anual (mm)'},
                                     color=Config.PRECIPITATION_COL,
                                     color_continuous_scale=px.colors.sequential.Blues_r)
                    
                    fig_avg.update_layout(height=500,
                                          xaxis={'categoryorder': 'total descending' if "Mayor a Menor" in sort_order
                                                 else ('total ascending' if "Menor a Mayor" in sort_order else 'trace')})
                    st.plotly_chart(fig_avg, use_container_width=True)
                else: # Gr√°fico de Cajas
                    df_anual_filtered_for_box = \
                        df_anual_melted[df_anual_melted[Config.STATION_NAME_COL].isin(stations_for_analysis)]
                    fig_box_annual = px.box(df_anual_filtered_for_box, x=Config.STATION_NAME_COL,
                                            y=Config.PRECIPITATION_COL,
                                            color=Config.STATION_NAME_COL, points='all',
                                            title='Distribuci√≥n de la Precipitaci√≥n Anual por Estaci√≥n',
                                            labels={Config.STATION_NAME_COL: 'Estaci√≥n',
                                                    Config.PRECIPITATION_COL: 'Precipitaci√≥n Anual (mm)'})
                    fig_box_annual.update_layout(height=500)
                    st.plotly_chart(fig_box_annual, use_container_width=True, key="box_anual_multianual") # <-- KEY A√ëADIDA
            else:
                st.warning("No hay datos anuales para mostrar el an√°lisis multianual.")

    with sub_tab_mensual:
        mensual_graf_tab, mensual_enso_tab, mensual_datos_tab = st.tabs(["Gr√°fico de Serie Mensual", "An√°lisis ENSO en el Per√≠odo", "Tabla de Datos"])
        with mensual_graf_tab:
            if not df_monthly_filtered.empty:
                controls_col, chart_col = st.columns([1, 4])
                with controls_col:
                    st.markdown("##### Opciones del Gr√°fico")
                    chart_type = st.radio("Tipo de Gr√°fico:", 
                                          ["L√≠neas y Puntos", "Nube de Puntos", "Gr√°fico de Cajas (Distribuci√≥n Mensual)"], 
                                          key="monthly_chart_type")
                    color_by_disabled = (chart_type == "Gr√°fico de Cajas (Distribuci√≥n Mensual)")
                    color_by = st.radio("Colorear por:", ["Estaci√≥n", "Mes"],
                                        key="monthly_color_by", disabled=color_by_disabled)
                with chart_col:
                    if chart_type != "Gr√°fico de Cajas (Distribuci√≥n Mensual)":
                        base_chart = alt.Chart(df_monthly_filtered).encode(
                            x=alt.X(f'{Config.DATE_COL}:T', title='Fecha'),
                            y=alt.Y(f'{Config.PRECIPITATION_COL}:Q', title='Precipitaci√≥n (mm)'),
                            tooltip=[alt.Tooltip(Config.DATE_COL, format='%Y-%m'),
                                     alt.Tooltip(Config.PRECIPITATION_COL, format='.0f'),
                                     Config.STATION_NAME_COL,
                                     Config.ORIGIN_COL, alt.Tooltip(f'{Config.MONTH_COL}:N', title="Mes")]
                        )
                        color_encoding = alt.Color(f'{Config.STATION_NAME_COL}:N', legend=alt.Legend(title="Estaciones"))
                        if color_by == "Mes":
                            color_encoding = alt.Color(f'month({Config.DATE_COL}):N', legend=alt.Legend(title="Meses"), scale=alt.Scale(scheme='tableau20'))

                        if chart_type == "L√≠neas y Puntos":
                            line_chart = base_chart.mark_line(opacity=0.4, color='lightgray').encode(detail=f'{Config.STATION_NAME_COL}:N')
                            point_chart = base_chart.mark_point(filled=True, size=60).encode(color=color_encoding)
                            final_chart = (line_chart + point_chart)
                        else:
                            point_chart = base_chart.mark_point(filled=True, size=60).encode(color=color_encoding)
                            final_chart = point_chart
                        
                        st.altair_chart(final_chart.properties(height=500, title=f"Serie de Precipitaci√≥n Mensual ({year_min} - {year_max})").interactive(), use_container_width=True)
                    else:
                        st.subheader("Distribuci√≥n de la Precipitaci√≥n Mensual")
                        fig_box_monthly = px.box(df_monthly_filtered, x=Config.MONTH_COL,
                                                 y=Config.PRECIPITATION_COL,
                                                 color=Config.STATION_NAME_COL, title='Distribuci√≥n de la Precipitaci√≥n por Mes',
                                                 labels={Config.MONTH_COL: 'Mes', Config.PRECIPITATION_COL: 'Precipitaci√≥n Mensual (mm)', Config.STATION_NAME_COL: 'Estaci√≥n'})
                        fig_box_monthly.update_layout(height=500)
                        st.plotly_chart(fig_box_monthly, use_container_width=True)
            else:
                st.warning("No hay datos mensuales para mostrar el gr√°fico.")

        with mensual_enso_tab:
            if 'df_enso' in st.session_state and st.session_state.df_enso is not None:
                enso_filtered = \
                    st.session_state.df_enso[(st.session_state.df_enso[Config.DATE_COL].dt.year >= year_min) &
                                             (st.session_state.df_enso[Config.DATE_COL].dt.year <= year_max) &
                                             (st.session_state.df_enso[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))]
                fig_enso_mensual = create_enso_chart(enso_filtered)
                st.plotly_chart(fig_enso_mensual, use_container_width=True, key="enso_chart_mensual")
            else:
                st.info("No hay datos ENSO disponibles para este an√°lisis.")

        with mensual_datos_tab:
            st.subheader("Datos de Precipitaci√≥n Mensual Detallados")
            if not df_monthly_filtered.empty:
                df_values = df_monthly_filtered.pivot_table(index=Config.DATE_COL,
                                                            columns=Config.STATION_NAME_COL, values=Config.PRECIPITATION_COL).round(1)
                st.dataframe(df_values, use_container_width=True)
            else:
                st.info("No hay datos mensuales detallados.")

    with sub_tab_comparacion:
        st.subheader("Comparaci√≥n de Precipitaci√≥n entre Estaciones")
        if len(stations_for_analysis) < 2:
            st.info("Seleccione al menos dos estaciones para comparar.")
        else:
            st.markdown("##### Precipitaci√≥n Mensual Promedio")
            df_monthly_avg = df_monthly_filtered.groupby([Config.STATION_NAME_COL,
                                                          Config.MONTH_COL])[Config.PRECIPITATION_COL].mean().reset_index()
            fig_avg_monthly = px.line(df_monthly_avg, x=Config.MONTH_COL,
                                      y=Config.PRECIPITATION_COL, color=Config.STATION_NAME_COL,
                                      labels={Config.MONTH_COL: 'Mes', Config.PRECIPITATION_COL: 'Precipitaci√≥n Promedio (mm)'},
                                      title='Promedio de Precipitaci√≥n Mensual por Estaci√≥n')
            meses_dict = {'Enero': 1, 'Febrero': 2, 'Marzo': 3, 'Abril': 4, 'Mayo': 5, 'Junio': 6, 'Julio': 7,
                          'Agosto': 8, 'Septiembre': 9, 'Octubre': 10, 'Noviembre': 11, 'Diciembre': 12}
            fig_avg_monthly.update_layout(height=500, xaxis=dict(tickmode='array',
                                                                 tickvals=list(meses_dict.values()), ticktext=list(meses_dict.keys())))
            st.plotly_chart(fig_avg_monthly, use_container_width=True)

            st.markdown("##### Distribuci√≥n de Precipitaci√≥n Anual")
            df_anual_filtered_for_box = \
                df_anual_melted[df_anual_melted[Config.STATION_NAME_COL].isin(stations_for_analysis)]
            fig_box_annual = px.box(df_anual_filtered_for_box, x=Config.STATION_NAME_COL,
                                    y=Config.PRECIPITATION_COL,
                                    color=Config.STATION_NAME_COL, points='all',
                                    title='Distribuci√≥n de la Precipitaci√≥n Anual por Estaci√≥n',
                                    labels={Config.STATION_NAME_COL: 'Estaci√≥n', Config.PRECIPITATION_COL:
                                            'Precipitaci√≥n Anual (mm)'})
            fig_box_annual.update_layout(height=500)
            st.plotly_chart(fig_box_annual, use_container_width=True, key="box_anual_comparacion")
            
    with sub_tab_distribucion:
        st.subheader("Distribuci√≥n de la Precipitaci√≥n")
        distribucion_tipo = st.radio("Seleccionar tipo de distribuci√≥n:", ("Anual", "Mensual"),
                                     horizontal=True)
        plot_type = st.radio("Seleccionar tipo de gr√°fico:", ("Histograma", "Gr√°fico de Viol√≠n"),
                             horizontal=True, key="distribucion_plot_type")
        if distribucion_tipo == "Anual":
            if not df_anual_melted.empty:
                if plot_type == "Histograma":
                    fig_hist_anual = px.histogram(df_anual_melted, x=Config.PRECIPITATION_COL,
                                                  color=Config.STATION_NAME_COL,
                                                  title=f'Distribuci√≥n Anual de Precipitaci√≥n ({year_min} - {year_max})',
                                                  labels={Config.PRECIPITATION_COL: 'Precipitaci√≥n Anual (mm)', 'count': 'Frecuencia'})
                    fig_hist_anual.update_layout(height=500)
                    st.plotly_chart(fig_hist_anual, use_container_width=True)
                else:
                    fig_violin_anual = px.violin(df_anual_melted, y=Config.PRECIPITATION_COL,
                                                 x=Config.STATION_NAME_COL, color=Config.STATION_NAME_COL,
                                                 box=True, points="all", title='Distribuci√≥n Anual con Gr√°fico de Viol√≠n',
                                                 labels={Config.PRECIPITATION_COL: 'Precipitaci√≥n Anual (mm)',
                                                         Config.STATION_NAME_COL: 'Estaci√≥n'})
                    fig_violin_anual.update_layout(height=500)
                    st.plotly_chart(fig_violin_anual, use_container_width=True)
            else:
                st.warning("No hay datos anuales para mostrar la distribuci√≥n.")
        else:
            if not df_monthly_filtered.empty:
                if plot_type == "Histograma":
                    fig_hist_mensual = px.histogram(df_monthly_filtered, x=Config.PRECIPITATION_COL,
                                                    color=Config.STATION_NAME_COL,
                                                    title=f'Distribuci√≥n Mensual de Precipitaci√≥n ({year_min} - {year_max})',
                                                    labels={Config.PRECIPITATION_COL: 'Precipitaci√≥n Mensual (mm)',
                                                            'count': 'Frecuencia'})
                    fig_hist_mensual.update_layout(height=500)
                    st.plotly_chart(fig_hist_mensual, use_container_width=True)
                else:
                    fig_violin_mensual = px.violin(df_monthly_filtered, y=Config.PRECIPITATION_COL,
                                                   x=Config.MONTH_COL, color=Config.STATION_NAME_COL,
                                                   box=True, points="all", title='Distribuci√≥n Mensual con Gr√°fico de Viol√≠n',
                                                   labels={Config.MONTH_COL: 'Mes', Config.PRECIPITATION_COL: 'Precipitaci√≥n Mensual (mm)', Config.STATION_NAME_COL: 'Estaci√≥n'})
                    fig_violin_mensual.update_layout(height=500)
                    st.plotly_chart(fig_violin_mensual, use_container_width=True)
            else:
                st.warning("No hay datos mensuales para mostrar la distribuci√≥n.")

    with sub_tab_acumulada:
        st.subheader("Precipitaci√≥n Acumulada Anual")
        if not df_anual_melted.empty:
            df_acumulada = df_anual_melted.groupby([Config.YEAR_COL,
                                                    Config.STATION_NAME_COL])[Config.PRECIPITATION_COL].sum().reset_index()
            fig_acumulada = px.bar(df_acumulada, x=Config.YEAR_COL, y=Config.PRECIPITATION_COL,
                                   color=Config.STATION_NAME_COL,
                                   title=f'Precipitaci√≥n Acumulada por A√±o ({year_min} - {year_max})',
                                   labels={Config.YEAR_COL: 'A√±o', Config.PRECIPITATION_COL: 'Precipitaci√≥n Acumulada (mm)'})
            fig_acumulada.update_layout(barmode='group', height=500)
            st.plotly_chart(fig_acumulada, use_container_width=True)
        else:
            st.info("No hay datos para calcular la precipitaci√≥n acumulada.")

    with sub_tab_altitud:
        st.subheader("Relaci√≥n entre Altitud y Precipitaci√≥n")
        if not df_anual_melted.empty and not gdf_filtered[Config.ALTITUDE_COL].isnull().all():
            df_relacion = \
                df_anual_melted.groupby(Config.STATION_NAME_COL)[Config.PRECIPITATION_COL].mean().reset_index()
            df_relacion = df_relacion.merge(gdf_filtered[[Config.STATION_NAME_COL,
                                                          Config.ALTITUDE_COL]].drop_duplicates(), on=Config.STATION_NAME_COL, how='left')
            fig_relacion = px.scatter(df_relacion, x=Config.ALTITUDE_COL, y=Config.PRECIPITATION_COL,
                                      color=Config.STATION_NAME_COL,
                                      title='Relaci√≥n entre Precipitaci√≥n Media Anual y Altitud',
                                      labels={Config.ALTITUDE_COL: 'Altitud (m)', Config.PRECIPITATION_COL:
                                              'Precipitaci√≥n Media Anual (mm)'})
            fig_relacion.update_layout(height=500)
            st.plotly_chart(fig_relacion, use_container_width=True)
        else:
            st.info("No hay datos de altitud o precipitaci√≥n disponibles para analizar la relaci√≥n.")

    with sub_tab_regional:
        st.subheader("Serie de Tiempo Promedio Regional (M√∫ltiples Estaciones)")
        if not stations_for_analysis:
            st.warning("Seleccione una o m√°s estaciones en el panel lateral para calcular la serie regional.")
        elif df_monthly_filtered.empty:
            st.warning("No hay datos mensuales para las estaciones seleccionadas para calcular la serie regional.")
        else:
            with st.spinner("Calculando serie de tiempo regional..."):
                df_regional_avg = \
                    df_monthly_filtered.groupby(Config.DATE_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                df_regional_avg.rename(columns={Config.PRECIPITATION_COL: 'Precipitaci√≥n Promedio'},
                                       inplace=True)

                show_individual = False
                if len(stations_for_analysis) > 1:
                    show_individual = st.checkbox("Superponer estaciones individuales", value=False)

                fig_regional = go.Figure()

                if show_individual and len(stations_for_analysis) <= 10:
                    for station in stations_for_analysis:
                        df_s = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] ==
                                                   station]
                        fig_regional.add_trace(go.Scatter(
                            x=df_s[Config.DATE_COL], y=df_s[Config.PRECIPITATION_COL], mode='lines',
                            name=station, line=dict(color='rgba(128, 128, 128, 0.5)', width=1.5),
                            showlegend=True
                        ))
                elif show_individual:
                    st.info("Demasiadas estaciones seleccionadas para superponer (>10). Mostrando solo el promedio regional.")

                fig_regional.add_trace(go.Scatter(
                    x=df_regional_avg[Config.DATE_COL], y=df_regional_avg['Precipitaci√≥n Promedio'],
                    mode='lines', name='Promedio Regional', line=dict(color='#1f77b4', width=3)
                ))

                fig_regional.update_layout(
                    title=f'Serie de Tiempo Promedio Regional ({len(stations_for_analysis)} Estaciones)',
                    xaxis_title="Fecha", yaxis_title="Precipitaci√≥n Mensual (mm)", height=550
                )
                st.plotly_chart(fig_regional, use_container_width=True)

            with st.expander("Ver Datos de la Serie Regional Promedio"):
                df_regional_avg_display = df_regional_avg.rename(columns={'Precipitaci√≥n Promedio': 'Precipitaci√≥n Promedio Regional (mm)'})
                st.dataframe(df_regional_avg_display.round(1), use_container_width=True)

def display_advanced_maps_tab(gdf_filtered, stations_for_analysis, df_anual_melted, df_monthly_filtered):
    st.header("Mapas Avanzados")
    
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
        
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return

    # --- Se elimina "Visualizaci√≥n de Estaci√≥n" de la lista ---
    tab_names = ["Animaci√≥n GIF (Antioquia)", "Visualizaci√≥n Temporal", "Gr√°fico de Carrera", 
                 "Mapa Animado", "Comparaci√≥n de Mapas", "Interpolaci√≥n Comparativa"]
    
    gif_tab, temporal_tab, race_tab, anim_tab, compare_tab, kriging_tab = \
        st.tabs(tab_names)

    with gif_tab:
        st.subheader("Distribuci√≥n Espacio-Temporal de la Lluvia en Antioquia")
        if os.path.exists(Config.GIF_PATH):
            col_controls, col_gif = st.columns([1, 3])
            with col_controls:
                if st.button("üîÑ Reiniciar Animaci√≥n"):
                    st.session_state['gif_reload_key'] += 1
                    st.rerun()
            with col_gif:
                try:
                    with open(Config.GIF_PATH, "rb") as file:
                        contents = file.read()
                    data_url = base64.b64encode(contents).decode("utf-8")
                    st.markdown(
                        f'<img src="data:image/gif;base64,{data_url}" alt="Animaci√≥n PPAM" '
                        f'style="width:70%; max-width: 600px;" '
                        f'key="gif_display_{st.session_state["gif_reload_key"]}">',
                        unsafe_allow_html=True
                    )
                except Exception as e:
                    st.warning(f"Error al cargar/mostrar GIF: {e}")
        else:
            st.warning("No se encontr√≥ el archivo GIF en la ruta especificada.")
    
    with temporal_tab:
        st.subheader("Explorador Anual de Precipitaci√≥n")
        df_anual_melted_non_na = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        
        if not df_anual_melted_non_na.empty:
            all_years_int = sorted(df_anual_melted_non_na[Config.YEAR_COL].unique())
            controls_col, map_col = st.columns([1, 3])
            
            with controls_col:
                st.markdown("##### Opciones de Visualizaci√≥n")
                selected_base_map_config, selected_overlays_config = display_map_controls(st, "temporal")

                selected_year = None
                if len(all_years_int) > 1:
                    selected_year = st.slider('Seleccione un A√±o para Explorar', 
                                              min_value=min(all_years_int),
                                              max_value=max(all_years_int), 
                                              value=min(all_years_int),
                                              key="temporal_year_slider")
                elif len(all_years_int) == 1:
                    selected_year = all_years_int[0]
                    st.info(f"Mostrando √∫nico a√±o disponible: {selected_year}")
                
                if selected_year:
                    st.markdown(f"#### Resumen del A√±o: {selected_year}")
                    df_year_filtered = df_anual_melted_non_na[df_anual_melted_non_na[Config.YEAR_COL] == selected_year]
                    
                    if not df_year_filtered.empty:
                        num_stations = len(df_year_filtered)
                        st.metric("Estaciones con Datos", num_stations)
                        
                        if num_stations > 1:
                            st.metric("Promedio Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].mean():.0f} mm")
                            st.metric("M√°ximo Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].max():.0f} mm")
                        else:
                            st.metric("Precipitaci√≥n Anual", f"{df_year_filtered[Config.PRECIPITATION_COL].iloc[0]:.0f} mm")

            with map_col:
                if selected_year:
                    m_temporal = create_folium_map([4.57, -74.29], 5, selected_base_map_config, selected_overlays_config)
                    df_year_filtered = df_anual_melted_non_na[df_anual_melted_non_na[Config.YEAR_COL] == selected_year]
                    
                    if not df_year_filtered.empty:
                        cols_to_merge = [
                            Config.STATION_NAME_COL, Config.LATITUDE_COL, Config.LONGITUDE_COL, 
                            Config.MUNICIPALITY_COL, Config.ALTITUDE_COL, 'geometry'
                        ]
                        df_map_data = pd.merge(
                            df_year_filtered,
                            gdf_filtered[cols_to_merge].drop_duplicates(),
                            on=Config.STATION_NAME_COL, how="inner"
                        )
                        
                        if not df_map_data.empty:
                            min_val, max_val = df_anual_melted_non_na[Config.PRECIPITATION_COL].min(), df_anual_melted_non_na[Config.PRECIPITATION_COL].max()
                            if min_val >= max_val: max_val = min_val + 1
                            
                            colormap = cm.LinearColormap(colors=plt.cm.viridis.colors, vmin=min_val, vmax=max_val)
                            
                            for row in df_map_data.iterrows():
                                popup_object = generate_station_popup_html(row, df_anual_melted,
                                                                           include_chart=False, 
                                                                           df_monthly_filtered=df_monthly_filtered)
                                folium.CircleMarker(
                                    location=[row['geometry'].y, row['geometry'].x], radius=5,
                                    color=colormap(row[Config.PRECIPITATION_COL]), fill=True,
                                    fill_color=colormap(row[Config.PRECIPITATION_COL]), fill_opacity=0.8,
                                    tooltip=row[Config.STATION_NAME_COL], popup=popup_object
                                ).add_to(m_temporal)
                                
                            temp_gdf = gpd.GeoDataFrame(df_map_data, geometry='geometry', crs=gdf_filtered.crs)
                            if not temp_gdf.empty:
                                bounds = temp_gdf.total_bounds
                                if np.all(np.isfinite(bounds)):
                                    m_temporal.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])
                                    
                            folium.LayerControl().add_to(m_temporal)
                            folium_static(m_temporal, height=700, width="100%")
                        else:
                            st.warning("No hay datos de estaciones v√°lidos para el a√±o seleccionado en el mapa.")
                    else:
                        st.info("No hay datos para el a√±o seleccionado.")
                else:
                    st.warning("No hay a√±os con datos v√°lidos en el rango seleccionado.")
        else:
            st.warning("No hay datos anuales para la visualizaci√≥n temporal.")
            
    with race_tab:
        st.subheader("Ranking Anual de Precipitaci√≥n por Estaci√≥n")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not df_anual_valid.empty:
            fig_racing = px.bar(
                df_anual_valid, x=Config.PRECIPITATION_COL, y=Config.STATION_NAME_COL,
                animation_frame=Config.YEAR_COL, orientation='h',
                labels={Config.PRECIPITATION_COL: 'Precipitaci√≥n Anual (mm)', Config.STATION_NAME_COL: 'Estaci√≥n'},
                title="Evoluci√≥n de Precipitaci√≥n Anual por Estaci√≥n"
            )
            fig_racing.update_layout(
                height=max(600, len(stations_for_analysis) * 35),
                yaxis=dict(categoryorder='total ascending')
            )
            st.plotly_chart(fig_racing, use_container_width=True)
        else:
            st.warning("No hay suficientes datos anuales con los filtros actuales para generar el Gr√°fico de Carrera.")

    with anim_tab:
        st.subheader("Mapa Animado de Precipitaci√≥n Anual")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        if not df_anual_valid.empty:
            df_anim_merged = pd.merge(
                df_anual_valid,
                gdf_filtered.drop_duplicates(subset=[Config.STATION_NAME_COL]),
                on=Config.STATION_NAME_COL,
                how="inner"
            )
            if not df_anim_merged.empty:
                fig_mapa_animado = px.scatter_geo(
                    df_anim_merged,
                    lat=Config.LATITUDE_COL, lon=Config.LONGITUDE_COL,
                    color=Config.PRECIPITATION_COL, size=Config.PRECIPITATION_COL,
                    hover_name=Config.STATION_NAME_COL,
                    animation_frame=Config.YEAR_COL,
                    projection='natural earth',
                    title='Precipitaci√≥n Anual por Estaci√≥n'
                )
                fig_mapa_animado.update_geos(fitbounds="locations", visible=True)
                st.plotly_chart(fig_mapa_animado, use_container_width=True)
            else:
                st.warning("No se pudieron combinar los datos anuales con la informaci√≥n geogr√°fica de las estaciones.")
        else:
            st.warning("No hay suficientes datos anuales con los filtros actuales para generar el Mapa Animado.")

    with compare_tab:
        st.subheader("Comparaci√≥n de Mapas Anuales")
        df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
        all_years = sorted(df_anual_valid[Config.YEAR_COL].unique())

        if len(all_years) > 1:
            control_col, map_col1, map_col2 = st.columns([1, 2, 2])

            with control_col:
                st.markdown("##### Controles de Mapa")
                selected_base_map_config, selected_overlays_config = display_map_controls(st, "compare")
                
                min_year, max_year = int(all_years[0]), int(all_years[-1])
                
                st.markdown("**Mapa 1**")
                year1 = st.selectbox("Seleccione el primer a√±o", options=all_years, index=len(all_years)-1, key="compare_year1")
                
                st.markdown("**Mapa 2**")
                year2 = st.selectbox("Seleccione el segundo a√±o", options=all_years, index=len(all_years)-2, key="compare_year2")
                
                min_precip, max_precip = int(df_anual_valid[Config.PRECIPITATION_COL].min()), int(df_anual_valid[Config.PRECIPITATION_COL].max())
                if min_precip >= max_precip: max_precip = min_precip + 1
                
                color_range = st.slider("Rango de Escala de Color (mm)", min_precip, max_precip, (min_precip, max_precip), key="color_compare")

            # Colormap consistente para ambos mapas
            colormap = cm.LinearColormap(
                colors=plt.cm.viridis.colors,
                vmin=color_range[0], vmax=color_range[1]
            )

            def create_compare_map(data, year, col, gdf_stations_info):
                col.markdown(f"**Precipitaci√≥n en {year}**")
                m = create_folium_map([6.24, -75.58], 6, selected_base_map_config, selected_overlays_config)
                if not data.empty:
                    data_with_geom = pd.merge(data, gdf_stations_info, on=Config.STATION_NAME_COL)
                    gpd_data = gpd.GeoDataFrame(data_with_geom, geometry='geometry', crs=gdf_stations_info.crs)
                    for _, row in gpd_data.iterrows():
                        if pd.notna(row[Config.PRECIPITATION_COL]):
                            popup_object = generate_station_popup_html(row, df_anual_melted)
                            folium.CircleMarker(
                                location=[row['geometry'].y, row['geometry'].x], radius=5,
                                color=colormap(row[Config.PRECIPITATION_COL]),
                                fill=True, fill_color=colormap(row[Config.PRECIPITATION_COL]), fill_opacity=0.8,
                                tooltip=row[Config.STATION_NAME_COL], popup=popup_object
                            ).add_to(m)
                    if not gpd_data.empty:
                        m.fit_bounds(gpd_data.total_bounds.tolist())
                folium.LayerControl().add_to(m)
                with col:
                    folium_static(m, height=450, width="100%")

            gdf_geometries = gdf_filtered[[Config.STATION_NAME_COL, 'geometry']].drop_duplicates()
            data_year1 = df_anual_valid[df_anual_valid[Config.YEAR_COL] == year1]
            data_year2 = df_anual_valid[df_anual_valid[Config.YEAR_COL] == year2]
            
            create_compare_map(data_year1, year1, map_col1, gdf_geometries)
            create_compare_map(data_year2, year2, map_col2, gdf_geometries)

        else:
            st.warning("Se necesitan datos de al menos dos a√±os diferentes para generar la Comparaci√≥n de Mapas.")

    with kriging_tab:
        st.subheader("Comparaci√≥n de Superficies de Interpolaci√≥n Anual")
        df_anual_non_na = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])

        if not stations_for_analysis:
            st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        elif df_anual_non_na.empty or len(df_anual_non_na[Config.YEAR_COL].unique()) == 0:
            st.warning("No hay suficientes datos anuales para realizar la interpolaci√≥n.")
        else:
            min_year, max_year = int(df_anual_non_na[Config.YEAR_COL].min()), int(df_anual_non_na[Config.YEAR_COL].max())

            control_col, map_col1, map_col2 = st.columns([1, 2, 2])
            with control_col:
                st.markdown("##### Controles de los Mapas")
                
                interpolation_methods = ["Kriging Ordinario", "IDW", "Spline (Thin Plate)"]
                if Config.ELEVATION_COL in gdf_filtered.columns:
                    interpolation_methods.insert(1, "Kriging con Deriva Externa (KED)")

                st.markdown("**Mapa 1**")
                year1 = st.slider("Seleccione el a√±o", min_year, max_year, max_year, key="interp_year1")
                method1 = st.selectbox("M√©todo de interpolaci√≥n", options=interpolation_methods, key="interp_method1")
                variogram_model1 = None
                if "Kriging" in method1:
                    variogram_options = ['linear', 'spherical', 'exponential', 'gaussian']
                    variogram_model1 = st.selectbox("Modelo de Variograma para Mapa 1", variogram_options, key="var_model_1")

                st.markdown("---")
                st.markdown("**Mapa 2**")
                year2 = st.slider("Seleccione el a√±o", min_year, max_year, max_year - 1 if max_year > min_year else max_year, key="interp_year2")
                method2 = st.selectbox("M√©todo de interpolaci√≥n", options=interpolation_methods, index=1, key="interp_method2")
                variogram_model2 = None
                if "Kriging" in method2:
                    variogram_options = ['linear', 'spherical', 'exponential', 'gaussian']
                    variogram_model2 = st.selectbox("Modelo de Variograma para Mapa 2", variogram_options, key="var_model_2")

            fig1, fig_var1, error1 = create_interpolation_surface(year1, method1, variogram_model1, gdf_filtered, df_anual_non_na)
            fig2, fig_var2, error2 = create_interpolation_surface(year2, method2, variogram_model2, gdf_filtered, df_anual_non_na)
            
            with map_col1:
                if fig1: st.plotly_chart(fig1, use_container_width=True)
                else: st.info(error1)
            with map_col2:
                if fig2: st.plotly_chart(fig2, use_container_width=True)
                else: st.info(error2)

            st.markdown("---")
            st.markdown("##### Variogramas de los Mapas")
            col3, col4 = st.columns(2)
            with col3:
                if fig_var1:
                    buf = io.BytesIO()
                    fig_var1.savefig(buf, format="png")
                    st.pyplot(fig_var1)
                    st.download_button(
                        label="Descargar Variograma 1 (PNG)", data=buf.getvalue(),
                        file_name=f"variograma_1_{year1}_{method1}_{variogram_model1}.png", mime="image/png"
                    )
                    plt.close(fig_var1)
                else:
                    st.info("El variograma no est√° disponible para este m√©todo o no hay suficientes datos.")
            with col4:
                if fig_var2:
                    buf = io.BytesIO()
                    fig_var2.savefig(buf, format="png")
                    st.pyplot(fig_var2)
                    st.download_button(
                        label="Descargar Variograma 2 (PNG)", data=buf.getvalue(),
                        file_name=f"variograma_2_{year2}_{method2}_{variogram_model2}.png", mime="image/png"
                    )
                    plt.close(fig_var2)
                else:
                    st.info("El variograma no est√° disponible para este m√©todo o no hay suficientes datos.")
                    
def display_drought_analysis_tab(df_monthly_filtered, gdf_filtered, stations_for_analysis):
    st.header("An√°lisis de Extremos Hidrol√≥gicos")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    
    percentile_sub_tab, indices_sub_tab = st.tabs(["An√°lisis por Percentiles", "√çndices de Sequ√≠a (SPI/SPEI)"])

    with percentile_sub_tab:
        st.subheader("An√°lisis de Eventos Extremos por Percentiles Mensuales")
        station_to_analyze_perc = st.selectbox(
            "Seleccione una estaci√≥n para el an√°lisis:",
            options=sorted(stations_for_analysis),
            key="percentile_station_select"
        )
        if station_to_analyze_perc:
            display_percentile_analysis_subtab(df_monthly_filtered, station_to_analyze_perc)

    with indices_sub_tab:
        st.subheader("An√°lisis con √çndices Estandarizados")
        
        col1_idx, col2_idx = st.columns([1, 2])
        
        with col1_idx:
            index_type = st.radio("Seleccione el √çndice a Calcular:", ("SPI", "SPEI"))
            station_to_analyze_idx = st.selectbox("Seleccione una estaci√≥n para el an√°lisis:",
                                                  options=sorted(stations_for_analysis),
                                                  key="index_station_select")
            index_window = st.select_slider("Seleccione la escala de tiempo (meses):",
                                           options=[3, 6, 9, 12, 24], value=12, key="index_window_slider",
                                           help="Escalas cortas (3m) reflejan sequ√≠as agr√≠colas. Escalas largas (12-24m) reflejan sequ√≠as hidrol√≥gicas.")
        
        if station_to_analyze_idx:
            df_station_idx = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] == station_to_analyze_idx].copy()
            df_station_idx = df_station_idx.set_index(Config.DATE_COL).sort_index()

            index_values = pd.Series(dtype=float)

            if index_type == "SPI":
                precip_series = df_station_idx[Config.PRECIPITATION_COL]
                if len(precip_series.dropna()) < index_window * 2:
                    with col2_idx:
                        st.warning(f"No hay suficientes datos ({len(precip_series.dropna())} meses) para calcular el SPI-{index_window}.")
                else:
                    with st.spinner(f"Calculando SPI-{index_window}..."):
                        index_values = calculate_spi(precip_series, index_window)

            elif index_type == "SPEI":
                if Config.ET_COL not in df_station_idx.columns or df_station_idx[Config.ET_COL].isnull().all():
                    with col2_idx:
                        st.error(f"No hay datos de evapotranspiraci√≥n ('{Config.ET_COL}') disponibles para esta estaci√≥n. No se puede calcular el SPEI.")
                else:
                    precip_series = df_station_idx[Config.PRECIPITATION_COL]
                    et_series = df_station_idx[Config.ET_COL]
                    
                    if len(precip_series.dropna()) < index_window * 2 or len(et_series.dropna()) < index_window * 2:
                        with col2_idx:
                            st.warning(f"No hay suficientes datos de precipitaci√≥n o evapotranspiraci√≥n para calcular el SPEI-{index_window}.")
                    else:
                        with st.spinner(f"Calculando SPEI-{index_window}..."):
                            index_values = calculate_spei(precip_series, et_series, index_window)
            
            if not index_values.empty:
                df_plot = pd.DataFrame({'index_val': index_values}).dropna()
                
                conditions = [
                    df_plot['index_val'] <= -2.0, (df_plot['index_val'] > -2.0) & (df_plot['index_val'] <= -1.5),
                    (df_plot['index_val'] > -1.5) & (df_plot['index_val'] <= -1.0), (df_plot['index_val'] > -1.0) & (df_plot['index_val'] < 1.0),
                    (df_plot['index_val'] >= 1.0) & (df_plot['index_val'] < 1.5), (df_plot['index_val'] >= 1.5) & (df_plot['index_val'] < 2.0),
                    df_plot['index_val'] >= 2.0
                ]
                colors = ['#b2182b', '#ef8a62', '#fddbc7', '#d1e5f0', '#92c5de', '#4393c3', '#2166ac']
                df_plot['color'] = np.select(conditions, colors, default='grey')
                
                fig = go.Figure()
                fig.add_trace(go.Bar(x=df_plot.index, y=df_plot['index_val'], marker_color=df_plot['color'], name=index_type))
                
                fig.update_layout(title=f"√çndice {index_type}-{index_window} para {station_to_analyze_idx}",
                                  yaxis_title=f"Valor {index_type}", xaxis_title="Fecha", height=600)

                with col2_idx:
                    st.plotly_chart(fig, use_container_width=True)
                    with st.expander(f"Ver tabla de datos {index_type}"):
                        st.dataframe(df_plot[['index_val']].rename(columns={'index_val': index_type}).style.format("{:.2f}"))
                            
def display_anomalies_tab(df_long, df_monthly_filtered, stations_for_analysis):
    st.header("An√°lisis de Anomal√≠as de Precipitaci√≥n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci√≥n: {stations_for_analysis[0]}"
    
    if df_long is None or df_long.empty:
        st.warning("No se puede realizar el an√°lisis de anomal√≠as. El DataFrame base no est√° disponible.")
        return

    df_anomalias = calculate_monthly_anomalies(df_monthly_filtered, df_long)

    if st.session_state.get('exclude_na', False):
        df_anomalias.dropna(subset=['anomalia'], inplace=True)

    if df_anomalias.empty or df_anomalias['anomalia'].isnull().all():
        st.warning("No hay suficientes datos hist√≥ricos para calcular y mostrar las anomal√≠as con los filtros actuales.")
        return

    anom_graf_tab, anom_fase_tab, anom_extremos_tab = st.tabs(["Gr√°fico de Anomal√≠as",
                                                              "Anomal√≠as por Fase ENSO", "Tabla de Eventos Extremos"])

    with anom_graf_tab:
        df_plot = df_anomalias.groupby(Config.DATE_COL).agg(
            anomalia=('anomalia', 'mean'),
            anomalia_oni=(Config.ENSO_ONI_COL, 'first')
        ).reset_index()

        fig = create_anomaly_chart(df_plot)
        st.plotly_chart(fig, use_container_width=True)

    with anom_fase_tab:
        if Config.ENSO_ONI_COL in df_anomalias.columns:
            df_anomalias_enso = df_anomalias.dropna(subset=[Config.ENSO_ONI_COL]).copy()
            conditions = [df_anomalias_enso[Config.ENSO_ONI_COL] >= 0.5,
                          df_anomalias_enso[Config.ENSO_ONI_COL] <= -0.5]
            phases = ['El Ni√±o', 'La Ni√±a']
            df_anomalias_enso['enso_fase'] = np.select(conditions, phases, default='Neutral')

            fig_box = px.box(df_anomalias_enso, x='enso_fase', y='anomalia', color='enso_fase',
                             title="Distribuci√≥n de Anomal√≠as de Precipitaci√≥n por Fase ENSO",
                             labels={'anomalia': 'Anomal√≠a de Precipitaci√≥n (mm)', 'enso_fase': 'Fase ENSO'},
                             points='all')
            st.plotly_chart(fig_box, use_container_width=True)
        else:
            st.warning("La columna 'anomalia_oni' no est√° disponible para este an√°lisis.")

    with anom_extremos_tab:
        st.subheader("Eventos Mensuales Extremos (Basado en Anomal√≠as)")
        df_extremos = df_anomalias.dropna(subset=['anomalia']).copy()
        df_extremos['fecha'] = df_extremos[Config.DATE_COL].dt.strftime('%Y-%m')

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### 10 Meses m√°s Secos")
            secos = df_extremos.nsmallest(10, 'anomalia')[['fecha', Config.STATION_NAME_COL,
                                                          'anomalia', Config.PRECIPITATION_COL, 'precip_promedio_mes']]
            st.dataframe(secos.rename(columns={Config.STATION_NAME_COL: 'Estaci√≥n', 'anomalia':
                                               'Anomal√≠a (mm)', Config.PRECIPITATION_COL: 'Ppt. (mm)', 'precip_promedio_mes': 'Ppt. Media (mm)'}).round(0), use_container_width=True)

        with col2:
            st.markdown("##### 10 Meses m√°s H√∫medos")
            humedos = df_extremos.nlargest(10, 'anomalia')[['fecha', Config.STATION_NAME_COL,
                                                           'anomalia', Config.PRECIPITATION_COL, 'precip_promedio_mes']]
            st.dataframe(humedos.rename(columns={Config.STATION_NAME_COL: 'Estaci√≥n',
                                                 'anomalia': 'Anomal√≠a (mm)', Config.PRECIPITATION_COL: 'Ppt. (mm)', 'precip_promedio_mes':
                                                 'Ppt. Media (mm)'}).round(0), use_container_width=True)

def display_stats_tab(df_long, df_anual_melted, df_monthly_filtered, stations_for_analysis):
    st.header("Estad√≠sticas de Precipitaci√≥n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci√≥n: {stations_for_analysis[0]}"
    
    matriz_tab, resumen_mensual_tab, sintesis_tab = st.tabs(["Matriz de Disponibilidad", "Resumen Mensual", "S√≠ntesis General"])

    with matriz_tab:
        st.subheader("Matriz de Disponibilidad de Datos Anual")
        df_base_raw = st.session_state.get('df_monthly_processed', pd.DataFrame())
        
        if df_base_raw.empty:
            st.warning("Los datos procesados no est√°n disponibles en la sesi√≥n.")
            return

        df_base_filtered = \
            df_base_raw[df_base_raw[Config.STATION_NAME_COL].isin(stations_for_analysis)].copy()

        if st.session_state.analysis_mode == "Completar series (interpolaci√≥n)":
            view_mode = st.radio("Seleccione la vista de la matriz:",
                                 ("Porcentaje de Datos Originales",
                                  "Porcentaje de Datos Totales (Original + Completado)",
                                  "Porcentaje de Datos Completados (Interpolados)"),
                                 horizontal=True)

            if view_mode == "Porcentaje de Datos Completados (Interpolados)":
                df_counts = df_base_filtered[df_base_filtered[Config.ORIGIN_COL] ==
                                             'Completado'].groupby(
                    [Config.STATION_NAME_COL, Config.YEAR_COL]
                ).size().reset_index(name='count_completed')
                df_counts['porc_value'] = (df_counts['count_completed'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL,
                                             columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Reds"
                title_text = "Porcentaje de Datos Completados (Interpolados)"
            elif view_mode == "Porcentaje de Datos Totales (Original + Completado)":
                df_counts = df_base_filtered.groupby(
                    [Config.STATION_NAME_COL, Config.YEAR_COL]
                ).size().reset_index(name='count_total')
                df_counts['porc_value'] = (df_counts['count_total'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL,
                                             columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Blues"
                title_text = "Disponibilidad de Datos Totales (Original + Completado)"
            else: # Porcentaje de Datos Originales
                df_original_filtered = \
                    df_long[df_long[Config.STATION_NAME_COL].isin(stations_for_analysis)]
                df_counts = df_original_filtered.groupby(
                    [Config.STATION_NAME_COL, Config.YEAR_COL]
                ).size().reset_index(name='count_original')
                df_counts['porc_value'] = (df_counts['count_original'] / 12) * 100
                heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL,
                                             columns=Config.YEAR_COL, values='porc_value').fillna(0)
                color_scale = "Greens"
                title_text = "Disponibilidad de Datos Originales"
        else: # Usar datos originales (Modo por defecto)
            df_base_filtered = \
                df_long[df_long[Config.STATION_NAME_COL].isin(stations_for_analysis)].copy()
            df_counts = df_base_filtered.groupby(
                [Config.STATION_NAME_COL, Config.YEAR_COL]
            ).size().reset_index(name='count_total')
            df_counts['porc_value'] = (df_counts['count_total'] / 12) * 100
            heatmap_df = df_counts.pivot(index=Config.STATION_NAME_COL,
                                         columns=Config.YEAR_COL, values='porc_value').fillna(0)
            color_scale = "Greens"
            title_text = "Disponibilidad de Datos Originales"

        if not heatmap_df.empty:
            avg_availability = heatmap_df.stack().mean()
            logo_col, metric_col = st.columns([1, 5])
            with logo_col:
                if os.path.exists(Config.LOGO_PATH): st.image(Config.LOGO_PATH, width=50)
            with metric_col: st.metric(label=f"Disponibilidad Promedio Anual ({title_text})",
                                       value=f"{avg_availability:.1f}%")
            styled_df = heatmap_df.style.background_gradient(cmap=color_scale, axis=None, vmin=0,
                                                             vmax=100).format("{:.0f}%", na_rep="-").set_table_styles([
                                                                 {'selector': 'th', 'props': [('background-color', '#333'), ('color', 'white'), ('font-size', '14px')]},
                                                                 {'selector': 'td', 'props': [('text-align', 'center')]}])
            st.dataframe(styled_df)
        else:
            st.info("No hay datos para mostrar en la matriz con la selecci√≥n actual.")

    with resumen_mensual_tab:
        st.subheader("Resumen de Estad√≠sticas Mensuales por Estaci√≥n")
        if not df_monthly_filtered.empty:
            summary_data = []
            for station_name, group in df_monthly_filtered.groupby(Config.STATION_NAME_COL):
                max_row = group.loc[group[Config.PRECIPITATION_COL].idxmax()]
                min_row = group.loc[group[Config.PRECIPITATION_COL].idxmin()]
                summary_data.append({
                    "Estaci√≥n": station_name,
                    "Ppt. M√°xima Mensual (mm)": max_row[Config.PRECIPITATION_COL],
                    "Fecha M√°xima": max_row[Config.DATE_COL].strftime('%Y-%m'),
                    "Ppt. M√≠nima Mensual (mm)": min_row[Config.PRECIPITATION_COL],
                    "Fecha M√≠nima": min_row[Config.DATE_COL].strftime('%Y-%m'),
                    "Promedio Mensual (mm)": group[Config.PRECIPITATION_COL].mean()
                })
            summary_df = pd.DataFrame(summary_data)
            st.dataframe(summary_df.round(0), use_container_width=True)
        else:
            st.info("No hay datos para mostrar el resumen mensual.")

    with sintesis_tab:
        st.subheader("S√≠ntesis General de Precipitaci√≥n")
        if not df_monthly_filtered.empty and not df_anual_melted.empty:
            df_anual_valid = df_anual_melted.dropna(subset=[Config.PRECIPITATION_COL])
            if not df_anual_valid.empty:
                max_annual_row = \
                    df_anual_valid.loc[df_anual_valid[Config.PRECIPITATION_COL].idxmax()]
                max_monthly_row = \
                    df_monthly_filtered.loc[df_monthly_filtered[Config.PRECIPITATION_COL].idxmax()]
                meses_map = {1: 'Enero', 2: 'Febrero', 3: 'Marzo', 4: 'Abril', 5: 'Mayo', 6: 'Junio', 7: 'Julio',
                             8: 'Agosto', 9: 'Septiembre', 10: 'Octubre', 11: 'Noviembre', 12: 'Diciembre'}
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        "M√°xima Ppt. Anual Registrada",
                        f"{max_annual_row[Config.PRECIPITATION_COL]:.0f} mm",
                        f"{max_annual_row[Config.STATION_NAME_COL]} (A√±o "
                        f"{int(max_annual_row[Config.YEAR_COL])})"
                    )
                with col2:
                    st.metric(
                        "M√°xima Ppt. Mensual Registrada",
                        f"{max_monthly_row[Config.PRECIPITATION_COL]:.0f} mm",
                        f"{max_monthly_row[Config.STATION_NAME_COL]} "
                        f"({meses_map.get(max_monthly_row[Config.MONTH_COL])} "
                        f"{max_monthly_row[Config.DATE_COL].year})"
                    )
            else:
                st.info("No hay datos anuales v√°lidos para mostrar la s√≠ntesis.")
        else:
            st.info("No hay datos para mostrar la s√≠ntesis general.")

def display_correlation_tab(df_monthly_filtered, stations_for_analysis):
    st.header("An√°lisis de Correlaci√≥n")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    st.markdown("Esta secci√≥n cuantifica la relaci√≥n lineal entre la precipitaci√≥n y diferentes "
                "variables (otras estaciones o √≠ndices clim√°ticos) utilizando el coeficiente de correlaci√≥n de Pearson.")

    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return

    enso_corr_tab, station_corr_tab, indices_climaticos_tab = st.tabs(["Correlaci√≥n con ENSO (ONI)", "Comparaci√≥n entre Estaciones", "Correlaci√≥n con Otros √çndices"])

    with enso_corr_tab:
        if Config.ENSO_ONI_COL not in df_monthly_filtered.columns or \
                df_monthly_filtered[Config.ENSO_ONI_COL].isnull().all():
            st.warning("No se puede realizar el an√°lisis de correlaci√≥n con ENSO. La columna "
                       "'anomalia_oni' no fue encontrada o no tiene datos en el per√≠odo seleccionado.")
            return

        st.subheader("Configuraci√≥n del An√°lisis de Correlaci√≥n con ENSO")
        lag_months = st.slider(
            "Seleccionar desfase temporal (meses)",
            min_value=0, max_value=12, value=0,
            help="Analiza la correlaci√≥n de la precipitaci√≥n con el ENSO de 'x' meses atr√°s. Un desfase de 3 significa correlacionar la lluvia de hoy con el ENSO de hace 3 meses."
        )

        df_corr_analysis = df_monthly_filtered.dropna(subset=[Config.PRECIPITATION_COL,
                                                              Config.ENSO_ONI_COL])
        if df_corr_analysis.empty:
            st.warning("No hay datos coincidentes entre la precipitaci√≥n y el ENSO para la selecci√≥n actual.")
            return

        analysis_level = st.radio("Nivel de An√°lisis de Correlaci√≥n con ENSO", ["Promedio de la selecci√≥n", "Por Estaci√≥n Individual"], horizontal=True, key="enso_corr_level")

        df_plot_corr = pd.DataFrame()
        title_text = ""

        if analysis_level == "Por Estaci√≥n Individual":
            station_to_corr = st.selectbox("Seleccione Estaci√≥n:",
                                           options=sorted(df_corr_analysis[Config.STATION_NAME_COL].unique()),
                                           key="enso_corr_station")
            if station_to_corr:
                df_plot_corr = df_corr_analysis[df_corr_analysis[Config.STATION_NAME_COL] ==
                                                station_to_corr].copy()
                title_text = f"Correlaci√≥n para la estaci√≥n: {station_to_corr}"
        else:
            df_plot_corr = df_corr_analysis.groupby(Config.DATE_COL).agg(
                precipitation=(Config.PRECIPITATION_COL, 'mean'),
                anomalia_oni=(Config.ENSO_ONI_COL, 'first')
            ).reset_index()
            title_text = "Correlaci√≥n para el promedio de las estaciones seleccionadas"

        if not df_plot_corr.empty and len(df_plot_corr) > 2:
            if lag_months > 0:
                df_plot_corr['anomalia_oni_shifted'] = df_plot_corr['anomalia_oni'].shift(lag_months)
                df_plot_corr.dropna(subset=['anomalia_oni_shifted'], inplace=True)
                oni_column_to_use = 'anomalia_oni_shifted'
                lag_text = f" (con desfase de {lag_months} meses)"
            else:
                oni_column_to_use = 'anomalia_oni'
                lag_text = ""

            corr, p_value = stats.pearsonr(df_plot_corr[oni_column_to_use], df_plot_corr['precipitation'])
            st.subheader(title_text + lag_text)

            col1, col2 = st.columns(2)
            col1.metric("Coeficiente de Correlaci√≥n (r)", f"{corr:.3f}")
            col2.metric("Significancia (valor p)", f"{p_value:.4f}")

            if p_value < 0.05:
                st.success("La correlaci√≥n es estad√≠sticamente significativa.")
            else:
                st.warning("La correlaci√≥n no es estad√≠sticamente significativa.")

            fig_corr = px.scatter(
                df_plot_corr, x=oni_column_to_use, y='precipitation', trendline='ols',
                title=f"Dispersi√≥n: Precipitaci√≥n vs. Anomal√≠a ONI{lag_text}",
                labels={
                    oni_column_to_use: f'Anomal√≠a ONI (¬∞C) [desfase {lag_months}m]',
                    'precipitation': 'Precipitaci√≥n Mensual (mm)'
                }
            )
            st.plotly_chart(fig_corr, use_container_width=True)

    with station_corr_tab:
        if len(stations_for_analysis) < 2:
            st.info("Seleccione al menos dos estaciones para comparar la correlaci√≥n entre ellas.")
        else:
            st.subheader("Correlaci√≥n de Precipitaci√≥n entre dos Estaciones")
            station_options = sorted(stations_for_analysis)
            col1, col2 = st.columns(2)
            station1_name = col1.selectbox("Estaci√≥n 1:", options=station_options,
                                           key="corr_station_1")
            station2_name = col2.selectbox("Estaci√≥n 2:", options=station_options, index=1 if
                                           len(station_options) > 1 else 0, key="corr_station_2")

            if station1_name and station2_name and station1_name != station2_name:
                df_station1 = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] ==
                                                  station1_name][
                    [Config.DATE_COL, Config.PRECIPITATION_COL]]
                df_station2 = df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] ==
                                                  station2_name][
                    [Config.DATE_COL, Config.PRECIPITATION_COL]]
                df_merged = pd.merge(df_station1, df_station2, on=Config.DATE_COL, suffixes=('_1',
                                                                                             '_2')).dropna()
                df_merged.rename(columns={f'{Config.PRECIPITATION_COL}_1': station1_name,
                                          f'{Config.PRECIPITATION_COL}_2': station2_name}, inplace=True)
                if not df_merged.empty and len(df_merged) > 2:
                    corr, p_value = stats.pearsonr(df_merged[station1_name], df_merged[station2_name])
                    st.markdown(f"#### Resultados de la correlaci√≥n ({station1_name} vs. "
                                f"{station2_name})")
                    st.metric("Coeficiente de Correlaci√≥n (r)", f"{corr:.3f}")
                    if p_value < 0.05:
                        st.success(f"La correlaci√≥n es estad√≠sticamente significativa (p<{p_value:.4f}).")
                    else:
                        st.warning(f"La correlaci√≥n no es estad√≠sticamente significativa (p>={p_value:.4f}).")
                    slope, intercept, _, _, _ = \
                        stats.linregress(df_merged[station1_name],
                                         df_merged[station2_name])
                    st.info(f"Ecuaci√≥n de regresi√≥n: y={slope:.2f}x+{intercept:.2f}")
                    fig_scatter = px.scatter(
                        df_merged, x=station1_name, y=station2_name, trendline='ols',
                        title=f'Dispersi√≥n de Precipitaci√≥n: {station1_name} vs. {station2_name}',
                        labels={station1_name: f'Precipitaci√≥n en {station1_name} (mm)', station2_name:
                                f'Precipitaci√≥n en {station2_name} (mm)'}
                    )
                    st.plotly_chart(fig_scatter, use_container_width=True)
                else:
                    st.warning("No hay suficientes datos superpuestos para calcular la correlaci√≥n para las estaciones seleccionadas.")

    with indices_climaticos_tab:
        st.subheader("An√°lisis de Correlaci√≥n con √çndices Clim√°ticos (SOI, IOD)")
        available_indices = []
        if Config.SOI_COL in df_monthly_filtered.columns and not \
                df_monthly_filtered[Config.SOI_COL].isnull().all():
            available_indices.append("SOI")
        if Config.IOD_COL in df_monthly_filtered.columns and not \
                df_monthly_filtered[Config.IOD_COL].isnull().all():
            available_indices.append("IOD")
        if not available_indices:
            st.warning("No se encontraron columnas para los √≠ndices clim√°ticos (SOI o IOD) en el archivo principal o no hay datos en el per√≠odo seleccionado.")
        else:
            col1_corr, col2_corr = st.columns(2)
            selected_index = col1_corr.selectbox("Seleccione un √≠ndice clim√°tico:", available_indices)
            selected_station_corr = col2_corr.selectbox("Seleccione una estaci√≥n:",
                                                        options=sorted(stations_for_analysis),
                                                        key="station_for_index_corr")
            if selected_index and selected_station_corr:
                index_col_map = {"SOI": Config.SOI_COL, "IOD": Config.IOD_COL}
                index_col_name = index_col_map.get(selected_index)
                df_merged_indices = \
                    df_monthly_filtered[df_monthly_filtered[Config.STATION_NAME_COL] ==
                                        selected_station_corr].copy()
                if index_col_name in df_merged_indices.columns:
                    df_merged_indices.dropna(subset=[Config.PRECIPITATION_COL, index_col_name],
                                             inplace=True)
                else:
                    st.error(f"La columna para el √≠ndice '{selected_index}' no se encontr√≥ en los datos de la estaci√≥n.")
                    return
                if not df_merged_indices.empty and len(df_merged_indices) > 2:
                    corr, p_value = stats.pearsonr(df_merged_indices[index_col_name],
                                                   df_merged_indices[Config.PRECIPITATION_COL])
                    st.markdown(f"#### Resultados de la correlaci√≥n ({selected_index}) vs. Precipitaci√≥n de "
                                f"{selected_station_corr})")
                    st.metric("Coeficiente de Correlaci√≥n (r)", f"{corr:.3f}")
                    if p_value < 0.05:
                        st.success("La correlaci√≥n es estad√≠sticamente significativa.")
                    else:
                        st.warning(f"La correlaci√≥n no es estad√≠sticamente significativa (p>={p_value:.4f}).")
                    fig_scatter_indices = px.scatter(
                        df_merged_indices, x=index_col_name, y=Config.PRECIPITATION_COL,
                        trendline='ols',
                        title=f'Dispersi√≥n: {selected_index} vs. Precipitaci√≥n de {selected_station_corr}',
                        labels={index_col_name: f'Valor del √çndice {selected_index}',
                                Config.PRECIPITATION_COL: 'Precipitaci√≥n Mensual (mm)'}
                    )
                    st.plotly_chart(fig_scatter_indices, use_container_width=True)
                else:
                    st.warning("No hay suficientes datos superpuestos entre la estaci√≥n y el √≠ndice para calcular la correlaci√≥n.")

def display_enso_tab(df_monthly_filtered, df_enso, gdf_filtered, stations_for_analysis):
    st.header("An√°lisis de Precipitaci√≥n y el Fen√≥meno ENSO")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci√≥n: {stations_for_analysis[0]}"
    
    if df_enso is None or df_enso.empty:
        st.warning("No se encontraron datos del fen√≥meno ENSO en el archivo de precipitaci√≥n cargado.")
        return

    enso_series_tab, enso_anim_tab = st.tabs(["Series de Tiempo ENSO", "Mapa Interactivo ENSO"])

    with enso_series_tab:
        enso_vars_available = {
            Config.ENSO_ONI_COL: 'Anomal√≠a ONI',
            'temp_sst': 'Temp. Superficial del Mar (SST)',
            'temp_media': 'Temp. Media'
        }
        available_tabs = [name for var, name in enso_vars_available.items() if var in df_enso.columns]
        if not available_tabs:
            st.warning("No hay variables ENSO disponibles en el archivo de datos para visualizar.")
        else:
            enso_variable_tabs = st.tabs(available_tabs)
            for i, var_name in enumerate(available_tabs):
                with enso_variable_tabs[i]:
                    var_code = [code for code, name in enso_vars_available.items() if name ==
                                var_name][0]
                    enso_filtered = df_enso
                    if not enso_filtered.empty and var_code in enso_filtered.columns and not \
                            enso_filtered[var_code].isnull().all():
                        fig_enso_series = px.line(enso_filtered, x=Config.DATE_COL, y=var_code,
                                                  title=f"Serie de Tiempo para {var_name}")
                        st.plotly_chart(fig_enso_series, use_container_width=True)
                    else:
                        st.warning(f"No hay datos disponibles para '{var_code}' en el per√≠odo seleccionado.")

    with enso_anim_tab:
        st.subheader("Explorador Mensual del Fen√≥meno ENSO")
        if gdf_filtered.empty or Config.ENSO_ONI_COL not in df_enso.columns:
            st.warning("Datos insuficientes para generar esta visualizaci√≥n. Se requiere informaci√≥n de "
                       "estaciones y la columna 'anomalia_oni'.")
            return
        
        controls_col, map_col = st.columns([1, 3])
        enso_anim_data = df_enso[[Config.DATE_COL,
                                  Config.ENSO_ONI_COL]].copy().dropna(subset=[Config.ENSO_ONI_COL])
        conditions = [enso_anim_data[Config.ENSO_ONI_COL] >= 0.5,
                      enso_anim_data[Config.ENSO_ONI_COL] <= -0.5]
        phases = ['El Ni√±o', 'La Ni√±a']
        enso_anim_data['fase'] = np.select(conditions, phases, default='Neutral')

        year_range_val = st.session_state.get('year_range', (2000, 2020))
        if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
            year_min, year_max = year_range_val
        else:
            year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))

        enso_anim_data_filtered = enso_anim_data[(enso_anim_data[Config.DATE_COL].dt.year >= year_min) &
                                                 (enso_anim_data[Config.DATE_COL].dt.year <= year_max)]
        selected_date = None

        with controls_col:
            st.markdown("##### Controles de Mapa")
            selected_base_map_config, selected_overlays_config = display_map_controls(st,
                                                                                      "enso_anim")
            st.markdown("##### Selecci√≥n de Fecha")
            available_dates = sorted(enso_anim_data_filtered[Config.DATE_COL].unique())
            if available_dates:
                selected_date = st.select_slider("Seleccione una fecha (A√±o-Mes)",
                                                 options=available_dates,
                                                 format_func=lambda date: pd.to_datetime(date).strftime('%Y-%m'))
                phase_info = enso_anim_data_filtered[enso_anim_data_filtered[Config.DATE_COL] ==
                                                     selected_date]
                if not phase_info.empty:
                    current_phase = phase_info['fase'].iloc[0]
                    current_oni = phase_info[Config.ENSO_ONI_COL].iloc[0]
                    st.metric(f"Fase ENSO en {pd.to_datetime(selected_date).strftime('%Y-%m')}",
                              current_phase, f"Anomal√≠a ONI: {current_oni:.2f}¬∞C")
                else:
                    st.warning("No hay datos de ENSO para el per√≠odo seleccionado.")
            else:
                st.warning("No hay fechas con datos ENSO en el rango seleccionado.")

        with map_col:
            if selected_date:
                m_enso = create_folium_map([4.57, -74.29], 5, selected_base_map_config,
                                           selected_overlays_config)
                phase_color_map = {'El Ni√±o': 'red', 'La Ni√±a': 'blue', 'Neutral': 'gray'}
                phase_info = enso_anim_data_filtered[enso_anim_data_filtered[Config.DATE_COL] ==
                                                     selected_date]
                current_phase_str = phase_info['fase'].iloc[0] if not phase_info.empty else "N/A"
                marker_color = phase_color_map.get(current_phase_str, 'black')
                for _, station in gdf_filtered.iterrows():
                    folium.Marker(
                        location=[station['geometry'].y, station['geometry'].x],
                        tooltip=f"{station[Config.STATION_NAME_COL]}<br>Fase: {current_phase_str}",
                        icon=folium.Icon(color=marker_color, icon='cloud')
                    ).add_to(m_enso)
                if not gdf_filtered.empty:
                    bounds = gdf_filtered.total_bounds
                    if np.all(np.isfinite(bounds)):
                        m_enso.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])
                folium.LayerControl().add_to(m_enso)
                folium_static(m_enso, height=700, width="100%")
            else:
                st.info("Seleccione una fecha para visualizar el mapa.")

def display_trends_and_forecast_tab(df_anual_melted, df_monthly_to_process, stations_for_analysis):
    st.header("An√°lisis de Tendencias y Pron√≥sticos")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci√≥n: {stations_for_analysis[0]}"
    
    tab_names = [
        "An√°lisis Lineal", "Tendencia Mann-Kendall", "Tabla Comparativa",
        "Descomposici√≥n de Series", "Autocorrelaci√≥n (ACF/PACF)",
        "Pron√≥stico SARIMA", "Pron√≥stico Prophet", "SARIMA vs Prophet"
    ]
    tendencia_individual_tab, mann_kendall_tab, tendencia_tabla_tab, descomposicion_tab, \
    autocorrelacion_tab, pronostico_sarima_tab, pronostico_prophet_tab, \
    compare_forecast_tab = st.tabs(tab_names)

    with pronostico_sarima_tab:
        st.subheader("Pron√≥stico de Precipitaci√≥n Mensual (Modelo SARIMA)")
        with st.expander("Ajuste de Par√°metros SARIMA y Descripci√≥n"):
            st.markdown("""
            El modelo **SARIMA** (Seasonal Auto-Regressive Integrated Moving Average) utiliza datos
            hist√≥ricos para predecir valores futuros.
            - **(p, d, q):** Componentes no estacionales (AR, I, MA).
            - **(P, D, Q):** Componentes estacionales (AR, I, MA). $s=12$ (mensual).
            """)
        
        col_p, col_d, col_q = st.columns(3)
        p = col_p.slider("p (AR no estacional)", 0, 3, 1, key="sarima_p")
        d = col_d.slider("d (I no estacional)", 0, 2, 1, key="sarima_d")
        q = col_q.slider("q (MA no estacional)", 0, 3, 1, key="sarima_q")

        col_P, col_D, col_Q = st.columns(3)
        P = col_P.slider("P (AR estacional)", 0, 2, 1, key="sarima_P")
        D = col_D.slider("D (I estacional)", 0, 2, 1, key="sarima_D")
        Q = col_Q.slider("Q (MA estacional)", 0, 2, 1, key="sarima_Q")

        station_to_forecast = st.selectbox("Seleccione una estaci√≥n para el pron√≥stico:",
                                           options=stations_for_analysis, key="sarima_station_select")
        forecast_horizon = st.slider("Meses a pronosticar:", 12, 36, 12, step=12,
                                     key="sarima_forecast_horizon_slider")
        
        sarima_order = (p, d, q)
        seasonal_order = (P, D, Q, 12)

        ts_data_sarima = \
            df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] ==
                                  station_to_forecast]

        if ts_data_sarima.empty or len(ts_data_sarima) < 24:
            st.warning("Se necesitan al menos 24 meses de datos continuos para un pron√≥stico SARIMA confiable.")
        else:
            with st.spinner(f"Entrenando modelo y generando pron√≥stico para {station_to_forecast} con SARIMA{sarima_order}x{seasonal_order[:-1]}..."):
                try:
                    ts_data_hist, forecast_mean, forecast_ci, sarima_df_export = \
                        generate_sarima_forecast(ts_data_sarima, sarima_order, seasonal_order, forecast_horizon)
                    st.session_state['sarima_forecast'] = sarima_df_export
                    fig_pronostico = go.Figure()
                    fig_pronostico.add_trace(go.Scatter(x=ts_data_hist.index, y=ts_data_hist, mode='lines',
                                                        name='Datos Hist√≥ricos'))
                    fig_pronostico.add_trace(go.Scatter(x=forecast_mean.index, y=forecast_mean,
                                                        mode='lines', name='Pron√≥stico SARIMA', line=dict(color='red', dash='dash')))
                    fig_pronostico.add_trace(go.Scatter(x=forecast_ci.index, y=forecast_ci.iloc[:, 0],
                                                        fill=None, mode='lines', line=dict(color='rgba(255,0,0,0.2)'),
                                                        showlegend=False))
                    fig_pronostico.add_trace(go.Scatter(x=forecast_ci.index, y=forecast_ci.iloc[:, 1],
                                                        fill='tonexty', mode='lines', line=dict(color='rgba(255,0,0,0.2)'),
                                                        name='Intervalo de Confianza'))
                    fig_pronostico.update_layout(title=f"Pron√≥stico de Precipitaci√≥n SARIMA "
                                                 f"{sarima_order}x{seasonal_order[:-1]} para {station_to_forecast}",
                                                 xaxis_title="Fecha", yaxis_title="Precipitaci√≥n (mm)")
                    st.plotly_chart(fig_pronostico, use_container_width=True)
                    st.info(f"El modelo SARIMA fue entrenado con la configuraci√≥n: **Orden={sarima_order}**, **Estacional={seasonal_order}**.")
                    forecast_df = pd.DataFrame({
                        'fecha': forecast_mean.index, 'pronostico': forecast_mean.values,
                        'limite_inferior': forecast_ci.iloc[:, 0].values, 'limite_superior': forecast_ci.iloc[:, 1].values
                    })
                    csv_data = forecast_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Descargar Pron√≥stico SARIMA en CSV", data=csv_data,
                        file_name=f'pronostico_sarima_{station_to_forecast.replace(" ", "_")}.csv',
                        mime='text/csv', key='download-sarima'
                    )
                except Exception as e:
                    st.error(f"No se pudo generar el pron√≥stico SARIMA. El modelo no pudo convergir. Error: {e}")

    with pronostico_prophet_tab:
        st.subheader("Pron√≥stico de Precipitaci√≥n Mensual (Modelo Prophet)")
        station_to_forecast_prophet = st.selectbox("Seleccione una estaci√≥n para el pron√≥stico:",
                                                   options=stations_for_analysis, key="prophet_station_select",
                                                   help="El pron√≥stico se realiza para una √∫nica serie de tiempo con Prophet.")
        forecast_horizon_prophet = st.slider("Meses a pronosticar:", 12, 36, 12, step=12,
                                             key="prophet_forecast_horizon_slider")
        
        ts_data_prophet_raw = \
            df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] ==
                                  station_to_forecast_prophet]

        if ts_data_prophet_raw.empty or len(ts_data_prophet_raw) < 24:
            st.warning("Se necesitan al menos 24 meses de datos para que Prophet funcione correctamente.")
        else:
            with st.spinner(f"Entrenando modelo Prophet y generando pron√≥stico para {station_to_forecast_prophet}..."):
                try:
                    model_prophet, forecast_prophet = \
                        generate_prophet_forecast(ts_data_prophet_raw, forecast_horizon_prophet)
                    st.session_state['prophet_forecast'] = forecast_prophet[['ds', 'yhat']].copy()
                    st.success("Pron√≥stico generado exitosamente.")
                    fig_prophet = plot_plotly(model_prophet, forecast_prophet)
                    fig_prophet.update_layout(title=f"Pron√≥stico de Precipitaci√≥n con Prophet para "
                                              f"{station_to_forecast_prophet}",
                                              yaxis_title="Precipitaci√≥n (mm)")
                    st.plotly_chart(fig_prophet, use_container_width=True)
                    csv_data = forecast_prophet[['ds', 'yhat', 'yhat_lower',
                                                 'yhat_upper']].to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Descargar Pron√≥stico Prophet en CSV", data=csv_data,
                        file_name=f'pronostico_prophet_{station_to_forecast_prophet.replace(" ", "_")}.csv',
                        mime='text/csv', key='download-prophet'
                    )
                except Exception as e:
                    st.error(f"Ocurri√≥ un error al generar el pron√≥stico con Prophet. Error: {e}")

    with compare_forecast_tab:
        st.subheader("Comparaci√≥n de Pron√≥sticos: SARIMA vs Prophet")
        sarima_disponible = st.session_state.get('sarima_forecast') is not None
        prophet_disponible = st.session_state.get('prophet_forecast') is not None
        if not sarima_disponible or not prophet_disponible:
            st.warning("Debe generar un pron√≥stico SARIMA y un pron√≥stico Prophet en las pesta√±as anteriores antes de poder compararlos.")
        else:
            sarima_df = st.session_state['sarima_forecast'].copy()
            prophet_df = st.session_state['prophet_forecast'].copy()
            if sarima_df.empty or prophet_df.empty:
                st.warning("Los pron√≥sticos generados no contienen datos v√°lidos para la comparaci√≥n.")
            else:
                station_id_for_history = st.selectbox("Estaci√≥n para serie hist√≥rica (debe coincidir con la de "
                                                      "los pron√≥sticos):",
                                                      options=stations_for_analysis, key="compare_station_history")
                
                ts_data = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] ==
                                                station_id_for_history].copy()

                if ts_data.empty:
                    st.warning("Datos hist√≥ricos no encontrados para la comparaci√≥n.")
                else:
                    sarima_df['ds'] = pd.to_datetime(sarima_df['ds'])
                    prophet_df['ds'] = pd.to_datetime(prophet_df['ds'])
                    ts_data['ds'] = ts_data[Config.DATE_COL]
                    df_combined = pd.merge(sarima_df[['ds', 'yhat']], prophet_df[['ds', 'yhat']], on='ds',
                                           suffixes=('_sarima', '_prophet'), how='outer')
                    df_combined = pd.merge(df_combined, ts_data[['ds', Config.PRECIPITATION_COL]],
                                           on='ds', how='left')
                    fig_compare = go.Figure()
                    fig_compare.add_trace(go.Scatter(
                        x=df_combined['ds'], y=df_combined[Config.PRECIPITATION_COL],
                        mode='lines+markers', name='Hist√≥rico', line=dict(color='gray', width=2)
                    ))
                    fig_compare.add_trace(go.Scatter(
                        x=df_combined['ds'], y=df_combined['yhat_sarima'],
                        mode='lines', name='Pron√≥stico SARIMA', line=dict(color='red', dash='dash', width=3)
                    ))
                    fig_compare.add_trace(go.Scatter(
                        x=df_combined['ds'], y=df_combined['yhat_prophet'],
                        mode='lines', name='Pron√≥stico Prophet', line=dict(color='blue', dash='dash', width=3)
                    ))
                    fig_compare.update_layout(
                        title=f"Pron√≥stico Comparativo SARIMA vs Prophet para {station_id_for_history}",
                        xaxis_title="Fecha", yaxis_title="Precipitaci√≥n (mm)", height=650,
                        legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
                    )
                    st.plotly_chart(fig_compare, use_container_width=True)
                    
    with tendencia_individual_tab:
        st.subheader("Tendencia de Precipitaci√≥n Anual (Regresi√≥n Lineal)")
        analysis_type = st.radio("Tipo de An√°lisis de Tendencia:", ["Promedio de la selecci√≥n",
                                                                     "Estaci√≥n individual"], horizontal=True,
                                 key="linear_trend_type")
        df_to_analyze = None
        title_for_download = "promedio"
        if analysis_type == "Promedio de la selecci√≥n":
            df_to_analyze = \
                df_anual_melted.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean().reset_index()
        else:
            station_to_analyze = st.selectbox("Seleccione una estaci√≥n para analizar:",
                                              options=stations_for_analysis, key="tendencia_station_select")
            if station_to_analyze:
                df_to_analyze = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] ==
                                                station_to_analyze]
                title_for_download = station_to_analyze.replace(" ", "_")
        if df_to_analyze is not None and \
                len(df_to_analyze.dropna(subset=[Config.PRECIPITATION_COL])) > 2:
            df_to_analyze['a√±o_num'] = pd.to_numeric(df_to_analyze[Config.YEAR_COL])
            df_clean = df_to_analyze.dropna(subset=[Config.PRECIPITATION_COL])
            slope, intercept, r_value, p_value, std_err = stats.linregress(df_clean['a√±o_num'],
                                                                           df_clean[Config.PRECIPITATION_COL])
            tendencia_texto = "aumentando" if slope > 0 else "disminuyendo"
            significancia_texto = "**estad√≠sticamente significativa**" if p_value < 0.05 else "no es estad√≠sticamente significativa"
            st.markdown(f"La tendencia de la precipitaci√≥n es de **{slope:.2f} mm/a√±o** (es decir, est√° "
                        f"{tendencia_texto}). Con un valor p de **{p_value:.3f}**, esta tendencia "
                        f"**{significancia_texto}**.")
            df_to_analyze['tendencia'] = slope * df_to_analyze['a√±o_num'] + intercept
            fig_tendencia = px.scatter(df_to_analyze, x='a√±o_num', y=Config.PRECIPITATION_COL,
                                       title=f'Tendencia de la Precipitaci√≥n Anual')
            fig_tendencia.add_trace(go.Scatter(x=df_to_analyze['a√±o_num'],
                                               y=df_to_analyze['tendencia'], mode='lines', name='L√≠nea de Tendencia',
                                               line=dict(color='red')))
            fig_tendencia.update_layout(xaxis_title="A√±o", yaxis_title="Precipitaci√≥n Anual (mm)")
            st.plotly_chart(fig_tendencia, use_container_width=True)
            csv_data = df_to_analyze.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="Descargar datos de Tendencia Anual", data=csv_data,
                file_name=f'tendencia_anual_{title_for_download}.csv', mime='text/csv',
                key='download-anual-tendencia'
            )
        else:
            st.warning("No hay suficientes datos en el per√≠odo seleccionado para calcular una tendencia.")

    with mann_kendall_tab:
        st.subheader("Tendencia de Precipitaci√≥n Anual (Prueba de Mann-Kendall)")
        with st.expander("¬øQu√© es la prueba de Mann-Kendall?"):
            st.markdown("""
            La **Prueba de Mann-Kendall** es un m√©todo estad√≠stico no param√©trico utilizado para
            detectar tendencias en series de tiempo. No asume que los datos sigan una distribuci√≥n particular.
            - **Tendencia**: Indica si es 'increasing' (creciente), 'decreasing' (decreciente) o 'no trend'.
            - **Valor $p$**: Si es menor a 0.05, la tendencia se considera estad√≠sticamente significativa.
            - **Pendiente de Sen**: Cuantifica la magnitud de la tendencia y es robusto frente a valores at√≠picos.
            """)
        mk_analysis_type = st.radio("Tipo de An√°lisis de Tendencia:", ["Promedio de la selecci√≥n",
                                                                        "Estaci√≥n individual"], horizontal=True,
                                    key="mk_trend_type")
        df_to_analyze_mk = None
        if mk_analysis_type == "Promedio de la selecci√≥n":
            df_to_analyze_mk = \
                df_anual_melted.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean().reset_index()
        else:
            station_to_analyze_mk = st.selectbox("Seleccione una estaci√≥n para analizar:",
                                                 options=stations_for_analysis, key="mk_station_select")
            if station_to_analyze_mk:
                df_to_analyze_mk = df_anual_melted[df_anual_melted[Config.STATION_NAME_COL] ==
                                                   station_to_analyze_mk]
        if df_to_analyze_mk is not None and \
                len(df_to_analyze_mk.dropna(subset=[Config.PRECIPITATION_COL])) > 3:
            df_clean_mk = \
                df_to_analyze_mk.dropna(subset=[Config.PRECIPITATION_COL]).sort_values(by=Config.YEAR_COL)
            mk_result = mk.original_test(df_clean_mk[Config.PRECIPITATION_COL])
            st.markdown(f"#### Resultados para: {mk_analysis_type if mk_analysis_type == 'Promedio de la selecci√≥n' else station_to_analyze_mk}")
            col1, col2, col3 = st.columns(3)
            col1.metric("Tendencia Detectada", mk_result.trend.capitalize())
            col2.metric("Valor p", f"{mk_result.p:.4f}")
            col3.metric("Pendiente de Sen (mm/a√±o)", f"{mk_result.slope:.2f}")
            if mk_result.p < 0.05:
                st.success("La tendencia es estad√≠sticamente significativa $(p<0.05)$")
            else:
                st.warning("La tendencia no es estad√≠sticamente significativa $(p>=0.05)$")
            fig_mk = px.scatter(df_clean_mk, x=Config.YEAR_COL, y=Config.PRECIPITATION_COL,
                                title="An√°lisis de Tendencia con Pendiente de Sen")
            median_x = df_clean_mk[Config.YEAR_COL].median()
            median_y = df_clean_mk[Config.PRECIPITATION_COL].median()
            intercept_sen = median_y - mk_result.slope * median_x
            x_vals = np.array(df_clean_mk[Config.YEAR_COL])
            y_vals = mk_result.slope * x_vals + intercept_sen
            fig_mk.add_trace(go.Scatter(x=x_vals, y=y_vals, mode='lines', name="Pendiente de Sen",
                                        line=dict(color='orange')))
            fig_mk.update_layout(xaxis_title="A√±o", yaxis_title="Precipitaci√≥n Anual (mm)")
            st.plotly_chart(fig_mk, use_container_width=True)
        else:
            st.warning("No hay suficientes datos (se requieren al menos 4 puntos) para calcular la tendencia de Mann-Kendall.")

    with tendencia_tabla_tab:
        st.subheader("Tabla Comparativa de Tendencias de Precipitaci√≥n Anual")
        st.info("Esta tabla resume los resultados de dos m√©todos de an√°lisis de tendencia. Presione el "
                "bot√≥n para calcular los valores para todas las estaciones seleccionadas.")
        if st.button("Calcular Tendencias para Todas las Estaciones Seleccionadas"):
            with st.spinner("Calculando tendencias..."):
                results = []
                df_anual_calc = df_anual_melted.copy()
                if st.session_state.get('exclude_zeros', False):
                    df_anual_calc = df_anual_calc[df_anual_calc[Config.PRECIPITATION_COL] > 0]
                for station in stations_for_analysis:
                    station_data = df_anual_calc[df_anual_calc[Config.STATION_NAME_COL] ==
                                                 station].dropna(subset=[Config.PRECIPITATION_COL]).sort_values(by=Config.YEAR_COL)
                    slope_lin, p_lin = np.nan, np.nan
                    trend_mk, p_mk, slope_sen = "Datos insuficientes", np.nan, np.nan
                    if len(station_data) > 2:
                        station_data['a√±o_num'] = pd.to_numeric(station_data[Config.YEAR_COL])
                        res = stats.linregress(station_data['a√±o_num'], station_data[Config.PRECIPITATION_COL])
                        slope_lin, p_lin = res.slope, res.pvalue
                    if len(station_data) > 3:
                        mk_result_table = mk.original_test(station_data[Config.PRECIPITATION_COL])
                        trend_mk = mk_result_table.trend.capitalize()
                        p_mk = mk_result_table.p
                        slope_sen = mk_result_table.slope
                    results.append({
                        "Estaci√≥n": station, "A√±os Analizados": len(station_data),
                        "Tendencia Lineal (mm/a√±o)": slope_lin, "Valor p (Lineal)": p_lin,
                        "Tendencia MK": trend_mk, "Valor p (MK)": p_mk,
                        "Pendiente de Sen (mm/a√±o)": slope_sen,
                    })
                if results:
                    results_df = pd.DataFrame(results)
                    def style_p_value(val):
                        if pd.isna(val) or isinstance(val, str): return ""
                        color = 'lightgreen' if val < 0.05 else 'lightcoral'
                        return f'background-color: {color}'
                    st.dataframe(results_df.style.format({
                        "Tendencia Lineal (mm/a√±o)": "{:.2f}", "Valor p (Lineal)": "{:.4f}",
                        "Valor p (MK)": "{:.4f}", "Pendiente de Sen (mm/a√±o)": "{:.2f}",
                    }).applymap(style_p_value, subset=['Valor p (Lineal)', 'Valor p (MK)']),
                                 use_container_width=True)
                    csv_data = results_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Descargar tabla de tendencias en CSV", data=csv_data,
                        file_name='tabla_tendencias_comparativa.csv', mime='text/csv', key='download-tabla-tendencias'
                    )
                else:
                    st.warning("No se pudieron calcular tendencias para las estaciones seleccionadas.")

    with descomposicion_tab:
        st.subheader("Descomposici√≥n de Series de Tiempo Mensual")
        st.markdown("""
        La **descomposici√≥n de una serie de tiempo** separa sus componentes principales: Tendencia, Estacionalidad y Residuo.
        """)
        station_to_decompose = st.selectbox("Seleccione una estaci√≥n para la descomposici√≥n:",
                                            options=stations_for_analysis, key="decompose_station_select")
        if station_to_decompose:
            df_station = df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] == station_to_decompose].copy()
            if not df_station.empty:
                df_station.set_index(Config.DATE_COL, inplace=True)
                try:
                    result = get_decomposition_results(df_station[Config.PRECIPITATION_COL], period=12, model='additive')
                    fig_decomp = go.Figure()
                    fig_decomp.add_trace(go.Scatter(x=df_station.index, y=df_station[Config.PRECIPITATION_COL], mode='lines',
                                                    name='Original'))
                    fig_decomp.add_trace(go.Scatter(x=result.trend.index, y=result.trend, mode='lines',
                                                    name='Tendencia'))
                    fig_decomp.add_trace(go.Scatter(x=result.seasonal.index, y=result.seasonal,
                                                    mode='lines', name='Estacionalidad'))
                    fig_decomp.add_trace(go.Scatter(x=result.resid.index, y=result.resid, mode='lines',
                                                    name='Residuo'))
                    fig_decomp.update_layout(title=f"Descomposici√≥n de la Serie de Precipitaci√≥n para "
                                             f"{station_to_decompose}", height=600,
                                             legend=dict(orientation='h', yanchor="bottom", y=1.02, xanchor="right", x=1))
                    st.plotly_chart(fig_decomp, use_container_width=True)
                except Exception as e:
                    st.error(f"No se pudo realizar la descomposici√≥n de la serie. Puede que la serie de datos sea demasiado corta. Error: {e}")
            else:
                st.warning(f"No hay datos mensuales para la estaci√≥n {station_to_decompose} en el per√≠odo seleccionado.")

    with autocorrelacion_tab:
        st.subheader("An√°lisis de Autocorrelaci√≥n (ACF) y Autocorrelaci√≥n Parcial (PACF)")
        st.markdown("Estos gr√°ficos ayudan a identificar la dependencia de la precipitaci√≥n con sus valores pasados (rezagos).")
        station_to_analyze_acf = st.selectbox("Seleccione una estaci√≥n:",
                                              options=stations_for_analysis, key="acf_station_select")
        max_lag = st.slider("N√∫mero m√°ximo de rezagos (meses):", min_value=12, max_value=60,
                            value=24, step=12)
        if station_to_analyze_acf:
            df_station_acf = \
                df_monthly_to_process[df_monthly_to_process[Config.STATION_NAME_COL] ==
                                      station_to_analyze_acf].copy()
            if not df_station_acf.empty:
                df_station_acf.set_index(Config.DATE_COL, inplace=True)
                df_station_acf = df_station_acf.asfreq('MS')
                df_station_acf[Config.PRECIPITATION_COL] = \
                    df_station_acf[Config.PRECIPITATION_COL].interpolate(method='time').dropna()
                if len(df_station_acf) > max_lag:
                    try:
                        fig_acf = create_acf_chart(df_station_acf[Config.PRECIPITATION_COL], max_lag)
                        st.plotly_chart(fig_acf, use_container_width=True)
                        fig_pacf = create_pacf_chart(df_station_acf[Config.PRECIPITATION_COL], max_lag)
                        st.plotly_chart(fig_pacf, use_container_width=True)
                    except Exception as e:
                        st.error(f"No se pudieron generar los gr√°ficos de autocorrelaci√≥n. Error: {e}")
                else:
                    st.warning(f"No hay suficientes datos (se requieren > {max_lag} meses) para el an√°lisis de autocorrelaci√≥n.")
            else:
                st.warning(f"No hay datos para la estaci√≥n {station_to_analyze_acf} en el per√≠odo seleccionado.")

def display_downloads_tab(df_anual_melted, df_monthly_filtered, stations_for_analysis):
    st.header("Opciones de Descarga")
    if len(stations_for_analysis) == 0:
        st.warning("Por favor, seleccione al menos una estaci√≥n para activar las descargas.")
        return

    @st.cache_data
    def convert_df_to_csv(df):
        return df.to_csv(index=False).encode('utf-8')

    st.markdown("**Datos de Precipitaci√≥n Anual (Filtrados)**")
    csv_anual = convert_df_to_csv(df_anual_melted)
    st.download_button("Descargar CSV Anual", csv_anual, 'precipitacion_anual.csv', 'text/csv',
                       key='download-anual')

    st.markdown("**Datos de Precipitaci√≥n Mensual (Filtrados)**")
    csv_mensual = convert_df_to_csv(df_monthly_filtered)
    st.download_button("Descargar CSV Mensual", csv_mensual, 'precipitacion_mensual.csv',
                       'text/csv', key='download-mensual')

    if st.session_state.analysis_mode == "Completar series (interpolaci√≥n)":
        st.markdown("**Datos de Precipitaci√≥n Mensual (Series Completadas y Filtradas)**")
        year_range_val = st.session_state.get('year_range', (2000, 2020))
        if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
            year_min, year_max = year_range_val
        else:
            year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))
            
        df_completed_to_download = (st.session_state.df_monthly_processed[
            (st.session_state.df_monthly_processed[Config.STATION_NAME_COL].isin(stations_for_analysis)) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.year >= year_min) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.year <= year_max) &
            (st.session_state.df_monthly_processed[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))
        ]).copy()
        csv_completado = convert_df_to_csv(df_completed_to_download)
        st.download_button("Descargar CSV con Series Completadas", csv_completado,
                            'precipitacion_mensual_completada.csv', 'text/csv', key='download-completado')

def display_station_table_tab(gdf_filtered, df_anual_melted, stations_for_analysis):
    st.header("Informaci√≥n Detallada de las Estaciones")
    display_filter_summary(
        total_stations_count=len(st.session_state.gdf_stations),
        selected_stations_count=len(stations_for_analysis),
        year_range=st.session_state.year_range,
        selected_months_count=len(st.session_state.meses_numeros)
    )
    
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    if not stations_for_analysis:
        st.warning("Por favor, seleccione al menos una estaci√≥n para ver esta secci√≥n.")
        return
    
    selected_stations_str = f"{len(stations_for_analysis)} estaciones" if len(stations_for_analysis) > 1 else f"1 estaci√≥n: {stations_for_analysis[0]}"
    st.info(f"Mostrando informaci√≥n para {selected_stations_str}.")

    if gdf_filtered.empty:
        st.info("No hay estaciones que cumplan con los filtros geogr√°ficos y de datos seleccionados.")
        return

    df_info_table = gdf_filtered[[Config.STATION_NAME_COL, Config.ALTITUDE_COL,
                                  Config.MUNICIPALITY_COL, Config.REGION_COL,
                                  Config.PERCENTAGE_COL]].copy()

    if not df_anual_melted.empty:
        df_mean_precip = \
            df_anual_melted.groupby(Config.STATION_NAME_COL)[Config.PRECIPITATION_COL].mean().round(0).reset_index()
        df_mean_precip.rename(columns={Config.PRECIPITATION_COL: 'Precipitaci√≥n media anual (mm)'}, inplace=True)
        df_info_table = df_info_table.merge(df_mean_precip, on=Config.STATION_NAME_COL,
                                            how='left')
    else:
        df_info_table['Precipitaci√≥n media anual (mm)'] = 'N/A'

    df_for_display = (
        df_info_table
        .drop(columns=[Config.PERCENTAGE_COL])
        .set_index(Config.STATION_NAME_COL)
    )

    st.dataframe(df_for_display, use_container_width=True)

def display_percentile_analysis_subtab(df_monthly_filtered, station_to_analyze_perc):
    """
    Realiza y muestra el an√°lisis de sequ√≠as y eventos extremos por percentiles
    mensuales para una estaci√≥n.
    """
    df_long = st.session_state.get('df_long')
    if df_long is None or df_long.empty:
        st.warning("No se puede realizar el an√°lisis de percentiles. El DataFrame hist√≥rico no est√° disponible.")
        return

    st.markdown("#### Par√°metros del An√°lisis")
    col1, col2 = st.columns(2)
    p_lower = col1.slider("Percentil Inferior (Sequ√≠a):", 1, 40, 10, key="p_lower_perc")
    p_upper = col2.slider("Percentil Superior (H√∫medo):", 60, 99, 90, key="p_upper_perc")
    st.markdown("---")

    with st.spinner(f"Calculando percentiles {p_lower} y {p_upper} para {station_to_analyze_perc}..."):
        try:
            df_extremes, df_thresholds = calculate_percentiles_and_extremes(
                df_long, station_to_analyze_perc, p_lower, p_upper
            )
            
            year_range_val = st.session_state.get('year_range', (2000, 2020))
            if isinstance(year_range_val, tuple) and len(year_range_val) == 2 and isinstance(year_range_val[0], int):
                year_min, year_max = year_range_val
            else:
                year_min, year_max = st.session_state.get('year_range_single', (2000, 2020))

            df_plot = df_extremes[
                (df_extremes[Config.DATE_COL].dt.year >= year_min) &
                (df_extremes[Config.DATE_COL].dt.year <= year_max) &
                (df_extremes[Config.DATE_COL].dt.month.isin(st.session_state.meses_numeros))
            ].copy()
            
            if df_plot.empty:
                st.warning("No hay datos que coincidan con los filtros de tiempo para la estaci√≥n seleccionada.")
                return

            st.subheader(f"Serie de Tiempo con Eventos Extremos ({p_lower} y {p_upper} Percentiles)")
            
            color_map = {'Sequ√≠a Extrema (< P{}%)'.format(p_lower): 'red',
                         'H√∫medo Extremo (> P{}%)'.format(p_upper): 'blue',
                         'Normal': 'gray'}

            fig_series = px.scatter(df_plot, x=Config.DATE_COL, y=Config.PRECIPITATION_COL,
                                    color='event_type',
                                    color_discrete_map=color_map,
                                    title=f"Precipitaci√≥n Mensual y Eventos Extremos en {station_to_analyze_perc}",
                                    labels={Config.PRECIPITATION_COL: "Precipitaci√≥n (mm)",
                                            Config.DATE_COL: "Fecha"},
                                    hover_data={'event_type': True, 'p_lower': ':.0f', 'p_upper': ':.0f'})
            
            mean_precip = df_long[df_long[Config.STATION_NAME_COL] == station_to_analyze_perc][Config.PRECIPITATION_COL].mean()
            fig_series.add_hline(y=mean_precip, line_dash="dash", line_color="green", annotation_text="Media Hist√≥rica")

            fig_series.update_layout(height=500)
            st.plotly_chart(fig_series, use_container_width=True)

            st.subheader("Umbrales de Percentil Mensual (Climatolog√≠a Hist√≥rica)")
            
            meses_map_inv = {1: 'Ene', 2: 'Feb', 3: 'Mar', 4: 'Abr', 5: 'May', 6: 'Jun',
                             7: 'Jul', 8: 'Ago', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dic'}
            df_thresholds['Month_Name'] = df_thresholds[Config.MONTH_COL].map(meses_map_inv)

            fig_thresh = go.Figure()
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['p_upper'],
                                            mode='lines+markers', name=f'Percentil Superior (P{p_upper}%)', line=dict(color='blue')))
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['p_lower'],
                                            mode='lines+markers', name=f'Percentil Inferior (P{p_lower}%)', line=dict(color='red')))
            fig_thresh.add_trace(go.Scatter(x=df_thresholds['Month_Name'], y=df_thresholds['mean_monthly'],
                                            mode='lines', name='Media Mensual', line=dict(color='green', dash='dot')))

            fig_thresh.update_layout(title='Umbrales de Precipitaci√≥n por Mes (Basado en Climatolog√≠a)',
                                     xaxis_title="Mes", yaxis_title="Precipitaci√≥n (mm)", height=400)
            st.plotly_chart(fig_thresh, use_container_width=True)

        except Exception as e:
            st.error(f"Error al calcular el an√°lisis de percentiles: {e}")
            st.info("Aseg√∫rese de que el archivo hist√≥rico de datos (`df_long`) contenga datos suficientes para la estaci√≥n seleccionada.")
